{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VoxelNetImplementation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNY9YWXjJA/qtbvgU8INn/6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"h9LbJnkeLTtT"},"source":["## Reference\n","* https://github.com/skyhehe123/VoxelNet-pytorch\n","* https://github.com/traveller59/second.pytorch"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVHbiwfcKFkH","executionInfo":{"status":"ok","timestamp":1623816395055,"user_tz":-540,"elapsed":29862,"user":{"displayName":"kyungpyo kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifa6EEm8a6qyXBrSpAKnm5YYLjZIHS2UC57G-Isw=s64","userId":"08142163190830893513"}},"outputId":"0a453d9c-7eb8-42b9-9fff-5afc3675eea2"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tfENXmqLmSk","executionInfo":{"status":"ok","timestamp":1623802700622,"user_tz":-540,"elapsed":309,"user":{"displayName":"kyungpyo kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifa6EEm8a6qyXBrSpAKnm5YYLjZIHS2UC57G-Isw=s64","userId":"08142163190830893513"}},"outputId":"53edfe10-35b9-40d7-a883-2253d0a428f1"},"source":["%cd /content/gdrive/MyDrive/Colab\\ Notebooks/LidarObjectDetection/VoxelNet\n","%pycat config.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Notebooks/LidarObjectDetection/VoxelNet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nPyzGfjELQAH","executionInfo":{"status":"ok","timestamp":1623808095157,"user_tz":-540,"elapsed":312,"user":{"displayName":"kyungpyo kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifa6EEm8a6qyXBrSpAKnm5YYLjZIHS2UC57G-Isw=s64","userId":"08142163190830893513"}},"outputId":"48b97fb4-1675-4b23-acf4-8bc4ad09a404"},"source":["%%writefile config.py\n","import math\n","import numpy as np\n","\n","class config:\n","\n","    # classes\n","    class_list = ['Car', 'Van']\n","\n","    # batch size\n","    N=2\n","\n","    # maxiumum number of points per voxel\n","    MaxPtsNum = 35\n","\n","    # voxel size\n","    vd = 0.4\n","    vh = 0.2\n","    vw = 0.2\n","\n","    # points cloud range\n","    xrange = (0, 70.4)\n","    yrange = (-40, 40)\n","    zrange = (-3, 1)\n","\n","    # voxel grid\n","    W = math.ceil((xrange[1] - xrange[0]) / vw)\n","    H = math.ceil((yrange[1] - yrange[0]) / vh)\n","    D = math.ceil((zrange[1] - zrange[0]) / vd)\n","\n","    # iou threshold\n","    pos_threshold = 0.6\n","    neg_threshold = 0.45\n","\n","    #   anchors: (200, 176, 2, 7) x y z h w l r\n","    x = np.linspace(xrange[0]+vw, xrange[1]-vw, int(W/2))\n","    y = np.linspace(yrange[0]+vh, yrange[1]-vh, int(H/2))\n","    cx, cy = np.meshgrid(x, y)\n","    # all is (w, l, 2)\n","    cx = np.tile(cx[..., np.newaxis], 2)\n","    cy = np.tile(cy[..., np.newaxis], 2)\n","    cz = np.ones_like(cx) * -1.0\n","    w = np.ones_like(cx) * 1.6\n","    l = np.ones_like(cx) * 3.9\n","    h = np.ones_like(cx) * 1.56\n","    r = np.ones_like(cx)\n","    r[..., 0] = 0\n","    r[..., 1] = np.pi/2\n","    anchors = np.stack([cx, cy, cz, h, w, l, r], axis=-1)\n","\n","    anchors_per_position = 2\n","\n","    # non-maximum suppression\n","    nms_threshold = 0.1\n","    score_threshold = 0.96"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting config.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y2T1yfOjKiBF","executionInfo":{"status":"ok","timestamp":1623808096495,"user_tz":-540,"elapsed":10,"user":{"displayName":"kyungpyo kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifa6EEm8a6qyXBrSpAKnm5YYLjZIHS2UC57G-Isw=s64","userId":"08142163190830893513"}},"outputId":"46fca286-975e-4207-dc97-41c96aa0401c"},"source":["%cd /content/gdrive/MyDrive/Colab\\ Notebooks/LidarObjectDetection/VoxelNet\n","%pycat model.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Notebooks/LidarObjectDetection/VoxelNet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XA2rf-i4SABd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623808097958,"user_tz":-540,"elapsed":18,"user":{"displayName":"kyungpyo kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifa6EEm8a6qyXBrSpAKnm5YYLjZIHS2UC57G-Isw=s64","userId":"08142163190830893513"}},"outputId":"e57798bd-7ca5-4d7a-d7ad-5a6284546e0b"},"source":["%%writefile model.py\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","from torch.autograd import Variable\n","from config import config as cfg\n","\n","# conv2d + bn + relu\n","class Conv2d(nn.Module):\n","\n","    def __init__(self,in_channels,out_channels,k,s,p, activation=True, batch_norm=True):\n","        super(Conv2d, self).__init__()\n","        self.conv = nn.Conv2d(in_channels,out_channels,kernel_size=k,stride=s,padding=p)\n","        if batch_norm:\n","            self.bn = nn.BatchNorm2d(out_channels)\n","        else:\n","            self.bn = None\n","        self.activation = activation\n","    def forward(self,x):\n","        x = self.conv(x)\n","        if self.bn is not None:\n","            x=self.bn(x)\n","        if self.activation:\n","            return F.relu(x,inplace=True)\n","        else:\n","            return x\n","\n","# conv3d + bn + relu\n","class Conv3d(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels, k, s, p, batch_norm=True):\n","        super(Conv3d, self).__init__()\n","        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=k, stride=s, padding=p)\n","        if batch_norm:\n","            self.bn = nn.BatchNorm3d(out_channels)\n","        else:\n","            self.bn = None\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        if self.bn is not None:\n","            x = self.bn(x)\n","\n","        return F.relu(x, inplace=True)\n","\n","# Fully Connected Network\n","class FCN(nn.Module):\n","\n","    def __init__(self,cin,cout):\n","        \"\"\"\n","        cin: input\n","        cout: output\n","        \"\"\"\n","        super(FCN, self).__init__()\n","        self.cout = cout\n","        self.linear = nn.Linear(cin, cout)\n","        self.bn = nn.BatchNorm1d(cout)\n","\n","    def forward(self,x):\n","        # KK is the stacked k across batch\n","        kk, t, _ = x.shape\n","        x = self.linear(x.view(kk*t,-1))\n","        x = F.relu(self.bn(x))\n","        return x.view(kk,t,-1)\n","\n","# Voxel Feature Encoding layer\n","class VFE(nn.Module):\n","\n","    def __init__(self,cin,cout):\n","        \"\"\"\n","        self.units: half of cout (number of features)\n","        \"\"\"\n","        super(VFE, self).__init__()\n","        assert cout % 2 == 0\n","        self.units = cout // 2\n","        self.fcn = FCN(cin,self.units)\n","\n","    def forward(self, x, mask):\n","        pointWiseFeature = self.fcn(x)\n","        # [VoxelNum, MaxPtsNum, units]\n","\n","        localAggrFeature = torch.max(pointWiseFeature,1, keepdim=True)[0]\n","        # [VoxelNum, 1, units]\n","        \n","        pointWiseConcat = torch.cat((pointWiseFeature, localAggrFeature),dim=2)\n","        # [VoxelNum, MaxPtsNum, 2*units]\n","\n","        # apply mask\n","        mask = mask.unsqueeze(2).repeat(1, 1, self.units * 2)\n","        pointWiseConcat = pointWiseConcat * mask.float()\n","\n","        return pointWiseConcat\n","\n","# Stacked Voxel Feature Encoding\n","class SVFE(nn.Module):\n","\n","    def __init__(self):\n","        super(SVFE, self).__init__()\n","        self.vfe_1 = VFE(7,32)\n","        self.vfe_2 = VFE(32,128)\n","        self.fcn = FCN(128,128)\n","    def forward(self, x):\n","        # x: [VoxelNum, MaxPtsNum, 7]\n","\n","        # masking for making sparse tensor\n","        mask = torch.ne(torch.max(x,2)[0], 0)\n","        \n","        x = self.vfe_1(x, mask)\n","        # x: [VoxelNum, MaxPtsNum, 32]\n","\n","        x = self.vfe_2(x, mask)\n","        # x: [VoxelNum, MaxPtsNum, 128]\n","\n","        x = self.fcn(x)\n","        # x: [VoxelNum, MaxPtsNum, 128]\n","\n","        # element-wise max pooling\n","        x = torch.max(x,1)[0]\n","        # x: [VoxelNum, 128]\n","\n","        return x\n","\n","# Convolutional Middle Layer\n","class CML(nn.Module):\n","    def __init__(self):\n","        super(CML, self).__init__()\n","        self.conv3d_1 = Conv3d(128, 64, 3, s=(2, 1, 1), p=(1, 1, 1))\n","        self.conv3d_2 = Conv3d(64, 64, 3, s=(1, 1, 1), p=(0, 1, 1))\n","        self.conv3d_3 = Conv3d(64, 64, 3, s=(2, 1, 1), p=(1, 1, 1))\n","\n","    def forward(self, x):\n","        x = self.conv3d_1(x)\n","        x = self.conv3d_2(x)\n","        x = self.conv3d_3(x)\n","        return x\n","\n","# Region Proposal Network\n","class RPN(nn.Module):\n","    def __init__(self):\n","        super(RPN, self).__init__()\n","        self.block_1 = [Conv2d(128, 128, 3, 2, 1)]\n","        self.block_1 += [Conv2d(128, 128, 3, 1, 1) for _ in range(3)]\n","        self.block_1 = nn.Sequential(*self.block_1)\n","\n","        self.block_2 = [Conv2d(128, 128, 3, 2, 1)]\n","        self.block_2 += [Conv2d(128, 128, 3, 1, 1) for _ in range(5)]\n","        self.block_2 = nn.Sequential(*self.block_2)\n","\n","        self.block_3 = [Conv2d(128, 256, 3, 2, 1)]\n","        self.block_3 += [nn.Conv2d(256, 256, 3, 1, 1) for _ in range(5)]\n","        self.block_3 = nn.Sequential(*self.block_3)\n","\n","        self.deconv_1 = nn.Sequential(nn.ConvTranspose2d(256, 256, 4, 4, 0),nn.BatchNorm2d(256))\n","        self.deconv_2 = nn.Sequential(nn.ConvTranspose2d(128, 256, 2, 2, 0),nn.BatchNorm2d(256))\n","        self.deconv_3 = nn.Sequential(nn.ConvTranspose2d(128, 256, 1, 1, 0),nn.BatchNorm2d(256))\n","\n","        self.score_head = Conv2d(768, cfg.anchors_per_position, 1, 1, 0, activation=False, batch_norm=False)\n","        self.reg_head = Conv2d(768, 7 * cfg.anchors_per_position, 1, 1, 0, activation=False, batch_norm=False)\n","\n","    def forward(self,x):\n","        x = self.block_1(x)\n","        x_skip_1 = x\n","        x = self.block_2(x)\n","        x_skip_2 = x\n","        x = self.block_3(x)\n","        x_0 = self.deconv_1(x)\n","        x_1 = self.deconv_2(x_skip_2)\n","        x_2 = self.deconv_3(x_skip_1)\n","        x = torch.cat((x_0,x_1,x_2),1)\n","        return self.score_head(x),self.reg_head(x)\n","\n","\n","class VoxelNet(nn.Module):\n","\n","    def __init__(self):\n","        super(VoxelNet, self).__init__()\n","        self.svfe = SVFE()\n","        self.cml = CML()\n","        self.rpn = RPN()\n","\n","    def voxel_indexing(self, sparse_features, coords):\n","        dim = sparse_features.shape[-1]\n","\n","        dense_feature = Variable(torch.zeros(dim, cfg.N, cfg.D, cfg.H, cfg.W).cuda())\n","\n","        dense_feature[:, coords[:,0], coords[:,1], coords[:,2], coords[:,3]]= sparse_features\n","\n","        return dense_feature.transpose(0, 1)\n","\n","    def forward(self, voxel_features, voxel_coords):\n","\n","        # feature learning network\n","        vwfs = self.svfe(voxel_features)\n","        vwfs = self.voxel_indexing(vwfs,voxel_coords)\n","\n","        # convolutional middle network\n","        cml_out = self.cml(vwfs)\n","\n","        # region proposal network\n","\n","        # merge the depth and feature dim into one, output probability score map and regression map\n","        psm,rm = self.rpn(cml_out.view(cfg.N,-1,cfg.H, cfg.W))\n","\n","        return psm, rm\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting model.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZGQ2zLj1LCPn","executionInfo":{"status":"ok","timestamp":1623808099459,"user_tz":-540,"elapsed":388,"user":{"displayName":"kyungpyo kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifa6EEm8a6qyXBrSpAKnm5YYLjZIHS2UC57G-Isw=s64","userId":"08142163190830893513"}},"outputId":"7bd20ace-0e8b-4ba8-9433-86451c57e1ad"},"source":["%cd /content/gdrive/MyDrive/Colab\\ Notebooks/LidarObjectDetection/VoxelNet\n","\n","from model import VoxelNet\n","\n","voxelnet = VoxelNet()\n","print(voxelnet)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["VoxelNet(\n","  (svfe): SVFE(\n","    (vfe_1): VFE(\n","      (fcn): FCN(\n","        (linear): Linear(in_features=7, out_features=16, bias=True)\n","        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (vfe_2): VFE(\n","      (fcn): FCN(\n","        (linear): Linear(in_features=32, out_features=64, bias=True)\n","        (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (fcn): FCN(\n","      (linear): Linear(in_features=128, out_features=128, bias=True)\n","      (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (cml): CML(\n","    (conv3d_1): Conv3d(\n","      (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n","      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (conv3d_2): Conv3d(\n","      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n","      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (conv3d_3): Conv3d(\n","      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 1, 1), padding=(1, 1, 1))\n","      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (rpn): RPN(\n","    (block_1): Sequential(\n","      (0): Conv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): Conv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): Conv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): Conv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (block_2): Sequential(\n","      (0): Conv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): Conv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): Conv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): Conv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (4): Conv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (5): Conv2d(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (block_3): Sequential(\n","      (0): Conv2d(\n","        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (deconv_1): Sequential(\n","      (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (deconv_2): Sequential(\n","      (0): ConvTranspose2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (deconv_3): Sequential(\n","      (0): ConvTranspose2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (score_head): Conv2d(\n","      (conv): Conv2d(768, 2, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (reg_head): Conv2d(\n","      (conv): Conv2d(768, 14, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2T4Ej4bB_dYm","executionInfo":{"status":"ok","timestamp":1623816484189,"user_tz":-540,"elapsed":309,"user":{"displayName":"kyungpyo kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifa6EEm8a6qyXBrSpAKnm5YYLjZIHS2UC57G-Isw=s64","userId":"08142163190830893513"}},"outputId":"15addc66-4c2b-4b2e-b87d-5d0ab00eb81d"},"source":["%cd /content/gdrive/MyDrive/Colab\\ Notebooks/LidarObjectDetection/VoxelNet\n","%pycat loss.py"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Notebooks/LidarObjectDetection/VoxelNet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BhUxV6WBVhw9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623816486446,"user_tz":-540,"elapsed":424,"user":{"displayName":"kyungpyo kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifa6EEm8a6qyXBrSpAKnm5YYLjZIHS2UC57G-Isw=s64","userId":"08142163190830893513"}},"outputId":"1d2991cb-d86c-40e7-83d5-b288f6116c12"},"source":["%%writefile loss.py\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class VoxelNetLoss(nn.Module):\n","    def __init__(self, alpha, beta):\n","        super(VoxelLoss, self).__init__()\n","        self.smoothl1loss = nn.SmoothL1Loss(size_average=False)\n","        self.alpha = alpha\n","        self.beta = beta\n","\n","    def forward(self, rm, psm, pos_equal_one, neg_equal_one, targets):\n","\n","        p_pos = F.sigmoid(psm.permute(0,2,3,1))\n","        rm = rm.permute(0,2,3,1).contiguous()\n","        rm = rm.view(rm.size(0),rm.size(1),rm.size(2),-1,7)\n","        targets = targets.view(targets.size(0),targets.size(1),targets.size(2),-1,7)\n","        pos_equal_one_for_reg = pos_equal_one.unsqueeze(pos_equal_one.dim()).expand(-1,-1,-1,-1,7)\n","\n","        rm_pos = rm * pos_equal_one_for_reg\n","        targets_pos = targets * pos_equal_one_for_reg\n","\n","        cls_pos_loss = -pos_equal_one * torch.log(p_pos + 1e-6)\n","        cls_pos_loss = cls_pos_loss.sum() / (pos_equal_one.sum() + 1e-6)\n","\n","        cls_neg_loss = -neg_equal_one * torch.log(1 - p_pos + 1e-6)\n","        cls_neg_loss = cls_neg_loss.sum() / (neg_equal_one.sum() + 1e-6)\n","\n","        reg_loss = self.smoothl1loss(rm_pos, targets_pos)\n","        reg_loss = reg_loss / (pos_equal_one.sum() + 1e-6)\n","        conf_loss = self.alpha * cls_pos_loss + self.beta * cls_neg_loss\n","        return conf_loss, reg_loss\n","\n","\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Overwriting loss.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rQm0798V_md1"},"source":[""],"execution_count":null,"outputs":[]}]}