{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VoxelNetTrain.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyP5sx1PA5KsRA25fTTwkNUa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dy1FfBWQTYVU","executionInfo":{"status":"ok","timestamp":1627038800616,"user_tz":-540,"elapsed":2729,"user":{"displayName":"kyungpyo kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifa6EEm8a6qyXBrSpAKnm5YYLjZIHS2UC57G-Isw=s64","userId":"08142163190830893513"}},"outputId":"afdefd86-a2bc-4715-d51c-a895c1fb8fc7"},"source":["import torch\n","print(torch.__version__)\n","print(torch.version.cuda)\n","!nvcc --version\n","# !pip install cloud-tpu-client==0.10 -q\n","# !pip install https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.12.1-cp37-cp37m-linux_x86_64.whl -q"],"execution_count":1,"outputs":[{"output_type":"stream","text":["1.9.0+cu102\n","10.2\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Wed_Jul_22_19:09:09_PDT_2020\n","Cuda compilation tools, release 11.0, V11.0.221\n","Build cuda_11.0_bu.TC445_37.28845127_0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YI_ewrFDlqzt","executionInfo":{"status":"ok","timestamp":1627038800617,"user_tz":-540,"elapsed":6,"user":{"displayName":"kyungpyo kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifa6EEm8a6qyXBrSpAKnm5YYLjZIHS2UC57G-Isw=s64","userId":"08142163190830893513"}}},"source":["%load_ext autoreload\n","%autoreload 2 "],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqfuKxo8hFKC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627038825931,"user_tz":-540,"elapsed":25319,"user":{"displayName":"kyungpyo kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifa6EEm8a6qyXBrSpAKnm5YYLjZIHS2UC57G-Isw=s64","userId":"08142163190830893513"}},"outputId":"3ce4b897-4bc5-4502-cbb7-00d0dee20ce7"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive/')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AC9kIv6NJfVH","executionInfo":{"status":"ok","timestamp":1627038826852,"user_tz":-540,"elapsed":926,"user":{"displayName":"kyungpyo kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gifa6EEm8a6qyXBrSpAKnm5YYLjZIHS2UC57G-Isw=s64","userId":"08142163190830893513"}},"outputId":"19e7a2f6-3133-4329-f80d-a4409449e52f"},"source":["%cd /content/gdrive/MyDrive/Colab\\ Notebooks/LidarObjectDetection/VoxelNet"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Notebooks/LidarObjectDetection/VoxelNet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sfbBBzsNeyKy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eaa3eede-cba7-4342-a427-12f65999ac07"},"source":["!sudo rm -rf ~/.nv\n","!python train.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1699 || Loss: 0.9341 || Conf Loss: 0.9341 || Regression Loss: 0.0000\n","Timer: 0.5950 sec.\n","tensor(2.4594, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1700 || Loss: 4.5083 || Conf Loss: 2.0489 || Regression Loss: 2.4594\n","Timer: 0.5812 sec.\n","tensor(1.5653, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1701 || Loss: 4.6422 || Conf Loss: 3.0769 || Regression Loss: 1.5653\n","Timer: 0.5034 sec.\n","tensor(3.2864, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1702 || Loss: 5.7814 || Conf Loss: 2.4950 || Regression Loss: 3.2864\n","Timer: 0.5223 sec.\n","tensor(5.7996, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1703 || Loss: 7.6004 || Conf Loss: 1.8008 || Regression Loss: 5.7996\n","Timer: 0.5171 sec.\n","tensor(3.1641, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1704 || Loss: 5.6662 || Conf Loss: 2.5022 || Regression Loss: 3.1641\n","Timer: 0.5178 sec.\n","tensor(3.7726, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1705 || Loss: 6.2388 || Conf Loss: 2.4661 || Regression Loss: 3.7726\n","Timer: 0.5617 sec.\n","tensor(4.7317, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1706 || Loss: 6.4068 || Conf Loss: 1.6751 || Regression Loss: 4.7317\n","Timer: 0.4621 sec.\n","tensor(2.8157, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1707 || Loss: 4.7944 || Conf Loss: 1.9787 || Regression Loss: 2.8157\n","Timer: 0.5253 sec.\n","tensor(1.2660, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1708 || Loss: 3.1598 || Conf Loss: 1.8938 || Regression Loss: 1.2660\n","Timer: 0.5748 sec.\n","tensor(0.5047, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1709 || Loss: 2.3254 || Conf Loss: 1.8206 || Regression Loss: 0.5047\n","Timer: 0.5803 sec.\n","tensor(5.9430, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1710 || Loss: 7.7059 || Conf Loss: 1.7629 || Regression Loss: 5.9430\n","Timer: 0.6205 sec.\n","tensor(3.2408, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1711 || Loss: 5.8268 || Conf Loss: 2.5861 || Regression Loss: 3.2408\n","Timer: 0.6033 sec.\n","tensor(3.8947, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1712 || Loss: 5.6318 || Conf Loss: 1.7371 || Regression Loss: 3.8947\n","Timer: 0.5447 sec.\n","tensor(3.3179, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1713 || Loss: 5.8945 || Conf Loss: 2.5767 || Regression Loss: 3.3179\n","Timer: 0.4823 sec.\n","tensor(5.0480, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1714 || Loss: 6.7923 || Conf Loss: 1.7443 || Regression Loss: 5.0480\n","Timer: 0.5864 sec.\n","tensor(1.6998, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1715 || Loss: 4.8444 || Conf Loss: 3.1447 || Regression Loss: 1.6998\n","Timer: 0.5887 sec.\n","tensor(5.4197, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1716 || Loss: 7.2538 || Conf Loss: 1.8341 || Regression Loss: 5.4197\n","Timer: 0.6015 sec.\n","tensor(5.2767, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1717 || Loss: 7.0237 || Conf Loss: 1.7470 || Regression Loss: 5.2767\n","Timer: 0.5556 sec.\n","tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1718 || Loss: 2.1228 || Conf Loss: 1.8904 || Regression Loss: 0.2325\n","Timer: 0.5161 sec.\n","tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1719 || Loss: 1.8588 || Conf Loss: 1.7829 || Regression Loss: 0.0759\n","Timer: 0.5912 sec.\n","tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1720 || Loss: 2.0647 || Conf Loss: 1.7649 || Regression Loss: 0.2998\n","Timer: 0.5115 sec.\n","tensor(0.0833, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1721 || Loss: 1.7705 || Conf Loss: 1.6872 || Regression Loss: 0.0833\n","Timer: 0.5599 sec.\n","tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1722 || Loss: 1.9413 || Conf Loss: 1.8653 || Regression Loss: 0.0761\n","Timer: 0.5498 sec.\n","tensor(6.3765, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1723 || Loss: 8.7003 || Conf Loss: 2.3238 || Regression Loss: 6.3765\n","Timer: 0.5047 sec.\n","tensor(2.0291, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1724 || Loss: 4.4954 || Conf Loss: 2.4664 || Regression Loss: 2.0291\n","Timer: 0.5291 sec.\n","tensor(1.1216, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1725 || Loss: 3.0919 || Conf Loss: 1.9703 || Regression Loss: 1.1216\n","Timer: 0.5599 sec.\n","tensor(1.6566, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1726 || Loss: 3.4745 || Conf Loss: 1.8179 || Regression Loss: 1.6566\n","Timer: 0.5339 sec.\n","tensor(1.9194, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1727 || Loss: 4.3333 || Conf Loss: 2.4139 || Regression Loss: 1.9194\n","Timer: 0.5009 sec.\n","tensor(3.9611, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1728 || Loss: 6.5388 || Conf Loss: 2.5777 || Regression Loss: 3.9611\n","Timer: 0.5740 sec.\n","tensor(3.2192, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1729 || Loss: 5.2929 || Conf Loss: 2.0737 || Regression Loss: 3.2192\n","Timer: 0.6425 sec.\n","tensor(3.6847, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1730 || Loss: 5.4592 || Conf Loss: 1.7746 || Regression Loss: 3.6847\n","Timer: 0.5700 sec.\n","tensor(2.9409, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1731 || Loss: 4.9978 || Conf Loss: 2.0569 || Regression Loss: 2.9409\n","Timer: 0.5952 sec.\n","tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1732 || Loss: 1.8810 || Conf Loss: 1.8161 || Regression Loss: 0.0649\n","Timer: 0.5736 sec.\n","tensor(0.0828, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1733 || Loss: 1.7334 || Conf Loss: 1.6505 || Regression Loss: 0.0828\n","Timer: 0.6220 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1734 || Loss: 0.9422 || Conf Loss: 0.9422 || Regression Loss: 0.0000\n","Timer: 0.6261 sec.\n","tensor(1.9309, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1735 || Loss: 4.5138 || Conf Loss: 2.5829 || Regression Loss: 1.9309\n","Timer: 0.5360 sec.\n","tensor(0.0883, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1736 || Loss: 1.9314 || Conf Loss: 1.8431 || Regression Loss: 0.0883\n","Timer: 0.5800 sec.\n","tensor(1.5348, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1737 || Loss: 4.4021 || Conf Loss: 2.8672 || Regression Loss: 1.5348\n","Timer: 0.7429 sec.\n","tensor(0.8592, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1738 || Loss: 3.8273 || Conf Loss: 2.9681 || Regression Loss: 0.8592\n","Timer: 0.5771 sec.\n","tensor(2.5853, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1739 || Loss: 6.1170 || Conf Loss: 3.5317 || Regression Loss: 2.5853\n","Timer: 0.6896 sec.\n","tensor(5.1643, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1740 || Loss: 7.1120 || Conf Loss: 1.9477 || Regression Loss: 5.1643\n","Timer: 0.5551 sec.\n","tensor(5.3606, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1741 || Loss: 7.1231 || Conf Loss: 1.7624 || Regression Loss: 5.3606\n","Timer: 0.5325 sec.\n","tensor(2.2225, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1742 || Loss: 4.0140 || Conf Loss: 1.7916 || Regression Loss: 2.2225\n","Timer: 0.5612 sec.\n","tensor(2.5666, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1743 || Loss: 6.3231 || Conf Loss: 3.7566 || Regression Loss: 2.5666\n","Timer: 0.5311 sec.\n","tensor(2.5769, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1744 || Loss: 4.8888 || Conf Loss: 2.3119 || Regression Loss: 2.5769\n","Timer: 0.5404 sec.\n","tensor(5.7501, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1745 || Loss: 7.5962 || Conf Loss: 1.8462 || Regression Loss: 5.7501\n","Timer: 0.5523 sec.\n","tensor(3.0429, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1746 || Loss: 5.1869 || Conf Loss: 2.1440 || Regression Loss: 3.0429\n","Timer: 0.5180 sec.\n","tensor(1.7630, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1747 || Loss: 3.7817 || Conf Loss: 2.0187 || Regression Loss: 1.7630\n","Timer: 0.4359 sec.\n","tensor(2.8196, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1748 || Loss: 4.7719 || Conf Loss: 1.9523 || Regression Loss: 2.8196\n","Timer: 0.5314 sec.\n","tensor(4.3121, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1749 || Loss: 6.1709 || Conf Loss: 1.8589 || Regression Loss: 4.3121\n","Timer: 0.5133 sec.\n","tensor(5.3891, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1750 || Loss: 7.2580 || Conf Loss: 1.8689 || Regression Loss: 5.3891\n","Timer: 0.6255 sec.\n","tensor(2.7556, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1751 || Loss: 4.6362 || Conf Loss: 1.8806 || Regression Loss: 2.7556\n","Timer: 0.5046 sec.\n","tensor(3.0263, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1752 || Loss: 5.1673 || Conf Loss: 2.1410 || Regression Loss: 3.0263\n","Timer: 0.5614 sec.\n","tensor(2.0970, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1753 || Loss: 3.8275 || Conf Loss: 1.7305 || Regression Loss: 2.0970\n","Timer: 0.5673 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1754 || Loss: 1.0034 || Conf Loss: 1.0034 || Regression Loss: 0.0000\n","Timer: 0.5489 sec.\n","tensor(4.1603, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1755 || Loss: 5.8950 || Conf Loss: 1.7347 || Regression Loss: 4.1603\n","Timer: 0.5391 sec.\n","tensor(5.3868, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1756 || Loss: 7.0745 || Conf Loss: 1.6877 || Regression Loss: 5.3868\n","Timer: 0.5601 sec.\n","tensor(4.9481, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1757 || Loss: 6.8041 || Conf Loss: 1.8559 || Regression Loss: 4.9481\n","Timer: 0.5479 sec.\n","tensor(1.5364, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1758 || Loss: 3.4422 || Conf Loss: 1.9058 || Regression Loss: 1.5364\n","Timer: 0.6016 sec.\n","tensor(1.9547, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1759 || Loss: 5.3667 || Conf Loss: 3.4119 || Regression Loss: 1.9547\n","Timer: 0.5684 sec.\n","tensor(3.6284, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1760 || Loss: 5.3660 || Conf Loss: 1.7376 || Regression Loss: 3.6284\n","Timer: 0.5678 sec.\n","tensor(0.2689, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1761 || Loss: 2.3122 || Conf Loss: 2.0433 || Regression Loss: 0.2689\n","Timer: 0.5198 sec.\n","tensor(0.0620, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1762 || Loss: 1.8503 || Conf Loss: 1.7883 || Regression Loss: 0.0620\n","Timer: 0.5423 sec.\n","tensor(0.5983, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1763 || Loss: 3.4899 || Conf Loss: 2.8916 || Regression Loss: 0.5983\n","Timer: 0.6433 sec.\n","tensor(0.1050, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1764 || Loss: 2.2085 || Conf Loss: 2.1036 || Regression Loss: 0.1050\n","Timer: 0.4919 sec.\n","tensor(2.4202, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1765 || Loss: 4.4710 || Conf Loss: 2.0508 || Regression Loss: 2.4202\n","Timer: 0.5546 sec.\n","tensor(0.4044, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1766 || Loss: 2.4641 || Conf Loss: 2.0597 || Regression Loss: 0.4044\n","Timer: 0.5299 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1767 || Loss: 0.9967 || Conf Loss: 0.9967 || Regression Loss: 0.0000\n","Timer: 0.5268 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1768 || Loss: 1.1118 || Conf Loss: 1.1118 || Regression Loss: 0.0000\n","Timer: 0.5729 sec.\n","tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1769 || Loss: 2.1841 || Conf Loss: 1.9984 || Regression Loss: 0.1857\n","Timer: 0.5833 sec.\n","tensor(5.2381, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1770 || Loss: 7.3268 || Conf Loss: 2.0887 || Regression Loss: 5.2381\n","Timer: 0.5142 sec.\n","tensor(2.3545, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1771 || Loss: 4.0801 || Conf Loss: 1.7256 || Regression Loss: 2.3545\n","Timer: 0.5070 sec.\n","tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1772 || Loss: 2.3096 || Conf Loss: 2.1155 || Regression Loss: 0.1941\n","Timer: 0.6190 sec.\n","tensor(3.0974, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1773 || Loss: 5.8385 || Conf Loss: 2.7411 || Regression Loss: 3.0974\n","Timer: 0.5602 sec.\n","tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1774 || Loss: 2.0372 || Conf Loss: 1.7899 || Regression Loss: 0.2472\n","Timer: 0.5934 sec.\n","tensor(5.4368, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1775 || Loss: 8.0237 || Conf Loss: 2.5869 || Regression Loss: 5.4368\n","Timer: 0.5350 sec.\n","tensor(4.5061, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1776 || Loss: 6.2244 || Conf Loss: 1.7183 || Regression Loss: 4.5061\n","Timer: 0.4940 sec.\n","tensor(2.3227, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1777 || Loss: 4.6203 || Conf Loss: 2.2976 || Regression Loss: 2.3227\n","Timer: 0.7148 sec.\n","tensor(3.9656, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1778 || Loss: 5.7310 || Conf Loss: 1.7654 || Regression Loss: 3.9656\n","Timer: 0.5082 sec.\n","tensor(0.1511, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1779 || Loss: 1.8663 || Conf Loss: 1.7152 || Regression Loss: 0.1511\n","Timer: 0.4895 sec.\n","tensor(3.0030, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1780 || Loss: 5.1433 || Conf Loss: 2.1403 || Regression Loss: 3.0030\n","Timer: 0.6615 sec.\n","tensor(1.4533, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1781 || Loss: 3.4060 || Conf Loss: 1.9527 || Regression Loss: 1.4533\n","Timer: 0.5339 sec.\n","tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1782 || Loss: 1.9269 || Conf Loss: 1.7118 || Regression Loss: 0.2151\n","Timer: 0.5193 sec.\n","tensor(5.4094, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1783 || Loss: 7.3472 || Conf Loss: 1.9378 || Regression Loss: 5.4094\n","Timer: 0.5475 sec.\n","tensor(1.6804, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1784 || Loss: 3.7761 || Conf Loss: 2.0957 || Regression Loss: 1.6804\n","Timer: 0.5561 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1785 || Loss: 0.9050 || Conf Loss: 0.9050 || Regression Loss: 0.0000\n","Timer: 0.5750 sec.\n","tensor(0.0615, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1786 || Loss: 1.7998 || Conf Loss: 1.7383 || Regression Loss: 0.0615\n","Timer: 0.5348 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1787 || Loss: 0.8890 || Conf Loss: 0.8890 || Regression Loss: 0.0000\n","Timer: 0.5486 sec.\n","tensor(0.2710, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1788 || Loss: 2.9026 || Conf Loss: 2.6317 || Regression Loss: 0.2710\n","Timer: 0.5734 sec.\n","tensor(3.6914, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1789 || Loss: 6.3249 || Conf Loss: 2.6335 || Regression Loss: 3.6914\n","Timer: 0.5605 sec.\n","tensor(3.8486, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1790 || Loss: 5.7189 || Conf Loss: 1.8703 || Regression Loss: 3.8486\n","Timer: 0.5068 sec.\n","tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1791 || Loss: 2.3924 || Conf Loss: 2.1706 || Regression Loss: 0.2218\n","Timer: 0.4894 sec.\n","tensor(3.0004, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1792 || Loss: 8.0799 || Conf Loss: 5.0795 || Regression Loss: 3.0004\n","Timer: 0.5355 sec.\n","tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1793 || Loss: 1.8846 || Conf Loss: 1.8172 || Regression Loss: 0.0674\n","Timer: 0.4890 sec.\n","tensor(3.6163, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1794 || Loss: 5.5302 || Conf Loss: 1.9139 || Regression Loss: 3.6163\n","Timer: 0.5651 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1795 || Loss: 1.0055 || Conf Loss: 1.0055 || Regression Loss: 0.0000\n","Timer: 0.5067 sec.\n","tensor(3.1065, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1796 || Loss: 4.9128 || Conf Loss: 1.8063 || Regression Loss: 3.1065\n","Timer: 0.5803 sec.\n","tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1797 || Loss: 2.2100 || Conf Loss: 1.8027 || Regression Loss: 0.4073\n","Timer: 0.4968 sec.\n","tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1798 || Loss: 2.0713 || Conf Loss: 1.9771 || Regression Loss: 0.0943\n","Timer: 0.4907 sec.\n","tensor(4.3181, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1799 || Loss: 6.4733 || Conf Loss: 2.1552 || Regression Loss: 4.3181\n","Timer: 0.6492 sec.\n","tensor(3.6971, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1800 || Loss: 5.5822 || Conf Loss: 1.8850 || Regression Loss: 3.6971\n","Timer: 0.6044 sec.\n","tensor(0.6419, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1801 || Loss: 3.0413 || Conf Loss: 2.3994 || Regression Loss: 0.6419\n","Timer: 0.5218 sec.\n","tensor(4.5713, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1802 || Loss: 6.3362 || Conf Loss: 1.7649 || Regression Loss: 4.5713\n","Timer: 0.5457 sec.\n","tensor(2.2450, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1803 || Loss: 7.1778 || Conf Loss: 4.9329 || Regression Loss: 2.2450\n","Timer: 0.7659 sec.\n","tensor(3.8043, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1804 || Loss: 5.8716 || Conf Loss: 2.0674 || Regression Loss: 3.8043\n","Timer: 0.5867 sec.\n","tensor(3.3322, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1805 || Loss: 5.2350 || Conf Loss: 1.9029 || Regression Loss: 3.3322\n","Timer: 0.6182 sec.\n","tensor(3.9184, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1806 || Loss: 5.7018 || Conf Loss: 1.7834 || Regression Loss: 3.9184\n","Timer: 0.4771 sec.\n","tensor(4.2500, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1807 || Loss: 6.2006 || Conf Loss: 1.9507 || Regression Loss: 4.2500\n","Timer: 0.5228 sec.\n","tensor(6.0932, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1808 || Loss: 7.8900 || Conf Loss: 1.7968 || Regression Loss: 6.0932\n","Timer: 0.5160 sec.\n","tensor(2.3235, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1809 || Loss: 4.0315 || Conf Loss: 1.7080 || Regression Loss: 2.3235\n","Timer: 0.5418 sec.\n","tensor(1.4887, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1810 || Loss: 3.2358 || Conf Loss: 1.7470 || Regression Loss: 1.4887\n","Timer: 0.5305 sec.\n","tensor(1.8964, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1811 || Loss: 3.8567 || Conf Loss: 1.9603 || Regression Loss: 1.8964\n","Timer: 0.5841 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1812 || Loss: 0.9130 || Conf Loss: 0.9130 || Regression Loss: 0.0000\n","Timer: 0.6787 sec.\n","tensor(2.4945, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1813 || Loss: 4.6393 || Conf Loss: 2.1448 || Regression Loss: 2.4945\n","Timer: 0.5430 sec.\n","tensor(1.9151, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1814 || Loss: 3.9248 || Conf Loss: 2.0097 || Regression Loss: 1.9151\n","Timer: 0.5650 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1815 || Loss: 0.9313 || Conf Loss: 0.9313 || Regression Loss: 0.0000\n","Timer: 0.5360 sec.\n","tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1816 || Loss: 1.9794 || Conf Loss: 1.7100 || Regression Loss: 0.2694\n","Timer: 0.5771 sec.\n","tensor(2.5700, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1817 || Loss: 6.9555 || Conf Loss: 4.3855 || Regression Loss: 2.5700\n","Timer: 0.5834 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1818 || Loss: 0.9771 || Conf Loss: 0.9771 || Regression Loss: 0.0000\n","Timer: 0.6161 sec.\n","tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1819 || Loss: 1.8981 || Conf Loss: 1.7186 || Regression Loss: 0.1795\n","Timer: 0.5034 sec.\n","tensor(5.5336, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1820 || Loss: 7.7525 || Conf Loss: 2.2189 || Regression Loss: 5.5336\n","Timer: 0.5846 sec.\n","tensor(4.5304, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1821 || Loss: 7.6406 || Conf Loss: 3.1103 || Regression Loss: 4.5304\n","Timer: 0.5438 sec.\n","tensor(4.0904, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1822 || Loss: 5.9680 || Conf Loss: 1.8776 || Regression Loss: 4.0904\n","Timer: 0.5305 sec.\n","tensor(0.0376, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1823 || Loss: 1.7613 || Conf Loss: 1.7237 || Regression Loss: 0.0376\n","Timer: 0.5362 sec.\n","tensor(3.6092, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1824 || Loss: 5.6685 || Conf Loss: 2.0593 || Regression Loss: 3.6092\n","Timer: 0.5171 sec.\n","tensor(0.5899, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1825 || Loss: 2.4796 || Conf Loss: 1.8896 || Regression Loss: 0.5899\n","Timer: 0.5576 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1826 || Loss: 0.9230 || Conf Loss: 0.9230 || Regression Loss: 0.0000\n","Timer: 0.4724 sec.\n","tensor(0.0715, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1827 || Loss: 2.0017 || Conf Loss: 1.9302 || Regression Loss: 0.0715\n","Timer: 0.5283 sec.\n","tensor(0.0692, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1828 || Loss: 1.9464 || Conf Loss: 1.8771 || Regression Loss: 0.0692\n","Timer: 0.5402 sec.\n","tensor(2.0091, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1829 || Loss: 5.7710 || Conf Loss: 3.7619 || Regression Loss: 2.0091\n","Timer: 0.5079 sec.\n","tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1830 || Loss: 1.9120 || Conf Loss: 1.7479 || Regression Loss: 0.1641\n","Timer: 0.5146 sec.\n","tensor(2.9723, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1831 || Loss: 4.7752 || Conf Loss: 1.8030 || Regression Loss: 2.9723\n","Timer: 0.4866 sec.\n","tensor(3.6396, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1832 || Loss: 6.3078 || Conf Loss: 2.6682 || Regression Loss: 3.6396\n","Timer: 0.5211 sec.\n","tensor(2.6205, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1833 || Loss: 4.4270 || Conf Loss: 1.8065 || Regression Loss: 2.6205\n","Timer: 0.5460 sec.\n","tensor(5.3770, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1834 || Loss: 7.1471 || Conf Loss: 1.7701 || Regression Loss: 5.3770\n","Timer: 0.5069 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1835 || Loss: 0.9162 || Conf Loss: 0.9162 || Regression Loss: 0.0000\n","Timer: 0.4687 sec.\n","tensor(0.8774, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1836 || Loss: 4.0612 || Conf Loss: 3.1838 || Regression Loss: 0.8774\n","Timer: 0.5189 sec.\n","tensor(5.3649, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1837 || Loss: 7.3714 || Conf Loss: 2.0065 || Regression Loss: 5.3649\n","Timer: 0.6746 sec.\n","tensor(0.9099, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1838 || Loss: 2.7514 || Conf Loss: 1.8415 || Regression Loss: 0.9099\n","Timer: 0.5770 sec.\n","tensor(2.2815, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1839 || Loss: 6.4074 || Conf Loss: 4.1259 || Regression Loss: 2.2815\n","Timer: 0.6124 sec.\n","tensor(6.1702, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1840 || Loss: 9.4195 || Conf Loss: 3.2494 || Regression Loss: 6.1702\n","Timer: 0.4790 sec.\n","tensor(1.2462, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1841 || Loss: 3.0444 || Conf Loss: 1.7982 || Regression Loss: 1.2462\n","Timer: 0.5622 sec.\n","tensor(1.3955, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1842 || Loss: 4.5597 || Conf Loss: 3.1643 || Regression Loss: 1.3955\n","Timer: 0.4204 sec.\n","tensor(3.6493, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1843 || Loss: 5.6405 || Conf Loss: 1.9912 || Regression Loss: 3.6493\n","Timer: 0.5421 sec.\n","tensor(1.3503, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1844 || Loss: 3.1117 || Conf Loss: 1.7614 || Regression Loss: 1.3503\n","Timer: 0.5206 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1845 || Loss: 1.0521 || Conf Loss: 1.0521 || Regression Loss: 0.0000\n","Timer: 0.6780 sec.\n","tensor(5.0061, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1846 || Loss: 8.8172 || Conf Loss: 3.8111 || Regression Loss: 5.0061\n","Timer: 0.5879 sec.\n","tensor(3.0442, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1847 || Loss: 5.6456 || Conf Loss: 2.6013 || Regression Loss: 3.0442\n","Timer: 0.4626 sec.\n","tensor(3.6461, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1848 || Loss: 6.4553 || Conf Loss: 2.8092 || Regression Loss: 3.6461\n","Timer: 0.5618 sec.\n","tensor(4.7301, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1849 || Loss: 6.5069 || Conf Loss: 1.7768 || Regression Loss: 4.7301\n","Timer: 0.5511 sec.\n","tensor(3.9863, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1850 || Loss: 6.4902 || Conf Loss: 2.5039 || Regression Loss: 3.9863\n","Timer: 0.5702 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1851 || Loss: 1.2637 || Conf Loss: 1.2637 || Regression Loss: 0.0000\n","Timer: 0.4918 sec.\n","tensor(1.4612, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1852 || Loss: 3.3438 || Conf Loss: 1.8826 || Regression Loss: 1.4612\n","Timer: 0.4919 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1853 || Loss: 0.9812 || Conf Loss: 0.9812 || Regression Loss: 0.0000\n","Timer: 0.5586 sec.\n","tensor(4.5480, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1854 || Loss: 6.4615 || Conf Loss: 1.9135 || Regression Loss: 4.5480\n","Timer: 0.5594 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1855 || Loss: 1.0389 || Conf Loss: 1.0389 || Regression Loss: 0.0000\n","Timer: 0.5736 sec.\n","tensor(3.2341, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1856 || Loss: 6.0880 || Conf Loss: 2.8538 || Regression Loss: 3.2341\n","Timer: 0.5989 sec.\n","tensor(3.3921, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1857 || Loss: 5.2354 || Conf Loss: 1.8434 || Regression Loss: 3.3921\n","Timer: 0.6076 sec.\n","tensor(2.5957, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1858 || Loss: 4.8082 || Conf Loss: 2.2126 || Regression Loss: 2.5957\n","Timer: 0.5705 sec.\n","tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1859 || Loss: 1.9937 || Conf Loss: 1.7554 || Regression Loss: 0.2382\n","Timer: 0.4910 sec.\n","tensor(3.7148, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1860 || Loss: 6.8501 || Conf Loss: 3.1354 || Regression Loss: 3.7148\n","Timer: 0.5588 sec.\n","tensor(5.7669, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1861 || Loss: 8.0608 || Conf Loss: 2.2939 || Regression Loss: 5.7669\n","Timer: 0.5666 sec.\n","tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1862 || Loss: 1.8598 || Conf Loss: 1.7852 || Regression Loss: 0.0745\n","Timer: 0.5326 sec.\n","tensor(2.1963, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1863 || Loss: 3.9814 || Conf Loss: 1.7851 || Regression Loss: 2.1963\n","Timer: 0.5314 sec.\n","tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1864 || Loss: 1.9728 || Conf Loss: 1.8898 || Regression Loss: 0.0829\n","Timer: 0.6778 sec.\n","tensor(3.7997, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1865 || Loss: 5.6274 || Conf Loss: 1.8276 || Regression Loss: 3.7997\n","Timer: 0.6146 sec.\n","tensor(1.5835, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1866 || Loss: 5.0115 || Conf Loss: 3.4281 || Regression Loss: 1.5835\n","Timer: 0.5506 sec.\n","tensor(1.7498, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1867 || Loss: 4.3615 || Conf Loss: 2.6118 || Regression Loss: 1.7498\n","Timer: 0.5921 sec.\n","tensor(2.1141, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1868 || Loss: 4.3243 || Conf Loss: 2.2101 || Regression Loss: 2.1141\n","Timer: 0.5710 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1869 || Loss: 1.3171 || Conf Loss: 1.3171 || Regression Loss: 0.0000\n","Timer: 0.5251 sec.\n","tensor(4.3883, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1870 || Loss: 6.1448 || Conf Loss: 1.7565 || Regression Loss: 4.3883\n","Timer: 0.5703 sec.\n","tensor(3.9821, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1871 || Loss: 6.3826 || Conf Loss: 2.4004 || Regression Loss: 3.9821\n","Timer: 0.5509 sec.\n","tensor(4.9372, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1872 || Loss: 6.6958 || Conf Loss: 1.7586 || Regression Loss: 4.9372\n","Timer: 0.7078 sec.\n","tensor(3.5801, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1873 || Loss: 5.4790 || Conf Loss: 1.8989 || Regression Loss: 3.5801\n","Timer: 0.5611 sec.\n","tensor(0.5329, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1874 || Loss: 2.3752 || Conf Loss: 1.8423 || Regression Loss: 0.5329\n","Timer: 0.5535 sec.\n","tensor(3.4831, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1875 || Loss: 5.6503 || Conf Loss: 2.1672 || Regression Loss: 3.4831\n","Timer: 0.5259 sec.\n","tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1876 || Loss: 2.0208 || Conf Loss: 1.7559 || Regression Loss: 0.2649\n","Timer: 0.5521 sec.\n","tensor(4.4750, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1877 || Loss: 6.1964 || Conf Loss: 1.7214 || Regression Loss: 4.4750\n","Timer: 0.5461 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1878 || Loss: 0.9370 || Conf Loss: 0.9370 || Regression Loss: 0.0000\n","Timer: 0.5773 sec.\n","tensor(1.6379, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1879 || Loss: 4.8604 || Conf Loss: 3.2224 || Regression Loss: 1.6379\n","Timer: 0.5933 sec.\n","tensor(0.7155, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1880 || Loss: 2.7964 || Conf Loss: 2.0809 || Regression Loss: 0.7155\n","Timer: 0.5275 sec.\n","tensor(2.4125, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1881 || Loss: 4.9615 || Conf Loss: 2.5490 || Regression Loss: 2.4125\n","Timer: 0.5845 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1882 || Loss: 1.1294 || Conf Loss: 1.1294 || Regression Loss: 0.0000\n","Timer: 0.4570 sec.\n","tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1883 || Loss: 1.9336 || Conf Loss: 1.7833 || Regression Loss: 0.1503\n","Timer: 2.3942 sec.\n","tensor(4.2523, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1884 || Loss: 5.9983 || Conf Loss: 1.7460 || Regression Loss: 4.2523\n","Timer: 0.5783 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1885 || Loss: 0.8195 || Conf Loss: 0.8195 || Regression Loss: 0.0000\n","Timer: 0.5673 sec.\n","tensor(1.8870, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1886 || Loss: 5.9060 || Conf Loss: 4.0191 || Regression Loss: 1.8870\n","Timer: 0.5883 sec.\n","tensor(2.8730, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1887 || Loss: 5.0955 || Conf Loss: 2.2225 || Regression Loss: 2.8730\n","Timer: 0.5821 sec.\n","tensor(5.4908, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1888 || Loss: 7.2540 || Conf Loss: 1.7632 || Regression Loss: 5.4908\n","Timer: 0.5867 sec.\n","tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1889 || Loss: 1.9712 || Conf Loss: 1.8728 || Regression Loss: 0.0984\n","Timer: 0.6287 sec.\n","tensor(3.2738, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1890 || Loss: 5.0637 || Conf Loss: 1.7899 || Regression Loss: 3.2738\n","Timer: 0.5348 sec.\n","tensor(5.8259, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1891 || Loss: 7.7709 || Conf Loss: 1.9450 || Regression Loss: 5.8259\n","Timer: 0.6345 sec.\n","tensor(8.2466, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1892 || Loss: 10.5362 || Conf Loss: 2.2895 || Regression Loss: 8.2466\n","Timer: 0.5990 sec.\n","tensor(1.0320, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1893 || Loss: 3.0026 || Conf Loss: 1.9706 || Regression Loss: 1.0320\n","Timer: 0.5818 sec.\n","tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1894 || Loss: 1.8330 || Conf Loss: 1.7131 || Regression Loss: 0.1199\n","Timer: 0.6919 sec.\n","tensor(2.2898, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1895 || Loss: 4.0482 || Conf Loss: 1.7583 || Regression Loss: 2.2898\n","Timer: 0.7148 sec.\n","tensor(4.7224, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1896 || Loss: 6.4064 || Conf Loss: 1.6840 || Regression Loss: 4.7224\n","Timer: 0.6004 sec.\n","tensor(1.5232, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1897 || Loss: 4.5010 || Conf Loss: 2.9778 || Regression Loss: 1.5232\n","Timer: 0.5449 sec.\n","tensor(1.6532, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1898 || Loss: 3.5050 || Conf Loss: 1.8518 || Regression Loss: 1.6532\n","Timer: 0.6071 sec.\n","tensor(0.1420, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1899 || Loss: 2.6683 || Conf Loss: 2.5263 || Regression Loss: 0.1420\n","Timer: 0.6001 sec.\n","tensor(5.2029, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1900 || Loss: 7.3759 || Conf Loss: 2.1729 || Regression Loss: 5.2029\n","Timer: 0.5764 sec.\n","tensor(3.6244, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1901 || Loss: 6.3740 || Conf Loss: 2.7496 || Regression Loss: 3.6244\n","Timer: 0.6485 sec.\n","tensor(2.2658, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1902 || Loss: 5.4946 || Conf Loss: 3.2288 || Regression Loss: 2.2658\n","Timer: 0.5342 sec.\n","tensor(0.3019, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1903 || Loss: 3.2062 || Conf Loss: 2.9043 || Regression Loss: 0.3019\n","Timer: 0.6665 sec.\n","tensor(2.4718, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1904 || Loss: 4.3863 || Conf Loss: 1.9145 || Regression Loss: 2.4718\n","Timer: 0.4841 sec.\n","tensor(4.4471, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1905 || Loss: 7.3829 || Conf Loss: 2.9358 || Regression Loss: 4.4471\n","Timer: 0.5295 sec.\n","tensor(5.3487, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1906 || Loss: 7.1797 || Conf Loss: 1.8310 || Regression Loss: 5.3487\n","Timer: 0.6265 sec.\n","tensor(3.9998, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1907 || Loss: 7.4434 || Conf Loss: 3.4436 || Regression Loss: 3.9998\n","Timer: 0.5720 sec.\n","tensor(3.4817, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1908 || Loss: 5.3603 || Conf Loss: 1.8785 || Regression Loss: 3.4817\n","Timer: 0.6467 sec.\n","tensor(1.2660, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1909 || Loss: 4.2053 || Conf Loss: 2.9393 || Regression Loss: 1.2660\n","Timer: 0.5848 sec.\n","tensor(4.9585, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1910 || Loss: 6.8470 || Conf Loss: 1.8885 || Regression Loss: 4.9585\n","Timer: 0.5638 sec.\n","tensor(2.4433, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1911 || Loss: 4.5679 || Conf Loss: 2.1246 || Regression Loss: 2.4433\n","Timer: 0.6510 sec.\n","tensor(3.1402, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1912 || Loss: 5.8381 || Conf Loss: 2.6979 || Regression Loss: 3.1402\n","Timer: 0.6070 sec.\n","tensor(0.5800, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1913 || Loss: 2.4292 || Conf Loss: 1.8491 || Regression Loss: 0.5800\n","Timer: 0.5352 sec.\n","tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1914 || Loss: 2.1059 || Conf Loss: 1.8156 || Regression Loss: 0.2903\n","Timer: 0.6124 sec.\n","tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1915 || Loss: 1.9485 || Conf Loss: 1.7814 || Regression Loss: 0.1671\n","Timer: 0.6853 sec.\n","tensor(2.9531, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1916 || Loss: 4.7459 || Conf Loss: 1.7928 || Regression Loss: 2.9531\n","Timer: 0.5754 sec.\n","tensor(1.7121, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1917 || Loss: 3.4882 || Conf Loss: 1.7761 || Regression Loss: 1.7121\n","Timer: 0.5724 sec.\n","tensor(0.0996, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1918 || Loss: 1.8169 || Conf Loss: 1.7173 || Regression Loss: 0.0996\n","Timer: 0.4948 sec.\n","tensor(2.1066, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1919 || Loss: 5.6539 || Conf Loss: 3.5473 || Regression Loss: 2.1066\n","Timer: 0.5768 sec.\n","tensor(4.7306, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1920 || Loss: 6.5002 || Conf Loss: 1.7696 || Regression Loss: 4.7306\n","Timer: 0.5888 sec.\n","tensor(3.8193, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1921 || Loss: 5.9212 || Conf Loss: 2.1019 || Regression Loss: 3.8193\n","Timer: 0.5963 sec.\n","tensor(1.0709, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1922 || Loss: 2.7917 || Conf Loss: 1.7208 || Regression Loss: 1.0709\n","Timer: 0.5876 sec.\n","tensor(4.4789, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1923 || Loss: 6.2283 || Conf Loss: 1.7494 || Regression Loss: 4.4789\n","Timer: 0.6011 sec.\n","tensor(0.8726, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1924 || Loss: 2.6618 || Conf Loss: 1.7892 || Regression Loss: 0.8726\n","Timer: 0.6020 sec.\n","tensor(2.2308, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1925 || Loss: 4.5197 || Conf Loss: 2.2890 || Regression Loss: 2.2308\n","Timer: 0.5883 sec.\n","tensor(5.8932, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1926 || Loss: 7.6151 || Conf Loss: 1.7219 || Regression Loss: 5.8932\n","Timer: 0.5806 sec.\n","tensor(0.6294, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1927 || Loss: 3.3015 || Conf Loss: 2.6721 || Regression Loss: 0.6294\n","Timer: 0.6352 sec.\n","tensor(2.0933, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1928 || Loss: 5.5671 || Conf Loss: 3.4738 || Regression Loss: 2.0933\n","Timer: 0.6145 sec.\n","tensor(1.9504, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1929 || Loss: 4.0807 || Conf Loss: 2.1303 || Regression Loss: 1.9504\n","Timer: 0.6628 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1930 || Loss: 1.0089 || Conf Loss: 1.0089 || Regression Loss: 0.0000\n","Timer: 0.7595 sec.\n","tensor(1.7347, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1931 || Loss: 4.8531 || Conf Loss: 3.1183 || Regression Loss: 1.7347\n","Timer: 0.5527 sec.\n","tensor(2.8792, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1932 || Loss: 4.8583 || Conf Loss: 1.9791 || Regression Loss: 2.8792\n","Timer: 0.5872 sec.\n","tensor(2.6968, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1933 || Loss: 4.9585 || Conf Loss: 2.2617 || Regression Loss: 2.6968\n","Timer: 0.5836 sec.\n","tensor(2.0747, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1934 || Loss: 7.0767 || Conf Loss: 5.0020 || Regression Loss: 2.0747\n","Timer: 0.6174 sec.\n","tensor(0.6968, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1935 || Loss: 3.0316 || Conf Loss: 2.3348 || Regression Loss: 0.6968\n","Timer: 0.6509 sec.\n","tensor(0.0791, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1936 || Loss: 1.9059 || Conf Loss: 1.8268 || Regression Loss: 0.0791\n","Timer: 0.5766 sec.\n","tensor(2.7534, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1937 || Loss: 9.8598 || Conf Loss: 7.1064 || Regression Loss: 2.7534\n","Timer: 0.6727 sec.\n","tensor(4.0615, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1938 || Loss: 6.8154 || Conf Loss: 2.7539 || Regression Loss: 4.0615\n","Timer: 0.5998 sec.\n","tensor(3.5994, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1939 || Loss: 6.1739 || Conf Loss: 2.5745 || Regression Loss: 3.5994\n","Timer: 0.5777 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1940 || Loss: 1.1438 || Conf Loss: 1.1438 || Regression Loss: 0.0000\n","Timer: 0.6412 sec.\n","tensor(0.5758, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1941 || Loss: 2.8535 || Conf Loss: 2.2777 || Regression Loss: 0.5758\n","Timer: 0.5628 sec.\n","tensor(4.6314, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1942 || Loss: 6.6982 || Conf Loss: 2.0668 || Regression Loss: 4.6314\n","Timer: 0.6497 sec.\n","tensor(2.3606, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1943 || Loss: 5.0350 || Conf Loss: 2.6743 || Regression Loss: 2.3606\n","Timer: 0.7052 sec.\n","tensor(0.9689, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1944 || Loss: 4.3979 || Conf Loss: 3.4290 || Regression Loss: 0.9689\n","Timer: 0.5867 sec.\n","tensor(2.7185, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1945 || Loss: 5.1451 || Conf Loss: 2.4266 || Regression Loss: 2.7185\n","Timer: 0.5848 sec.\n","tensor(0.2927, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1946 || Loss: 2.2654 || Conf Loss: 1.9728 || Regression Loss: 0.2927\n","Timer: 0.5840 sec.\n","tensor(6.1672, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1947 || Loss: 8.1231 || Conf Loss: 1.9558 || Regression Loss: 6.1672\n","Timer: 0.5427 sec.\n","tensor(0.6622, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1948 || Loss: 3.3784 || Conf Loss: 2.7162 || Regression Loss: 0.6622\n","Timer: 0.6138 sec.\n","tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1949 || Loss: 2.1855 || Conf Loss: 2.0117 || Regression Loss: 0.1738\n","Timer: 0.6336 sec.\n","tensor(3.3795, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1950 || Loss: 5.7370 || Conf Loss: 2.3575 || Regression Loss: 3.3795\n","Timer: 0.5558 sec.\n","tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1951 || Loss: 2.1349 || Conf Loss: 2.0224 || Regression Loss: 0.1125\n","Timer: 0.5813 sec.\n","tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1952 || Loss: 2.2015 || Conf Loss: 2.0831 || Regression Loss: 0.1184\n","Timer: 0.5570 sec.\n","tensor(0.1876, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1953 || Loss: 2.0305 || Conf Loss: 1.8429 || Regression Loss: 0.1876\n","Timer: 0.5788 sec.\n","tensor(3.2516, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1954 || Loss: 6.4687 || Conf Loss: 3.2172 || Regression Loss: 3.2516\n","Timer: 0.6725 sec.\n","tensor(2.9056, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1955 || Loss: 4.8288 || Conf Loss: 1.9232 || Regression Loss: 2.9056\n","Timer: 0.5693 sec.\n","tensor(3.1772, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1956 || Loss: 5.1622 || Conf Loss: 1.9850 || Regression Loss: 3.1772\n","Timer: 0.5868 sec.\n","tensor(1.7593, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1957 || Loss: 4.0800 || Conf Loss: 2.3207 || Regression Loss: 1.7593\n","Timer: 0.5855 sec.\n","tensor(5.2270, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1958 || Loss: 7.1625 || Conf Loss: 1.9354 || Regression Loss: 5.2270\n","Timer: 0.6832 sec.\n","tensor(0.1102, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1959 || Loss: 1.9309 || Conf Loss: 1.8207 || Regression Loss: 0.1102\n","Timer: 0.5446 sec.\n","tensor(8.9448, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1960 || Loss: 21.0450 || Conf Loss: 12.1002 || Regression Loss: 8.9448\n","Timer: 0.5658 sec.\n","tensor(0.4880, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1961 || Loss: 2.5822 || Conf Loss: 2.0942 || Regression Loss: 0.4880\n","Timer: 0.6246 sec.\n","tensor(1.5587, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1962 || Loss: 5.6570 || Conf Loss: 4.0982 || Regression Loss: 1.5587\n","Timer: 0.6308 sec.\n","tensor(7.6506, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1963 || Loss: 11.0841 || Conf Loss: 3.4335 || Regression Loss: 7.6506\n","Timer: 0.6776 sec.\n","tensor(15.2123, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1964 || Loss: 21.4720 || Conf Loss: 6.2597 || Regression Loss: 15.2123\n","Timer: 0.5648 sec.\n","tensor(7.5206, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1965 || Loss: 13.9763 || Conf Loss: 6.4557 || Regression Loss: 7.5206\n","Timer: 0.6071 sec.\n","tensor(6.6086, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1966 || Loss: 9.3557 || Conf Loss: 2.7471 || Regression Loss: 6.6086\n","Timer: 0.5631 sec.\n","tensor(3.0386, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1967 || Loss: 5.6153 || Conf Loss: 2.5767 || Regression Loss: 3.0386\n","Timer: 0.6470 sec.\n","tensor(1.2181, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1968 || Loss: 4.6578 || Conf Loss: 3.4398 || Regression Loss: 1.2181\n","Timer: 0.5239 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1969 || Loss: 0.8689 || Conf Loss: 0.8689 || Regression Loss: 0.0000\n","Timer: 0.5578 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1970 || Loss: 0.9567 || Conf Loss: 0.9567 || Regression Loss: 0.0000\n","Timer: 0.5455 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1971 || Loss: 0.8379 || Conf Loss: 0.8379 || Regression Loss: 0.0000\n","Timer: 0.6653 sec.\n","tensor(2.7509, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1972 || Loss: 7.2831 || Conf Loss: 4.5323 || Regression Loss: 2.7509\n","Timer: 0.6494 sec.\n","tensor(3.9642, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1973 || Loss: 6.9818 || Conf Loss: 3.0177 || Regression Loss: 3.9642\n","Timer: 0.5827 sec.\n","tensor(2.8955, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1974 || Loss: 5.3559 || Conf Loss: 2.4605 || Regression Loss: 2.8955\n","Timer: 0.5616 sec.\n","tensor(5.2803, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1975 || Loss: 7.7666 || Conf Loss: 2.4863 || Regression Loss: 5.2803\n","Timer: 0.7351 sec.\n","tensor(2.7753, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1976 || Loss: 7.1399 || Conf Loss: 4.3647 || Regression Loss: 2.7753\n","Timer: 0.5627 sec.\n","tensor(1.4825, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1977 || Loss: 3.9138 || Conf Loss: 2.4313 || Regression Loss: 1.4825\n","Timer: 0.7113 sec.\n","tensor(0.1237, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1978 || Loss: 2.3133 || Conf Loss: 2.1897 || Regression Loss: 0.1237\n","Timer: 0.6616 sec.\n","tensor(5.7415, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1979 || Loss: 8.1615 || Conf Loss: 2.4200 || Regression Loss: 5.7415\n","Timer: 0.6518 sec.\n","tensor(2.4974, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1980 || Loss: 4.6817 || Conf Loss: 2.1844 || Regression Loss: 2.4974\n","Timer: 0.6078 sec.\n","tensor(0.9062, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1981 || Loss: 3.8335 || Conf Loss: 2.9273 || Regression Loss: 0.9062\n","Timer: 0.5720 sec.\n","tensor(0.1519, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1982 || Loss: 2.2651 || Conf Loss: 2.1132 || Regression Loss: 0.1519\n","Timer: 0.5833 sec.\n","tensor(1.9508, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1983 || Loss: 4.2370 || Conf Loss: 2.2862 || Regression Loss: 1.9508\n","Timer: 0.6783 sec.\n","tensor(1.3482, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1984 || Loss: 3.4043 || Conf Loss: 2.0561 || Regression Loss: 1.3482\n","Timer: 0.6670 sec.\n","tensor(3.6380, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1985 || Loss: 5.9275 || Conf Loss: 2.2895 || Regression Loss: 3.6380\n","Timer: 0.5520 sec.\n","tensor(4.8293, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1986 || Loss: 7.0038 || Conf Loss: 2.1745 || Regression Loss: 4.8293\n","Timer: 0.5833 sec.\n","tensor(6.0533, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1987 || Loss: 11.5809 || Conf Loss: 5.5276 || Regression Loss: 6.0533\n","Timer: 0.7127 sec.\n","tensor(3.8650, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1988 || Loss: 7.2461 || Conf Loss: 3.3811 || Regression Loss: 3.8650\n","Timer: 0.5401 sec.\n","tensor(3.1508, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1989 || Loss: 5.2613 || Conf Loss: 2.1104 || Regression Loss: 3.1508\n","Timer: 0.5656 sec.\n","tensor(8.3610, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1990 || Loss: 10.9580 || Conf Loss: 2.5971 || Regression Loss: 8.3610\n","Timer: 0.7072 sec.\n","tensor(1.3123, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1991 || Loss: 3.3587 || Conf Loss: 2.0464 || Regression Loss: 1.3123\n","Timer: 0.6134 sec.\n","tensor(5.2401, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1992 || Loss: 7.4335 || Conf Loss: 2.1934 || Regression Loss: 5.2401\n","Timer: 0.5357 sec.\n","tensor(2.1174, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1993 || Loss: 7.0990 || Conf Loss: 4.9816 || Regression Loss: 2.1174\n","Timer: 0.5806 sec.\n","tensor(3.3501, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1994 || Loss: 5.5452 || Conf Loss: 2.1952 || Regression Loss: 3.3501\n","Timer: 0.5419 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1995 || Loss: 1.0681 || Conf Loss: 1.0681 || Regression Loss: 0.0000\n","Timer: 0.6494 sec.\n","tensor(2.4459, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1996 || Loss: 4.6164 || Conf Loss: 2.1704 || Regression Loss: 2.4459\n","Timer: 0.5789 sec.\n","tensor(2.6478, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1997 || Loss: 5.3625 || Conf Loss: 2.7147 || Regression Loss: 2.6478\n","Timer: 0.5714 sec.\n","tensor(3.0060, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1998 || Loss: 5.9584 || Conf Loss: 2.9524 || Regression Loss: 3.0060\n","Timer: 0.5792 sec.\n","tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 1999 || Loss: 2.0934 || Conf Loss: 1.9623 || Regression Loss: 0.1311\n","Timer: 0.5450 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2000 || Loss: 1.2106 || Conf Loss: 1.2106 || Regression Loss: 0.0000\n","Timer: 0.5896 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2001 || Loss: 1.0431 || Conf Loss: 1.0431 || Regression Loss: 0.0000\n","Timer: 0.5338 sec.\n","tensor(2.0955, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2002 || Loss: 4.2128 || Conf Loss: 2.1173 || Regression Loss: 2.0955\n","Timer: 0.6724 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2003 || Loss: 1.0307 || Conf Loss: 1.0307 || Regression Loss: 0.0000\n","Timer: 0.6175 sec.\n","tensor(2.9570, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2004 || Loss: 5.5971 || Conf Loss: 2.6400 || Regression Loss: 2.9570\n","Timer: 0.5981 sec.\n","tensor(5.1997, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2005 || Loss: 7.2576 || Conf Loss: 2.0579 || Regression Loss: 5.1997\n","Timer: 0.5883 sec.\n","tensor(5.1532, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2006 || Loss: 7.0632 || Conf Loss: 1.9100 || Regression Loss: 5.1532\n","Timer: 0.6552 sec.\n","tensor(1.2338, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2007 || Loss: 5.0120 || Conf Loss: 3.7782 || Regression Loss: 1.2338\n","Timer: 0.6226 sec.\n","tensor(0.8929, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2008 || Loss: 3.1624 || Conf Loss: 2.2695 || Regression Loss: 0.8929\n","Timer: 0.6204 sec.\n","tensor(0.0915, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2009 || Loss: 2.1078 || Conf Loss: 2.0163 || Regression Loss: 0.0915\n","Timer: 0.6345 sec.\n","tensor(4.5510, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2010 || Loss: 6.5445 || Conf Loss: 1.9934 || Regression Loss: 4.5510\n","Timer: 0.5421 sec.\n","tensor(5.7233, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2011 || Loss: 7.6553 || Conf Loss: 1.9321 || Regression Loss: 5.7233\n","Timer: 0.5424 sec.\n","tensor(5.5731, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2012 || Loss: 8.1648 || Conf Loss: 2.5917 || Regression Loss: 5.5731\n","Timer: 0.5596 sec.\n","tensor(0.0250, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2013 || Loss: 1.9940 || Conf Loss: 1.9690 || Regression Loss: 0.0250\n","Timer: 0.5927 sec.\n","tensor(3.4324, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2014 || Loss: 6.6516 || Conf Loss: 3.2193 || Regression Loss: 3.4324\n","Timer: 0.5674 sec.\n","tensor(4.9834, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2015 || Loss: 6.9571 || Conf Loss: 1.9737 || Regression Loss: 4.9834\n","Timer: 0.6044 sec.\n","tensor(3.2343, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2016 || Loss: 5.8526 || Conf Loss: 2.6183 || Regression Loss: 3.2343\n","Timer: 0.5713 sec.\n","tensor(12.3177, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2017 || Loss: 19.6601 || Conf Loss: 7.3424 || Regression Loss: 12.3177\n","Timer: 0.7867 sec.\n","tensor(0.0594, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2018 || Loss: 2.0520 || Conf Loss: 1.9926 || Regression Loss: 0.0594\n","Timer: 0.5799 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2019 || Loss: 1.0429 || Conf Loss: 1.0429 || Regression Loss: 0.0000\n","Timer: 0.5751 sec.\n","tensor(2.2402, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2020 || Loss: 6.2466 || Conf Loss: 4.0064 || Regression Loss: 2.2402\n","Timer: 0.5695 sec.\n","tensor(1.8602, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2021 || Loss: 5.7248 || Conf Loss: 3.8646 || Regression Loss: 1.8602\n","Timer: 0.6437 sec.\n","tensor(1.5018, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2022 || Loss: 3.5653 || Conf Loss: 2.0634 || Regression Loss: 1.5018\n","Timer: 0.6408 sec.\n","tensor(0.1358, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2023 || Loss: 2.1538 || Conf Loss: 2.0180 || Regression Loss: 0.1358\n","Timer: 0.5619 sec.\n","tensor(5.2504, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2024 || Loss: 7.1926 || Conf Loss: 1.9422 || Regression Loss: 5.2504\n","Timer: 0.6323 sec.\n","tensor(2.2919, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2025 || Loss: 7.7763 || Conf Loss: 5.4844 || Regression Loss: 2.2919\n","Timer: 0.6279 sec.\n","tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2026 || Loss: 2.3312 || Conf Loss: 2.0850 || Regression Loss: 0.2462\n","Timer: 0.5931 sec.\n","tensor(1.0356, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2027 || Loss: 4.1241 || Conf Loss: 3.0886 || Regression Loss: 1.0356\n","Timer: 0.6274 sec.\n","tensor(3.4212, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2028 || Loss: 6.4981 || Conf Loss: 3.0768 || Regression Loss: 3.4212\n","Timer: 0.6001 sec.\n","tensor(4.5596, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2029 || Loss: 7.1191 || Conf Loss: 2.5594 || Regression Loss: 4.5596\n","Timer: 0.5890 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2030 || Loss: 1.0814 || Conf Loss: 1.0814 || Regression Loss: 0.0000\n","Timer: 0.6051 sec.\n","tensor(2.8597, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2031 || Loss: 5.3006 || Conf Loss: 2.4409 || Regression Loss: 2.8597\n","Timer: 0.7029 sec.\n","tensor(5.4815, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2032 || Loss: 7.6803 || Conf Loss: 2.1988 || Regression Loss: 5.4815\n","Timer: 0.5437 sec.\n","tensor(3.5283, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2033 || Loss: 5.5443 || Conf Loss: 2.0160 || Regression Loss: 3.5283\n","Timer: 0.6615 sec.\n","tensor(2.7061, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2034 || Loss: 5.1631 || Conf Loss: 2.4570 || Regression Loss: 2.7061\n","Timer: 0.5768 sec.\n","tensor(3.2087, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2035 || Loss: 5.5998 || Conf Loss: 2.3912 || Regression Loss: 3.2087\n","Timer: 0.5818 sec.\n","tensor(4.2974, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2036 || Loss: 6.5127 || Conf Loss: 2.2153 || Regression Loss: 4.2974\n","Timer: 0.7533 sec.\n","tensor(0.1498, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2037 || Loss: 2.2138 || Conf Loss: 2.0640 || Regression Loss: 0.1498\n","Timer: 0.5521 sec.\n","tensor(2.9293, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2038 || Loss: 5.5207 || Conf Loss: 2.5914 || Regression Loss: 2.9293\n","Timer: 0.5910 sec.\n","tensor(5.4319, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2039 || Loss: 7.3738 || Conf Loss: 1.9419 || Regression Loss: 5.4319\n","Timer: 0.5372 sec.\n","tensor(5.3652, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2040 || Loss: 7.3720 || Conf Loss: 2.0068 || Regression Loss: 5.3652\n","Timer: 0.5567 sec.\n","tensor(2.7181, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2041 || Loss: 4.6863 || Conf Loss: 1.9682 || Regression Loss: 2.7181\n","Timer: 0.6284 sec.\n","tensor(54.2438, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2042 || Loss: 64.5264 || Conf Loss: 10.2826 || Regression Loss: 54.2438\n","Timer: 0.5723 sec.\n","tensor(2.8348, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2043 || Loss: 5.1080 || Conf Loss: 2.2732 || Regression Loss: 2.8348\n","Timer: 0.5596 sec.\n","tensor(12.1122, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2044 || Loss: 17.6681 || Conf Loss: 5.5559 || Regression Loss: 12.1122\n","Timer: 0.6750 sec.\n","tensor(4.3989, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2045 || Loss: 8.9338 || Conf Loss: 4.5349 || Regression Loss: 4.3989\n","Timer: 0.6023 sec.\n","tensor(2.6565, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2046 || Loss: 5.0764 || Conf Loss: 2.4199 || Regression Loss: 2.6565\n","Timer: 0.8082 sec.\n","tensor(1.1282, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2047 || Loss: 3.7129 || Conf Loss: 2.5848 || Regression Loss: 1.1282\n","Timer: 0.6669 sec.\n","tensor(3.1558, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2048 || Loss: 5.8785 || Conf Loss: 2.7228 || Regression Loss: 3.1558\n","Timer: 0.5355 sec.\n","tensor(2.4698, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2049 || Loss: 4.8179 || Conf Loss: 2.3481 || Regression Loss: 2.4698\n","Timer: 0.5719 sec.\n","tensor(5.2628, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2050 || Loss: 7.9210 || Conf Loss: 2.6582 || Regression Loss: 5.2628\n","Timer: 0.6456 sec.\n","tensor(1.5883, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2051 || Loss: 3.8165 || Conf Loss: 2.2282 || Regression Loss: 1.5883\n","Timer: 0.7279 sec.\n","tensor(3.6826, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2052 || Loss: 6.5558 || Conf Loss: 2.8732 || Regression Loss: 3.6826\n","Timer: 0.6154 sec.\n","tensor(0.3645, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2053 || Loss: 2.7046 || Conf Loss: 2.3401 || Regression Loss: 0.3645\n","Timer: 0.5815 sec.\n","tensor(1.5681, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2054 || Loss: 3.7311 || Conf Loss: 2.1630 || Regression Loss: 1.5681\n","Timer: 0.7491 sec.\n","tensor(3.4660, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2055 || Loss: 5.6282 || Conf Loss: 2.1622 || Regression Loss: 3.4660\n","Timer: 0.6509 sec.\n","tensor(0.1514, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2056 || Loss: 2.1976 || Conf Loss: 2.0462 || Regression Loss: 0.1514\n","Timer: 0.6589 sec.\n","tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2057 || Loss: 2.1845 || Conf Loss: 2.0814 || Regression Loss: 0.1031\n","Timer: 0.5119 sec.\n","tensor(0.6566, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2058 || Loss: 2.6526 || Conf Loss: 1.9960 || Regression Loss: 0.6566\n","Timer: 0.6412 sec.\n","tensor(5.4971, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2059 || Loss: 7.5006 || Conf Loss: 2.0035 || Regression Loss: 5.4971\n","Timer: 0.5531 sec.\n","tensor(4.1014, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2060 || Loss: 6.2060 || Conf Loss: 2.1046 || Regression Loss: 4.1014\n","Timer: 0.5947 sec.\n","tensor(1.9164, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2061 || Loss: 6.4244 || Conf Loss: 4.5080 || Regression Loss: 1.9164\n","Timer: 0.5212 sec.\n","tensor(5.2675, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2062 || Loss: 7.5023 || Conf Loss: 2.2348 || Regression Loss: 5.2675\n","Timer: 0.6341 sec.\n","tensor(0.7449, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2063 || Loss: 2.9308 || Conf Loss: 2.1859 || Regression Loss: 0.7449\n","Timer: 0.7191 sec.\n","tensor(5.1029, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2064 || Loss: 7.5804 || Conf Loss: 2.4775 || Regression Loss: 5.1029\n","Timer: 0.6082 sec.\n","tensor(4.8383, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2065 || Loss: 7.0022 || Conf Loss: 2.1639 || Regression Loss: 4.8383\n","Timer: 0.6015 sec.\n","tensor(3.2162, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2066 || Loss: 5.2761 || Conf Loss: 2.0599 || Regression Loss: 3.2162\n","Timer: 0.5236 sec.\n","tensor(3.2113, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2067 || Loss: 5.1827 || Conf Loss: 1.9714 || Regression Loss: 3.2113\n","Timer: 0.5735 sec.\n","tensor(3.1745, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2068 || Loss: 5.2979 || Conf Loss: 2.1234 || Regression Loss: 3.1745\n","Timer: 0.5313 sec.\n","tensor(3.2540, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2069 || Loss: 5.7069 || Conf Loss: 2.4529 || Regression Loss: 3.2540\n","Timer: 0.5681 sec.\n","tensor(4.6692, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2070 || Loss: 6.8712 || Conf Loss: 2.2020 || Regression Loss: 4.6692\n","Timer: 0.6742 sec.\n","tensor(3.5856, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2071 || Loss: 8.0710 || Conf Loss: 4.4854 || Regression Loss: 3.5856\n","Timer: 0.6451 sec.\n","tensor(3.4155, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2072 || Loss: 7.4831 || Conf Loss: 4.0676 || Regression Loss: 3.4155\n","Timer: 0.5576 sec.\n","tensor(3.4211, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2073 || Loss: 5.4064 || Conf Loss: 1.9853 || Regression Loss: 3.4211\n","Timer: 0.6439 sec.\n","tensor(0.2021, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2074 || Loss: 2.2248 || Conf Loss: 2.0227 || Regression Loss: 0.2021\n","Timer: 0.5840 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2075 || Loss: 1.4096 || Conf Loss: 1.4096 || Regression Loss: 0.0000\n","Timer: 0.6129 sec.\n","tensor(1.8602, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2076 || Loss: 4.0695 || Conf Loss: 2.2093 || Regression Loss: 1.8602\n","Timer: 0.7224 sec.\n","tensor(3.4823, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2077 || Loss: 5.5278 || Conf Loss: 2.0455 || Regression Loss: 3.4823\n","Timer: 0.5448 sec.\n","tensor(1.7500, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2078 || Loss: 3.9542 || Conf Loss: 2.2042 || Regression Loss: 1.7500\n","Timer: 0.5914 sec.\n","tensor(2.8143, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2079 || Loss: 6.5382 || Conf Loss: 3.7238 || Regression Loss: 2.8143\n","Timer: 0.5851 sec.\n","tensor(5.1422, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2080 || Loss: 7.1403 || Conf Loss: 1.9980 || Regression Loss: 5.1422\n","Timer: 0.5463 sec.\n","tensor(4.2612, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2081 || Loss: 6.2241 || Conf Loss: 1.9629 || Regression Loss: 4.2612\n","Timer: 0.5424 sec.\n","tensor(3.7587, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2082 || Loss: 5.9270 || Conf Loss: 2.1682 || Regression Loss: 3.7587\n","Timer: 0.5870 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2083 || Loss: 1.3355 || Conf Loss: 1.3355 || Regression Loss: 0.0000\n","Timer: 0.5836 sec.\n","tensor(4.1918, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2084 || Loss: 6.2780 || Conf Loss: 2.0862 || Regression Loss: 4.1918\n","Timer: 0.6626 sec.\n","tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2085 || Loss: 2.0185 || Conf Loss: 1.9367 || Regression Loss: 0.0818\n","Timer: 0.5661 sec.\n","tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2086 || Loss: 2.1152 || Conf Loss: 1.9988 || Regression Loss: 0.1164\n","Timer: 0.5856 sec.\n","tensor(4.2951, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2087 || Loss: 6.5348 || Conf Loss: 2.2397 || Regression Loss: 4.2951\n","Timer: 0.6851 sec.\n","tensor(1.6225, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2088 || Loss: 3.7352 || Conf Loss: 2.1127 || Regression Loss: 1.6225\n","Timer: 0.5677 sec.\n","tensor(5.0822, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2089 || Loss: 7.0090 || Conf Loss: 1.9268 || Regression Loss: 5.0822\n","Timer: 0.5461 sec.\n","tensor(4.9055, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2090 || Loss: 6.9361 || Conf Loss: 2.0306 || Regression Loss: 4.9055\n","Timer: 0.6378 sec.\n","tensor(1.1032, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2091 || Loss: 3.0682 || Conf Loss: 1.9650 || Regression Loss: 1.1032\n","Timer: 0.5822 sec.\n","tensor(3.8391, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2092 || Loss: 6.0296 || Conf Loss: 2.1905 || Regression Loss: 3.8391\n","Timer: 0.5360 sec.\n","tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2093 || Loss: 2.1888 || Conf Loss: 1.9447 || Regression Loss: 0.2441\n","Timer: 0.5724 sec.\n","tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2094 || Loss: 2.0432 || Conf Loss: 1.8371 || Regression Loss: 0.2061\n","Timer: 0.6545 sec.\n","tensor(2.5932, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2095 || Loss: 4.4797 || Conf Loss: 1.8865 || Regression Loss: 2.5932\n","Timer: 0.5803 sec.\n","tensor(25.8634, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2096 || Loss: 32.8178 || Conf Loss: 6.9544 || Regression Loss: 25.8634\n","Timer: 0.5854 sec.\n","tensor(0.4958, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2097 || Loss: 2.6204 || Conf Loss: 2.1246 || Regression Loss: 0.4958\n","Timer: 0.5851 sec.\n","tensor(3.0051, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2098 || Loss: 5.0951 || Conf Loss: 2.0900 || Regression Loss: 3.0051\n","Timer: 0.6409 sec.\n","tensor(5.3541, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2099 || Loss: 7.3909 || Conf Loss: 2.0368 || Regression Loss: 5.3541\n","Timer: 0.6217 sec.\n","tensor(0.7682, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2100 || Loss: 3.5406 || Conf Loss: 2.7724 || Regression Loss: 0.7682\n","Timer: 0.5670 sec.\n","tensor(1.7183, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2101 || Loss: 3.8188 || Conf Loss: 2.1005 || Regression Loss: 1.7183\n","Timer: 0.6738 sec.\n","tensor(2.7392, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2102 || Loss: 4.6988 || Conf Loss: 1.9597 || Regression Loss: 2.7392\n","Timer: 0.6668 sec.\n","tensor(1.9238, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2103 || Loss: 6.2539 || Conf Loss: 4.3301 || Regression Loss: 1.9238\n","Timer: 0.5497 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2104 || Loss: 1.1927 || Conf Loss: 1.1927 || Regression Loss: 0.0000\n","Timer: 0.5392 sec.\n","tensor(2.2617, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2105 || Loss: 6.5547 || Conf Loss: 4.2930 || Regression Loss: 2.2617\n","Timer: 0.5604 sec.\n","tensor(5.4273, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2106 || Loss: 7.4612 || Conf Loss: 2.0339 || Regression Loss: 5.4273\n","Timer: 0.6051 sec.\n","tensor(1.5962, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2107 || Loss: 4.6864 || Conf Loss: 3.0902 || Regression Loss: 1.5962\n","Timer: 0.5536 sec.\n","tensor(3.2966, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2108 || Loss: 5.5688 || Conf Loss: 2.2722 || Regression Loss: 3.2966\n","Timer: 0.7467 sec.\n","tensor(5.2323, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2109 || Loss: 7.2614 || Conf Loss: 2.0291 || Regression Loss: 5.2323\n","Timer: 0.6496 sec.\n","tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2110 || Loss: 2.2648 || Conf Loss: 1.9494 || Regression Loss: 0.3153\n","Timer: 0.5917 sec.\n","tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2111 || Loss: 2.6248 || Conf Loss: 2.3124 || Regression Loss: 0.3124\n","Timer: 0.5714 sec.\n","tensor(3.3425, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2112 || Loss: 5.8230 || Conf Loss: 2.4805 || Regression Loss: 3.3425\n","Timer: 0.5634 sec.\n","tensor(4.6241, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2113 || Loss: 7.1929 || Conf Loss: 2.5688 || Regression Loss: 4.6241\n","Timer: 0.6376 sec.\n","tensor(5.0872, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2114 || Loss: 7.1628 || Conf Loss: 2.0756 || Regression Loss: 5.0872\n","Timer: 0.5845 sec.\n","tensor(3.5754, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2115 || Loss: 6.4131 || Conf Loss: 2.8377 || Regression Loss: 3.5754\n","Timer: 0.6642 sec.\n","tensor(9.2973, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2116 || Loss: 17.0475 || Conf Loss: 7.7502 || Regression Loss: 9.2973\n","Timer: 0.7105 sec.\n","tensor(1.4750, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2117 || Loss: 3.5407 || Conf Loss: 2.0657 || Regression Loss: 1.4750\n","Timer: 0.6561 sec.\n","tensor(2.7468, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2118 || Loss: 5.1656 || Conf Loss: 2.4188 || Regression Loss: 2.7468\n","Timer: 0.6086 sec.\n","tensor(3.8993, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2119 || Loss: 6.0800 || Conf Loss: 2.1807 || Regression Loss: 3.8993\n","Timer: 0.6218 sec.\n","tensor(3.6488, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2120 || Loss: 6.3493 || Conf Loss: 2.7005 || Regression Loss: 3.6488\n","Timer: 0.5853 sec.\n","tensor(1.2684, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2121 || Loss: 3.5695 || Conf Loss: 2.3011 || Regression Loss: 1.2684\n","Timer: 0.6217 sec.\n","tensor(7.4195, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2122 || Loss: 10.9430 || Conf Loss: 3.5234 || Regression Loss: 7.4195\n","Timer: 0.7297 sec.\n","tensor(0.1170, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2123 || Loss: 2.1659 || Conf Loss: 2.0488 || Regression Loss: 0.1170\n","Timer: 0.7164 sec.\n","tensor(0.6930, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2124 || Loss: 2.7812 || Conf Loss: 2.0882 || Regression Loss: 0.6930\n","Timer: 0.5751 sec.\n","tensor(4.2936, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2125 || Loss: 6.2421 || Conf Loss: 1.9485 || Regression Loss: 4.2936\n","Timer: 0.5747 sec.\n","tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2126 || Loss: 2.3440 || Conf Loss: 2.1481 || Regression Loss: 0.1959\n","Timer: 0.5913 sec.\n","tensor(3.7278, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2127 || Loss: 5.8646 || Conf Loss: 2.1368 || Regression Loss: 3.7278\n","Timer: 0.6980 sec.\n","tensor(4.2754, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2128 || Loss: 6.2605 || Conf Loss: 1.9851 || Regression Loss: 4.2754\n","Timer: 0.6625 sec.\n","tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2129 || Loss: 2.1279 || Conf Loss: 1.9804 || Regression Loss: 0.1475\n","Timer: 0.5833 sec.\n","tensor(1.8396, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2130 || Loss: 4.1089 || Conf Loss: 2.2692 || Regression Loss: 1.8396\n","Timer: 0.6281 sec.\n","tensor(2.1955, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2131 || Loss: 6.8783 || Conf Loss: 4.6828 || Regression Loss: 2.1955\n","Timer: 0.6893 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2132 || Loss: 1.3259 || Conf Loss: 1.3259 || Regression Loss: 0.0000\n","Timer: 0.5566 sec.\n","tensor(3.0867, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2133 || Loss: 5.0802 || Conf Loss: 1.9934 || Regression Loss: 3.0867\n","Timer: 0.5811 sec.\n","tensor(4.9582, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2134 || Loss: 7.0051 || Conf Loss: 2.0470 || Regression Loss: 4.9582\n","Timer: 0.5738 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2135 || Loss: 1.1770 || Conf Loss: 1.1770 || Regression Loss: 0.0000\n","Timer: 0.5939 sec.\n","tensor(5.8381, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2136 || Loss: 7.8046 || Conf Loss: 1.9665 || Regression Loss: 5.8381\n","Timer: 0.5865 sec.\n","tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2137 || Loss: 2.1380 || Conf Loss: 2.0366 || Regression Loss: 0.1015\n","Timer: 0.6415 sec.\n","tensor(5.3943, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2138 || Loss: 7.4430 || Conf Loss: 2.0487 || Regression Loss: 5.3943\n","Timer: 0.5940 sec.\n","tensor(2.6726, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2139 || Loss: 4.6323 || Conf Loss: 1.9597 || Regression Loss: 2.6726\n","Timer: 0.5527 sec.\n","tensor(2.8060, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2140 || Loss: 9.0945 || Conf Loss: 6.2885 || Regression Loss: 2.8060\n","Timer: 0.5520 sec.\n","tensor(0.1020, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2141 || Loss: 2.4500 || Conf Loss: 2.3480 || Regression Loss: 0.1020\n","Timer: 0.5547 sec.\n","tensor(3.0370, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2142 || Loss: 5.1431 || Conf Loss: 2.1061 || Regression Loss: 3.0370\n","Timer: 0.6486 sec.\n","tensor(5.3298, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2143 || Loss: 7.4160 || Conf Loss: 2.0862 || Regression Loss: 5.3298\n","Timer: 0.5578 sec.\n","tensor(3.5155, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2144 || Loss: 5.8501 || Conf Loss: 2.3346 || Regression Loss: 3.5155\n","Timer: 0.6025 sec.\n","tensor(3.2597, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2145 || Loss: 5.9176 || Conf Loss: 2.6579 || Regression Loss: 3.2597\n","Timer: 0.7112 sec.\n","tensor(3.7667, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2146 || Loss: 9.5889 || Conf Loss: 5.8222 || Regression Loss: 3.7667\n","Timer: 0.7169 sec.\n","tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2147 || Loss: 2.5210 || Conf Loss: 2.3619 || Regression Loss: 0.1591\n","Timer: 0.5946 sec.\n","tensor(0.2853, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2148 || Loss: 2.3410 || Conf Loss: 2.0557 || Regression Loss: 0.2853\n","Timer: 0.5716 sec.\n","tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2149 || Loss: 2.2222 || Conf Loss: 2.0328 || Regression Loss: 0.1894\n","Timer: 0.6241 sec.\n","tensor(2.3071, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2150 || Loss: 4.3130 || Conf Loss: 2.0059 || Regression Loss: 2.3071\n","Timer: 0.7168 sec.\n","tensor(5.7801, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2151 || Loss: 7.7107 || Conf Loss: 1.9306 || Regression Loss: 5.7801\n","Timer: 0.5189 sec.\n","tensor(3.8156, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2152 || Loss: 5.8955 || Conf Loss: 2.0799 || Regression Loss: 3.8156\n","Timer: 0.6571 sec.\n","tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2153 || Loss: 2.0881 || Conf Loss: 1.9593 || Regression Loss: 0.1288\n","Timer: 0.5967 sec.\n","tensor(2.5617, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2154 || Loss: 4.7717 || Conf Loss: 2.2100 || Regression Loss: 2.5617\n","Timer: 0.7191 sec.\n","tensor(2.6341, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2155 || Loss: 5.4000 || Conf Loss: 2.7659 || Regression Loss: 2.6341\n","Timer: 0.5828 sec.\n","tensor(5.5787, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2156 || Loss: 7.5644 || Conf Loss: 1.9857 || Regression Loss: 5.5787\n","Timer: 0.5403 sec.\n","tensor(2.8091, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2157 || Loss: 4.7785 || Conf Loss: 1.9694 || Regression Loss: 2.8091\n","Timer: 0.5350 sec.\n","tensor(2.2326, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2158 || Loss: 6.7347 || Conf Loss: 4.5021 || Regression Loss: 2.2326\n","Timer: 0.6501 sec.\n","tensor(4.1228, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2159 || Loss: 6.1136 || Conf Loss: 1.9908 || Regression Loss: 4.1228\n","Timer: 0.5705 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2160 || Loss: 1.1633 || Conf Loss: 1.1633 || Regression Loss: 0.0000\n","Timer: 0.7312 sec.\n","tensor(3.2350, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2161 || Loss: 5.2439 || Conf Loss: 2.0089 || Regression Loss: 3.2350\n","Timer: 0.6642 sec.\n","tensor(3.5566, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2162 || Loss: 5.8223 || Conf Loss: 2.2657 || Regression Loss: 3.5566\n","Timer: 0.5539 sec.\n","tensor(5.5205, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2163 || Loss: 7.5131 || Conf Loss: 1.9926 || Regression Loss: 5.5205\n","Timer: 0.5902 sec.\n","tensor(2.2884, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2164 || Loss: 6.6187 || Conf Loss: 4.3303 || Regression Loss: 2.2884\n","Timer: 0.6086 sec.\n","tensor(2.4101, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2165 || Loss: 6.0172 || Conf Loss: 3.6071 || Regression Loss: 2.4101\n","Timer: 0.5735 sec.\n","tensor(2.4200, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2166 || Loss: 4.6651 || Conf Loss: 2.2451 || Regression Loss: 2.4200\n","Timer: 0.5770 sec.\n","tensor(5.5954, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2167 || Loss: 7.5364 || Conf Loss: 1.9410 || Regression Loss: 5.5954\n","Timer: 0.5851 sec.\n","tensor(5.3410, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2168 || Loss: 7.2881 || Conf Loss: 1.9471 || Regression Loss: 5.3410\n","Timer: 0.6779 sec.\n","tensor(5.1809, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2169 || Loss: 10.5971 || Conf Loss: 5.4162 || Regression Loss: 5.1809\n","Timer: 0.5916 sec.\n","tensor(5.1335, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2170 || Loss: 7.1651 || Conf Loss: 2.0316 || Regression Loss: 5.1335\n","Timer: 0.5470 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2171 || Loss: 1.2479 || Conf Loss: 1.2479 || Regression Loss: 0.0000\n","Timer: 0.5570 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2172 || Loss: 1.3300 || Conf Loss: 1.3300 || Regression Loss: 0.0000\n","Timer: 0.5781 sec.\n","tensor(2.5063, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2173 || Loss: 6.0709 || Conf Loss: 3.5646 || Regression Loss: 2.5063\n","Timer: 0.6301 sec.\n","tensor(2.3948, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2174 || Loss: 5.2321 || Conf Loss: 2.8372 || Regression Loss: 2.3948\n","Timer: 0.5414 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2175 || Loss: 1.1922 || Conf Loss: 1.1922 || Regression Loss: 0.0000\n","Timer: 0.5581 sec.\n","tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2176 || Loss: 2.2736 || Conf Loss: 2.1176 || Regression Loss: 0.1560\n","Timer: 0.6137 sec.\n","tensor(4.5961, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2177 || Loss: 6.7639 || Conf Loss: 2.1679 || Regression Loss: 4.5961\n","Timer: 0.5884 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2178 || Loss: 1.0917 || Conf Loss: 1.0917 || Regression Loss: 0.0000\n","Timer: 0.5521 sec.\n","tensor(0.8568, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2179 || Loss: 3.9837 || Conf Loss: 3.1269 || Regression Loss: 0.8568\n","Timer: 0.5883 sec.\n","tensor(1.6959, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2180 || Loss: 3.8109 || Conf Loss: 2.1150 || Regression Loss: 1.6959\n","Timer: 0.5626 sec.\n","tensor(1.8847, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2181 || Loss: 5.9317 || Conf Loss: 4.0470 || Regression Loss: 1.8847\n","Timer: 0.5935 sec.\n","tensor(1.5562, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2182 || Loss: 4.0457 || Conf Loss: 2.4895 || Regression Loss: 1.5562\n","Timer: 0.5932 sec.\n","tensor(3.6006, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2183 || Loss: 6.1795 || Conf Loss: 2.5788 || Regression Loss: 3.6006\n","Timer: 0.6052 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2184 || Loss: 1.2528 || Conf Loss: 1.2528 || Regression Loss: 0.0000\n","Timer: 0.5781 sec.\n","tensor(1.3906, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2185 || Loss: 3.6271 || Conf Loss: 2.2365 || Regression Loss: 1.3906\n","Timer: 0.6183 sec.\n","tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2186 || Loss: 2.4780 || Conf Loss: 2.3489 || Regression Loss: 0.1291\n","Timer: 0.6418 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2187 || Loss: 1.1643 || Conf Loss: 1.1643 || Regression Loss: 0.0000\n","Timer: 0.5801 sec.\n","tensor(5.7480, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2188 || Loss: 7.7883 || Conf Loss: 2.0403 || Regression Loss: 5.7480\n","Timer: 0.6193 sec.\n","tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2189 || Loss: 2.1805 || Conf Loss: 2.0011 || Regression Loss: 0.1794\n","Timer: 0.7251 sec.\n","tensor(0.0602, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2190 || Loss: 2.0273 || Conf Loss: 1.9672 || Regression Loss: 0.0602\n","Timer: 0.5239 sec.\n","tensor(0.5973, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2191 || Loss: 2.5682 || Conf Loss: 1.9710 || Regression Loss: 0.5973\n","Timer: 0.6618 sec.\n","tensor(0.0717, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2192 || Loss: 2.0376 || Conf Loss: 1.9658 || Regression Loss: 0.0717\n","Timer: 0.5776 sec.\n","tensor(4.2056, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2193 || Loss: 6.1176 || Conf Loss: 1.9121 || Regression Loss: 4.2056\n","Timer: 0.5629 sec.\n","tensor(3.9135, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2194 || Loss: 7.8813 || Conf Loss: 3.9678 || Regression Loss: 3.9135\n","Timer: 0.7147 sec.\n","tensor(1.4173, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2195 || Loss: 5.1137 || Conf Loss: 3.6964 || Regression Loss: 1.4173\n","Timer: 0.5673 sec.\n","tensor(5.6820, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2196 || Loss: 7.7212 || Conf Loss: 2.0391 || Regression Loss: 5.6820\n","Timer: 0.5816 sec.\n","tensor(0.5116, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2197 || Loss: 2.7162 || Conf Loss: 2.2046 || Regression Loss: 0.5116\n","Timer: 0.5924 sec.\n","tensor(4.5145, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2198 || Loss: 6.6045 || Conf Loss: 2.0900 || Regression Loss: 4.5145\n","Timer: 0.6425 sec.\n","tensor(5.4235, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2199 || Loss: 7.4476 || Conf Loss: 2.0241 || Regression Loss: 5.4235\n","Timer: 0.5990 sec.\n","tensor(2.3611, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2200 || Loss: 4.7678 || Conf Loss: 2.4067 || Regression Loss: 2.3611\n","Timer: 0.5987 sec.\n","tensor(1.4097, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2201 || Loss: 3.3854 || Conf Loss: 1.9757 || Regression Loss: 1.4097\n","Timer: 0.6644 sec.\n","tensor(5.4349, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2202 || Loss: 7.4486 || Conf Loss: 2.0136 || Regression Loss: 5.4349\n","Timer: 0.5666 sec.\n","tensor(1.3260, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2203 || Loss: 3.3322 || Conf Loss: 2.0062 || Regression Loss: 1.3260\n","Timer: 0.5776 sec.\n","tensor(0.1010, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2204 || Loss: 2.0608 || Conf Loss: 1.9598 || Regression Loss: 0.1010\n","Timer: 0.5665 sec.\n","tensor(3.9022, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2205 || Loss: 5.8891 || Conf Loss: 1.9869 || Regression Loss: 3.9022\n","Timer: 0.6422 sec.\n","tensor(0.4590, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2206 || Loss: 2.4090 || Conf Loss: 1.9499 || Regression Loss: 0.4590\n","Timer: 0.5575 sec.\n","tensor(5.5685, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2207 || Loss: 7.3548 || Conf Loss: 1.7864 || Regression Loss: 5.5685\n","Timer: 0.6395 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2208 || Loss: 1.2832 || Conf Loss: 1.2832 || Regression Loss: 0.0000\n","Timer: 0.6484 sec.\n","tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2209 || Loss: 2.0094 || Conf Loss: 1.8591 || Regression Loss: 0.1503\n","Timer: 0.5879 sec.\n","tensor(2.7059, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2210 || Loss: 4.5224 || Conf Loss: 1.8165 || Regression Loss: 2.7059\n","Timer: 0.5578 sec.\n","tensor(2.5282, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2211 || Loss: 4.4893 || Conf Loss: 1.9610 || Regression Loss: 2.5282\n","Timer: 0.6660 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2212 || Loss: 1.4131 || Conf Loss: 1.4131 || Regression Loss: 0.0000\n","Timer: 0.6536 sec.\n","tensor(2.0193, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2213 || Loss: 3.9254 || Conf Loss: 1.9062 || Regression Loss: 2.0193\n","Timer: 0.5666 sec.\n","tensor(5.1626, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2214 || Loss: 7.6591 || Conf Loss: 2.4965 || Regression Loss: 5.1626\n","Timer: 0.5865 sec.\n","tensor(2.6969, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2215 || Loss: 4.7662 || Conf Loss: 2.0693 || Regression Loss: 2.6969\n","Timer: 0.5570 sec.\n","tensor(2.0621, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2216 || Loss: 5.9210 || Conf Loss: 3.8589 || Regression Loss: 2.0621\n","Timer: 0.6179 sec.\n","tensor(2.1525, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2217 || Loss: 5.6950 || Conf Loss: 3.5425 || Regression Loss: 2.1525\n","Timer: 0.6032 sec.\n","tensor(3.4707, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2218 || Loss: 5.7903 || Conf Loss: 2.3196 || Regression Loss: 3.4707\n","Timer: 0.6450 sec.\n","tensor(5.5442, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2219 || Loss: 7.4143 || Conf Loss: 1.8701 || Regression Loss: 5.5442\n","Timer: 0.5443 sec.\n","tensor(5.5165, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2220 || Loss: 7.3898 || Conf Loss: 1.8733 || Regression Loss: 5.5165\n","Timer: 0.6364 sec.\n","tensor(0.1607, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2221 || Loss: 2.2829 || Conf Loss: 2.1222 || Regression Loss: 0.1607\n","Timer: 0.5219 sec.\n","tensor(3.6691, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2222 || Loss: 5.8589 || Conf Loss: 2.1898 || Regression Loss: 3.6691\n","Timer: 0.5870 sec.\n","tensor(0.5167, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2223 || Loss: 2.4073 || Conf Loss: 1.8906 || Regression Loss: 0.5167\n","Timer: 0.5768 sec.\n","tensor(3.9019, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2224 || Loss: 6.4590 || Conf Loss: 2.5571 || Regression Loss: 3.9019\n","Timer: 0.5499 sec.\n","tensor(1.8851, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2225 || Loss: 4.4915 || Conf Loss: 2.6064 || Regression Loss: 1.8851\n","Timer: 0.5603 sec.\n","tensor(3.9860, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2226 || Loss: 6.0903 || Conf Loss: 2.1044 || Regression Loss: 3.9860\n","Timer: 0.6572 sec.\n","tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2227 || Loss: 1.9777 || Conf Loss: 1.9011 || Regression Loss: 0.0766\n","Timer: 0.7469 sec.\n","tensor(4.3392, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2228 || Loss: 9.9621 || Conf Loss: 5.6229 || Regression Loss: 4.3392\n","Timer: 0.5454 sec.\n","tensor(3.5425, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2229 || Loss: 5.9202 || Conf Loss: 2.3778 || Regression Loss: 3.5425\n","Timer: 0.5645 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2230 || Loss: 1.1759 || Conf Loss: 1.1759 || Regression Loss: 0.0000\n","Timer: 0.6352 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2231 || Loss: 1.2368 || Conf Loss: 1.2368 || Regression Loss: 0.0000\n","Timer: 0.5429 sec.\n","tensor(0.0727, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2232 || Loss: 1.9943 || Conf Loss: 1.9215 || Regression Loss: 0.0727\n","Timer: 0.5457 sec.\n","tensor(0.0664, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2233 || Loss: 2.1887 || Conf Loss: 2.1223 || Regression Loss: 0.0664\n","Timer: 0.5615 sec.\n","tensor(3.7052, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2234 || Loss: 6.3040 || Conf Loss: 2.5989 || Regression Loss: 3.7052\n","Timer: 0.7354 sec.\n","tensor(1.1235, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2235 || Loss: 3.9922 || Conf Loss: 2.8688 || Regression Loss: 1.1235\n","Timer: 0.7090 sec.\n","tensor(4.0305, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2236 || Loss: 5.9588 || Conf Loss: 1.9283 || Regression Loss: 4.0305\n","Timer: 0.6348 sec.\n","tensor(2.2336, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2237 || Loss: 4.3657 || Conf Loss: 2.1321 || Regression Loss: 2.2336\n","Timer: 0.5834 sec.\n","tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2238 || Loss: 2.5146 || Conf Loss: 2.3012 || Regression Loss: 0.2133\n","Timer: 0.5945 sec.\n","tensor(2.7666, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2239 || Loss: 4.5623 || Conf Loss: 1.7956 || Regression Loss: 2.7666\n","Timer: 0.5445 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2240 || Loss: 1.2053 || Conf Loss: 1.2053 || Regression Loss: 0.0000\n","Timer: 0.6199 sec.\n","tensor(5.0544, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2241 || Loss: 7.0061 || Conf Loss: 1.9517 || Regression Loss: 5.0544\n","Timer: 0.5425 sec.\n","tensor(0.0596, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2242 || Loss: 1.9528 || Conf Loss: 1.8932 || Regression Loss: 0.0596\n","Timer: 0.5306 sec.\n","tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2243 || Loss: 1.8979 || Conf Loss: 1.8329 || Regression Loss: 0.0650\n","Timer: 0.5358 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2244 || Loss: 1.0786 || Conf Loss: 1.0786 || Regression Loss: 0.0000\n","Timer: 0.5473 sec.\n","tensor(5.5668, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2245 || Loss: 8.3438 || Conf Loss: 2.7770 || Regression Loss: 5.5668\n","Timer: 0.5599 sec.\n","tensor(1.9564, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2246 || Loss: 4.5289 || Conf Loss: 2.5725 || Regression Loss: 1.9564\n","Timer: 0.6618 sec.\n","tensor(5.1692, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2247 || Loss: 8.0216 || Conf Loss: 2.8524 || Regression Loss: 5.1692\n","Timer: 0.6538 sec.\n","tensor(1.8127, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2248 || Loss: 5.8147 || Conf Loss: 4.0021 || Regression Loss: 1.8127\n","Timer: 0.5644 sec.\n","tensor(5.0168, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2249 || Loss: 7.0681 || Conf Loss: 2.0513 || Regression Loss: 5.0168\n","Timer: 0.6710 sec.\n","tensor(3.7310, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2250 || Loss: 5.8576 || Conf Loss: 2.1266 || Regression Loss: 3.7310\n","Timer: 0.5997 sec.\n","tensor(2.2004, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2251 || Loss: 4.2152 || Conf Loss: 2.0148 || Regression Loss: 2.2004\n","Timer: 0.6598 sec.\n","tensor(3.2003, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2252 || Loss: 5.8059 || Conf Loss: 2.6057 || Regression Loss: 3.2003\n","Timer: 0.6293 sec.\n","tensor(2.0733, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2253 || Loss: 5.9409 || Conf Loss: 3.8676 || Regression Loss: 2.0733\n","Timer: 0.5827 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2254 || Loss: 1.1135 || Conf Loss: 1.1135 || Regression Loss: 0.0000\n","Timer: 0.6415 sec.\n","tensor(0.1088, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2255 || Loss: 2.0197 || Conf Loss: 1.9110 || Regression Loss: 0.1088\n","Timer: 0.5855 sec.\n","tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2256 || Loss: 1.9611 || Conf Loss: 1.8788 || Regression Loss: 0.0823\n","Timer: 0.6000 sec.\n","tensor(5.0871, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2257 || Loss: 8.4894 || Conf Loss: 3.4023 || Regression Loss: 5.0871\n","Timer: 0.6765 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2258 || Loss: 1.0869 || Conf Loss: 1.0869 || Regression Loss: 0.0000\n","Timer: 0.6191 sec.\n","tensor(2.1729, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2259 || Loss: 4.4079 || Conf Loss: 2.2350 || Regression Loss: 2.1729\n","Timer: 0.5926 sec.\n","tensor(2.0625, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2260 || Loss: 6.0458 || Conf Loss: 3.9833 || Regression Loss: 2.0625\n","Timer: 0.6624 sec.\n","tensor(1.0922, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2261 || Loss: 3.7589 || Conf Loss: 2.6667 || Regression Loss: 1.0922\n","Timer: 0.5368 sec.\n","tensor(0.6343, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2262 || Loss: 3.7044 || Conf Loss: 3.0701 || Regression Loss: 0.6343\n","Timer: 0.6772 sec.\n","tensor(0.0672, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2263 || Loss: 2.0341 || Conf Loss: 1.9668 || Regression Loss: 0.0672\n","Timer: 0.6364 sec.\n","tensor(4.2837, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2264 || Loss: 6.5145 || Conf Loss: 2.2308 || Regression Loss: 4.2837\n","Timer: 0.6387 sec.\n","tensor(4.9098, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2265 || Loss: 7.7151 || Conf Loss: 2.8053 || Regression Loss: 4.9098\n","Timer: 0.5731 sec.\n","tensor(1.1664, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2266 || Loss: 3.4551 || Conf Loss: 2.2887 || Regression Loss: 1.1664\n","Timer: 0.6707 sec.\n","tensor(1.9561, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2267 || Loss: 5.7311 || Conf Loss: 3.7750 || Regression Loss: 1.9561\n","Timer: 0.5846 sec.\n","tensor(3.3388, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2268 || Loss: 7.0320 || Conf Loss: 3.6932 || Regression Loss: 3.3388\n","Timer: 0.6221 sec.\n","tensor(0.5303, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2269 || Loss: 2.6342 || Conf Loss: 2.1039 || Regression Loss: 0.5303\n","Timer: 0.5315 sec.\n","tensor(0.4302, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2270 || Loss: 2.2913 || Conf Loss: 1.8610 || Regression Loss: 0.4302\n","Timer: 0.6108 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2271 || Loss: 1.0804 || Conf Loss: 1.0804 || Regression Loss: 0.0000\n","Timer: 0.5695 sec.\n","tensor(4.7820, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2272 || Loss: 6.6971 || Conf Loss: 1.9151 || Regression Loss: 4.7820\n","Timer: 0.7004 sec.\n","tensor(0.9011, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2273 || Loss: 3.4452 || Conf Loss: 2.5441 || Regression Loss: 0.9011\n","Timer: 0.6456 sec.\n","tensor(1.8037, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2274 || Loss: 3.9932 || Conf Loss: 2.1895 || Regression Loss: 1.8037\n","Timer: 0.6263 sec.\n","tensor(5.2584, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2275 || Loss: 7.1260 || Conf Loss: 1.8675 || Regression Loss: 5.2584\n","Timer: 0.5737 sec.\n","tensor(7.7042, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2276 || Loss: 10.7333 || Conf Loss: 3.0291 || Regression Loss: 7.7042\n","Timer: 0.5902 sec.\n","tensor(4.9435, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2277 || Loss: 6.9629 || Conf Loss: 2.0194 || Regression Loss: 4.9435\n","Timer: 0.5631 sec.\n","tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2278 || Loss: 2.2512 || Conf Loss: 1.9208 || Regression Loss: 0.3304\n","Timer: 0.5976 sec.\n","tensor(2.7438, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2279 || Loss: 6.2912 || Conf Loss: 3.5474 || Regression Loss: 2.7438\n","Timer: 0.6248 sec.\n","tensor(5.2154, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2280 || Loss: 7.2175 || Conf Loss: 2.0021 || Regression Loss: 5.2154\n","Timer: 0.5215 sec.\n","tensor(2.2202, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2281 || Loss: 5.8637 || Conf Loss: 3.6435 || Regression Loss: 2.2202\n","Timer: 0.6385 sec.\n","tensor(2.3690, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2282 || Loss: 4.4671 || Conf Loss: 2.0981 || Regression Loss: 2.3690\n","Timer: 0.5605 sec.\n","tensor(4.3298, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2283 || Loss: 6.3746 || Conf Loss: 2.0448 || Regression Loss: 4.3298\n","Timer: 0.5421 sec.\n","tensor(2.3108, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2284 || Loss: 5.8421 || Conf Loss: 3.5313 || Regression Loss: 2.3108\n","Timer: 0.6661 sec.\n","tensor(0.0573, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2285 || Loss: 2.0374 || Conf Loss: 1.9801 || Regression Loss: 0.0573\n","Timer: 0.7252 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2286 || Loss: 1.2581 || Conf Loss: 1.2581 || Regression Loss: 0.0000\n","Timer: 0.7253 sec.\n","tensor(5.2072, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2287 || Loss: 7.1196 || Conf Loss: 1.9124 || Regression Loss: 5.2072\n","Timer: 0.6259 sec.\n","tensor(5.4897, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2288 || Loss: 7.4410 || Conf Loss: 1.9513 || Regression Loss: 5.4897\n","Timer: 0.5565 sec.\n","tensor(2.0272, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2289 || Loss: 4.1920 || Conf Loss: 2.1648 || Regression Loss: 2.0272\n","Timer: 0.6677 sec.\n","tensor(1.7830, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2290 || Loss: 4.4227 || Conf Loss: 2.6397 || Regression Loss: 1.7830\n","Timer: 0.7875 sec.\n","tensor(5.0238, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2291 || Loss: 6.8447 || Conf Loss: 1.8209 || Regression Loss: 5.0238\n","Timer: 0.5872 sec.\n","tensor(4.2170, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2292 || Loss: 6.1735 || Conf Loss: 1.9565 || Regression Loss: 4.2170\n","Timer: 0.6176 sec.\n","tensor(4.2317, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2293 || Loss: 6.1178 || Conf Loss: 1.8860 || Regression Loss: 4.2317\n","Timer: 0.6610 sec.\n","tensor(5.3781, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2294 || Loss: 7.3551 || Conf Loss: 1.9770 || Regression Loss: 5.3781\n","Timer: 0.6108 sec.\n","tensor(5.1186, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2295 || Loss: 7.2731 || Conf Loss: 2.1546 || Regression Loss: 5.1186\n","Timer: 0.6469 sec.\n","tensor(2.9963, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2296 || Loss: 5.5350 || Conf Loss: 2.5388 || Regression Loss: 2.9963\n","Timer: 0.6235 sec.\n","tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2297 || Loss: 1.9562 || Conf Loss: 1.8385 || Regression Loss: 0.1177\n","Timer: 0.7015 sec.\n","tensor(1.4183, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2298 || Loss: 3.4127 || Conf Loss: 1.9945 || Regression Loss: 1.4183\n","Timer: 0.5803 sec.\n","tensor(5.8515, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2299 || Loss: 7.6729 || Conf Loss: 1.8214 || Regression Loss: 5.8515\n","Timer: 0.5841 sec.\n","tensor(6.1347, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2300 || Loss: 8.3034 || Conf Loss: 2.1687 || Regression Loss: 6.1347\n","Timer: 0.6709 sec.\n","tensor(5.0955, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2301 || Loss: 7.1873 || Conf Loss: 2.0918 || Regression Loss: 5.0955\n","Timer: 0.5912 sec.\n","tensor(3.4587, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2302 || Loss: 5.4316 || Conf Loss: 1.9729 || Regression Loss: 3.4587\n","Timer: 0.6281 sec.\n","tensor(2.2133, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2303 || Loss: 4.1228 || Conf Loss: 1.9096 || Regression Loss: 2.2133\n","Timer: 0.5547 sec.\n","tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2304 || Loss: 1.9700 || Conf Loss: 1.8921 || Regression Loss: 0.0780\n","Timer: 0.6761 sec.\n","tensor(4.2574, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2305 || Loss: 6.1003 || Conf Loss: 1.8429 || Regression Loss: 4.2574\n","Timer: 0.5404 sec.\n","tensor(3.5779, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2306 || Loss: 5.5054 || Conf Loss: 1.9275 || Regression Loss: 3.5779\n","Timer: 0.7066 sec.\n","tensor(4.9425, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2307 || Loss: 6.7919 || Conf Loss: 1.8494 || Regression Loss: 4.9425\n","Timer: 0.5428 sec.\n","tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2308 || Loss: 1.7724 || Conf Loss: 1.7324 || Regression Loss: 0.0400\n","Timer: 0.5370 sec.\n","tensor(0.0897, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2309 || Loss: 1.9446 || Conf Loss: 1.8549 || Regression Loss: 0.0897\n","Timer: 0.7509 sec.\n","tensor(4.3812, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2310 || Loss: 7.8309 || Conf Loss: 3.4496 || Regression Loss: 4.3812\n","Timer: 0.6553 sec.\n","tensor(1.4895, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2311 || Loss: 4.5477 || Conf Loss: 3.0583 || Regression Loss: 1.4895\n","Timer: 0.5873 sec.\n","tensor(2.5467, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2312 || Loss: 4.7648 || Conf Loss: 2.2181 || Regression Loss: 2.5467\n","Timer: 0.6435 sec.\n","tensor(2.1710, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2313 || Loss: 4.2839 || Conf Loss: 2.1129 || Regression Loss: 2.1710\n","Timer: 0.6932 sec.\n","tensor(1.3375, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2314 || Loss: 3.3418 || Conf Loss: 2.0043 || Regression Loss: 1.3375\n","Timer: 0.5391 sec.\n","tensor(1.4678, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2315 || Loss: 3.4868 || Conf Loss: 2.0191 || Regression Loss: 1.4678\n","Timer: 0.5615 sec.\n","tensor(0.4047, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2316 || Loss: 3.0709 || Conf Loss: 2.6663 || Regression Loss: 0.4047\n","Timer: 0.5649 sec.\n","tensor(5.3341, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2317 || Loss: 7.2478 || Conf Loss: 1.9138 || Regression Loss: 5.3341\n","Timer: 0.5864 sec.\n","tensor(3.3331, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2318 || Loss: 5.3872 || Conf Loss: 2.0541 || Regression Loss: 3.3331\n","Timer: 0.5580 sec.\n","tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2319 || Loss: 2.0522 || Conf Loss: 1.8414 || Regression Loss: 0.2108\n","Timer: 0.5820 sec.\n","tensor(1.0039, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2320 || Loss: 2.8515 || Conf Loss: 1.8477 || Regression Loss: 1.0039\n","Timer: 0.5625 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2321 || Loss: 1.1968 || Conf Loss: 1.1968 || Regression Loss: 0.0000\n","Timer: 0.6588 sec.\n","tensor(4.1890, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2322 || Loss: 6.2149 || Conf Loss: 2.0259 || Regression Loss: 4.1890\n","Timer: 0.5088 sec.\n","tensor(1.5628, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2323 || Loss: 5.2484 || Conf Loss: 3.6855 || Regression Loss: 1.5628\n","Timer: 0.6876 sec.\n","tensor(3.1197, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2324 || Loss: 5.9528 || Conf Loss: 2.8330 || Regression Loss: 3.1197\n","Timer: 0.5852 sec.\n","tensor(3.0790, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2325 || Loss: 5.0238 || Conf Loss: 1.9447 || Regression Loss: 3.0790\n","Timer: 0.5533 sec.\n","tensor(3.3359, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2326 || Loss: 5.5405 || Conf Loss: 2.2046 || Regression Loss: 3.3359\n","Timer: 0.5493 sec.\n","tensor(1.4443, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2327 || Loss: 4.2511 || Conf Loss: 2.8068 || Regression Loss: 1.4443\n","Timer: 0.5896 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2328 || Loss: 1.1116 || Conf Loss: 1.1116 || Regression Loss: 0.0000\n","Timer: 0.5849 sec.\n","tensor(0.5584, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2329 || Loss: 2.4537 || Conf Loss: 1.8953 || Regression Loss: 0.5584\n","Timer: 0.5674 sec.\n","tensor(2.4521, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2330 || Loss: 4.3118 || Conf Loss: 1.8596 || Regression Loss: 2.4521\n","Timer: 0.6125 sec.\n","tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2331 || Loss: 2.2666 || Conf Loss: 2.1437 || Regression Loss: 0.1229\n","Timer: 0.5229 sec.\n","tensor(0.5045, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2332 || Loss: 2.9076 || Conf Loss: 2.4031 || Regression Loss: 0.5045\n","Timer: 0.5459 sec.\n","tensor(4.0473, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2333 || Loss: 5.9592 || Conf Loss: 1.9119 || Regression Loss: 4.0473\n","Timer: 0.5668 sec.\n","tensor(33.9734, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2334 || Loss: 38.5553 || Conf Loss: 4.5819 || Regression Loss: 33.9734\n","Timer: 0.5694 sec.\n","tensor(5.7822, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2335 || Loss: 8.0081 || Conf Loss: 2.2259 || Regression Loss: 5.7822\n","Timer: 0.5898 sec.\n","tensor(1.9952, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2336 || Loss: 5.8292 || Conf Loss: 3.8340 || Regression Loss: 1.9952\n","Timer: 0.6474 sec.\n","tensor(1.8214, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2337 || Loss: 5.3101 || Conf Loss: 3.4887 || Regression Loss: 1.8214\n","Timer: 0.6537 sec.\n","tensor(3.8075, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2338 || Loss: 9.1902 || Conf Loss: 5.3827 || Regression Loss: 3.8075\n","Timer: 0.6747 sec.\n","tensor(0.2094, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2339 || Loss: 2.4693 || Conf Loss: 2.2599 || Regression Loss: 0.2094\n","Timer: 0.6076 sec.\n","tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2340 || Loss: 2.5272 || Conf Loss: 2.3197 || Regression Loss: 0.2075\n","Timer: 0.5746 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2341 || Loss: 1.1822 || Conf Loss: 1.1822 || Regression Loss: 0.0000\n","Timer: 0.5413 sec.\n","tensor(2.2475, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2342 || Loss: 4.7028 || Conf Loss: 2.4553 || Regression Loss: 2.2475\n","Timer: 0.5561 sec.\n","tensor(2.5677, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2343 || Loss: 4.8772 || Conf Loss: 2.3095 || Regression Loss: 2.5677\n","Timer: 0.7230 sec.\n","tensor(5.7193, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2344 || Loss: 8.2032 || Conf Loss: 2.4839 || Regression Loss: 5.7193\n","Timer: 0.5476 sec.\n","tensor(2.4193, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2345 || Loss: 7.0722 || Conf Loss: 4.6530 || Regression Loss: 2.4193\n","Timer: 0.5194 sec.\n","tensor(1.4501, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2346 || Loss: 3.6969 || Conf Loss: 2.2468 || Regression Loss: 1.4501\n","Timer: 0.5840 sec.\n","tensor(1.9142, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2347 || Loss: 5.5220 || Conf Loss: 3.6078 || Regression Loss: 1.9142\n","Timer: 0.6474 sec.\n","tensor(5.2018, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2348 || Loss: 7.2519 || Conf Loss: 2.0501 || Regression Loss: 5.2018\n","Timer: 0.5868 sec.\n","tensor(3.3285, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2349 || Loss: 5.4329 || Conf Loss: 2.1044 || Regression Loss: 3.3285\n","Timer: 0.5743 sec.\n","tensor(3.9971, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2350 || Loss: 6.5996 || Conf Loss: 2.6024 || Regression Loss: 3.9971\n","Timer: 0.6722 sec.\n","tensor(3.6419, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2351 || Loss: 5.6368 || Conf Loss: 1.9950 || Regression Loss: 3.6419\n","Timer: 0.5499 sec.\n","tensor(5.2371, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2352 || Loss: 7.2736 || Conf Loss: 2.0365 || Regression Loss: 5.2371\n","Timer: 0.5796 sec.\n","tensor(3.2514, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2353 || Loss: 5.2452 || Conf Loss: 1.9938 || Regression Loss: 3.2514\n","Timer: 0.6030 sec.\n","tensor(5.8097, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2354 || Loss: 7.7532 || Conf Loss: 1.9435 || Regression Loss: 5.8097\n","Timer: 0.7017 sec.\n","tensor(0.0767, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2355 || Loss: 2.1450 || Conf Loss: 2.0684 || Regression Loss: 0.0767\n","Timer: 0.6150 sec.\n","tensor(3.3323, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2356 || Loss: 5.2593 || Conf Loss: 1.9270 || Regression Loss: 3.3323\n","Timer: 0.5840 sec.\n","tensor(2.7127, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2357 || Loss: 4.6896 || Conf Loss: 1.9769 || Regression Loss: 2.7127\n","Timer: 0.6568 sec.\n","tensor(5.0909, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2358 || Loss: 7.0862 || Conf Loss: 1.9953 || Regression Loss: 5.0909\n","Timer: 0.7193 sec.\n","tensor(2.9360, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2359 || Loss: 4.7828 || Conf Loss: 1.8468 || Regression Loss: 2.9360\n","Timer: 0.6703 sec.\n","tensor(3.1672, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2360 || Loss: 5.2299 || Conf Loss: 2.0627 || Regression Loss: 3.1672\n","Timer: 0.5628 sec.\n","tensor(5.4186, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2361 || Loss: 8.0393 || Conf Loss: 2.6207 || Regression Loss: 5.4186\n","Timer: 0.5533 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2362 || Loss: 1.2326 || Conf Loss: 1.2326 || Regression Loss: 0.0000\n","Timer: 0.6446 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2363 || Loss: 1.2348 || Conf Loss: 1.2348 || Regression Loss: 0.0000\n","Timer: 0.5758 sec.\n","tensor(0.6765, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2364 || Loss: 3.7098 || Conf Loss: 3.0333 || Regression Loss: 0.6765\n","Timer: 0.6994 sec.\n","tensor(4.9574, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2365 || Loss: 6.9850 || Conf Loss: 2.0276 || Regression Loss: 4.9574\n","Timer: 0.6681 sec.\n","tensor(3.7668, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2366 || Loss: 5.7102 || Conf Loss: 1.9434 || Regression Loss: 3.7668\n","Timer: 0.6426 sec.\n","tensor(4.1094, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2367 || Loss: 6.1700 || Conf Loss: 2.0605 || Regression Loss: 4.1094\n","Timer: 0.6213 sec.\n","tensor(4.9999, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2368 || Loss: 6.9000 || Conf Loss: 1.9002 || Regression Loss: 4.9999\n","Timer: 0.6065 sec.\n","tensor(4.5026, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2369 || Loss: 6.4299 || Conf Loss: 1.9272 || Regression Loss: 4.5026\n","Timer: 0.5979 sec.\n","tensor(0.4882, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2370 || Loss: 2.4551 || Conf Loss: 1.9668 || Regression Loss: 0.4882\n","Timer: 0.6529 sec.\n","tensor(1.9566, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2371 || Loss: 5.6673 || Conf Loss: 3.7107 || Regression Loss: 1.9566\n","Timer: 0.5888 sec.\n","tensor(4.4863, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2372 || Loss: 6.3560 || Conf Loss: 1.8697 || Regression Loss: 4.4863\n","Timer: 0.6165 sec.\n","tensor(3.0973, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2373 || Loss: 5.0506 || Conf Loss: 1.9533 || Regression Loss: 3.0973\n","Timer: 0.5528 sec.\n","tensor(1.9030, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2374 || Loss: 4.7068 || Conf Loss: 2.8039 || Regression Loss: 1.9030\n","Timer: 0.5493 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2375 || Loss: 1.2906 || Conf Loss: 1.2906 || Regression Loss: 0.0000\n","Timer: 0.6525 sec.\n","tensor(2.2105, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2376 || Loss: 4.1592 || Conf Loss: 1.9487 || Regression Loss: 2.2105\n","Timer: 0.6826 sec.\n","tensor(3.6105, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2377 || Loss: 5.4225 || Conf Loss: 1.8121 || Regression Loss: 3.6105\n","Timer: 0.5825 sec.\n","tensor(0.1596, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2378 || Loss: 2.3127 || Conf Loss: 2.1531 || Regression Loss: 0.1596\n","Timer: 0.6287 sec.\n","tensor(4.5929, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2379 || Loss: 6.4143 || Conf Loss: 1.8213 || Regression Loss: 4.5929\n","Timer: 0.5852 sec.\n","tensor(6.5757, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2380 || Loss: 8.4082 || Conf Loss: 1.8325 || Regression Loss: 6.5757\n","Timer: 0.6122 sec.\n","tensor(1.5051, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2381 || Loss: 3.4707 || Conf Loss: 1.9656 || Regression Loss: 1.5051\n","Timer: 0.6727 sec.\n","tensor(4.8347, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2382 || Loss: 6.6059 || Conf Loss: 1.7713 || Regression Loss: 4.8347\n","Timer: 0.5219 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2383 || Loss: 1.2240 || Conf Loss: 1.2240 || Regression Loss: 0.0000\n","Timer: 0.5911 sec.\n","tensor(6.0556, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2384 || Loss: 7.9020 || Conf Loss: 1.8464 || Regression Loss: 6.0556\n","Timer: 0.6616 sec.\n","tensor(0.5389, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2385 || Loss: 2.4739 || Conf Loss: 1.9350 || Regression Loss: 0.5389\n","Timer: 0.6024 sec.\n","tensor(0.5441, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2386 || Loss: 2.6985 || Conf Loss: 2.1544 || Regression Loss: 0.5441\n","Timer: 0.6340 sec.\n","tensor(3.1708, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2387 || Loss: 5.2271 || Conf Loss: 2.0563 || Regression Loss: 3.1708\n","Timer: 0.5842 sec.\n","tensor(4.0092, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2388 || Loss: 6.2940 || Conf Loss: 2.2848 || Regression Loss: 4.0092\n","Timer: 0.5728 sec.\n","tensor(2.2791, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2389 || Loss: 4.1317 || Conf Loss: 1.8526 || Regression Loss: 2.2791\n","Timer: 0.5455 sec.\n","tensor(7.7605, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2390 || Loss: 10.4364 || Conf Loss: 2.6759 || Regression Loss: 7.7605\n","Timer: 0.5894 sec.\n","tensor(0.4371, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2391 || Loss: 2.9156 || Conf Loss: 2.4785 || Regression Loss: 0.4371\n","Timer: 0.7504 sec.\n","tensor(0.2413, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2392 || Loss: 2.0916 || Conf Loss: 1.8503 || Regression Loss: 0.2413\n","Timer: 0.5809 sec.\n","tensor(4.9944, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2393 || Loss: 6.8361 || Conf Loss: 1.8417 || Regression Loss: 4.9944\n","Timer: 0.6494 sec.\n","tensor(0.5331, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2394 || Loss: 3.0152 || Conf Loss: 2.4821 || Regression Loss: 0.5331\n","Timer: 0.5658 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2395 || Loss: 1.1826 || Conf Loss: 1.1826 || Regression Loss: 0.0000\n","Timer: 0.6020 sec.\n","tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2396 || Loss: 1.9304 || Conf Loss: 1.8470 || Regression Loss: 0.0835\n","Timer: 0.5523 sec.\n","tensor(5.0240, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2397 || Loss: 6.8670 || Conf Loss: 1.8430 || Regression Loss: 5.0240\n","Timer: 0.5913 sec.\n","tensor(2.2643, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2398 || Loss: 4.3440 || Conf Loss: 2.0797 || Regression Loss: 2.2643\n","Timer: 0.5461 sec.\n","tensor(3.2524, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2399 || Loss: 5.5566 || Conf Loss: 2.3041 || Regression Loss: 3.2524\n","Timer: 0.6446 sec.\n","tensor(3.3169, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2400 || Loss: 5.1639 || Conf Loss: 1.8469 || Regression Loss: 3.3169\n","Timer: 0.5750 sec.\n","tensor(0.4432, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2401 || Loss: 2.7324 || Conf Loss: 2.2892 || Regression Loss: 0.4432\n","Timer: 0.6381 sec.\n","tensor(2.0088, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2402 || Loss: 3.9888 || Conf Loss: 1.9801 || Regression Loss: 2.0088\n","Timer: 0.6369 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2403 || Loss: 1.1153 || Conf Loss: 1.1153 || Regression Loss: 0.0000\n","Timer: 0.5934 sec.\n","tensor(4.4320, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2404 || Loss: 6.4324 || Conf Loss: 2.0003 || Regression Loss: 4.4320\n","Timer: 0.6940 sec.\n","tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2405 || Loss: 2.2700 || Conf Loss: 2.2109 || Regression Loss: 0.0591\n","Timer: 0.5429 sec.\n","tensor(5.2378, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2406 || Loss: 6.9972 || Conf Loss: 1.7593 || Regression Loss: 5.2378\n","Timer: 0.5702 sec.\n","tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2407 || Loss: 1.9544 || Conf Loss: 1.7170 || Regression Loss: 0.2374\n","Timer: 0.5882 sec.\n","tensor(3.7550, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2408 || Loss: 5.6812 || Conf Loss: 1.9262 || Regression Loss: 3.7550\n","Timer: 0.5535 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2409 || Loss: 0.9826 || Conf Loss: 0.9826 || Regression Loss: 0.0000\n","Timer: 0.5816 sec.\n","tensor(4.8426, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2410 || Loss: 6.5975 || Conf Loss: 1.7549 || Regression Loss: 4.8426\n","Timer: 0.5837 sec.\n","tensor(2.9383, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2411 || Loss: 5.3280 || Conf Loss: 2.3897 || Regression Loss: 2.9383\n","Timer: 0.5703 sec.\n","tensor(2.9555, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2412 || Loss: 4.6877 || Conf Loss: 1.7322 || Regression Loss: 2.9555\n","Timer: 0.5828 sec.\n","tensor(3.1406, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2413 || Loss: 5.5760 || Conf Loss: 2.4354 || Regression Loss: 3.1406\n","Timer: 0.5331 sec.\n","tensor(5.0394, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2414 || Loss: 6.7413 || Conf Loss: 1.7019 || Regression Loss: 5.0394\n","Timer: 0.5821 sec.\n","tensor(3.3441, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2415 || Loss: 5.0681 || Conf Loss: 1.7240 || Regression Loss: 3.3441\n","Timer: 0.5768 sec.\n","tensor(0.0642, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2416 || Loss: 2.1078 || Conf Loss: 2.0435 || Regression Loss: 0.0642\n","Timer: 0.6069 sec.\n","tensor(4.7637, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2417 || Loss: 6.4772 || Conf Loss: 1.7135 || Regression Loss: 4.7637\n","Timer: 0.5546 sec.\n","tensor(4.9193, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2418 || Loss: 6.7548 || Conf Loss: 1.8355 || Regression Loss: 4.9193\n","Timer: 0.6038 sec.\n","tensor(2.0347, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2419 || Loss: 6.7939 || Conf Loss: 4.7592 || Regression Loss: 2.0347\n","Timer: 0.6627 sec.\n","tensor(5.1440, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2420 || Loss: 7.3121 || Conf Loss: 2.1681 || Regression Loss: 5.1440\n","Timer: 0.5572 sec.\n","tensor(3.7207, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2421 || Loss: 5.5828 || Conf Loss: 1.8620 || Regression Loss: 3.7207\n","Timer: 0.5473 sec.\n","tensor(6.1090, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2422 || Loss: 7.9280 || Conf Loss: 1.8189 || Regression Loss: 6.1090\n","Timer: 0.5528 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2423 || Loss: 1.0892 || Conf Loss: 1.0892 || Regression Loss: 0.0000\n","Timer: 0.6480 sec.\n","tensor(3.6065, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2424 || Loss: 5.6629 || Conf Loss: 2.0564 || Regression Loss: 3.6065\n","Timer: 0.5668 sec.\n","tensor(3.2761, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2425 || Loss: 5.5367 || Conf Loss: 2.2606 || Regression Loss: 3.2761\n","Timer: 0.5490 sec.\n","tensor(3.1878, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2426 || Loss: 5.0505 || Conf Loss: 1.8627 || Regression Loss: 3.1878\n","Timer: 0.6110 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2427 || Loss: 1.0593 || Conf Loss: 1.0593 || Regression Loss: 0.0000\n","Timer: 0.5837 sec.\n","tensor(3.2689, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2428 || Loss: 5.4998 || Conf Loss: 2.2309 || Regression Loss: 3.2689\n","Timer: 0.5946 sec.\n","tensor(0.5289, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2429 || Loss: 2.8596 || Conf Loss: 2.3307 || Regression Loss: 0.5289\n","Timer: 0.5811 sec.\n","tensor(2.3773, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2430 || Loss: 4.3656 || Conf Loss: 1.9882 || Regression Loss: 2.3773\n","Timer: 0.7004 sec.\n","tensor(4.2620, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2431 || Loss: 6.0686 || Conf Loss: 1.8066 || Regression Loss: 4.2620\n","Timer: 0.6810 sec.\n","tensor(3.1486, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2432 || Loss: 8.5535 || Conf Loss: 5.4049 || Regression Loss: 3.1486\n","Timer: 0.5701 sec.\n","tensor(0.0884, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2433 || Loss: 1.9811 || Conf Loss: 1.8927 || Regression Loss: 0.0884\n","Timer: 0.6190 sec.\n","tensor(2.8114, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2434 || Loss: 4.5511 || Conf Loss: 1.7396 || Regression Loss: 2.8114\n","Timer: 0.5726 sec.\n","tensor(2.8324, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2435 || Loss: 7.0851 || Conf Loss: 4.2528 || Regression Loss: 2.8324\n","Timer: 0.5824 sec.\n","tensor(0.1124, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2436 || Loss: 1.9516 || Conf Loss: 1.8392 || Regression Loss: 0.1124\n","Timer: 0.6820 sec.\n","tensor(5.1966, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2437 || Loss: 7.0628 || Conf Loss: 1.8662 || Regression Loss: 5.1966\n","Timer: 0.5594 sec.\n","tensor(5.9809, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2438 || Loss: 7.7907 || Conf Loss: 1.8098 || Regression Loss: 5.9809\n","Timer: 0.7193 sec.\n","tensor(5.1719, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2439 || Loss: 7.0607 || Conf Loss: 1.8888 || Regression Loss: 5.1719\n","Timer: 0.6576 sec.\n","tensor(1.2520, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2440 || Loss: 4.9432 || Conf Loss: 3.6912 || Regression Loss: 1.2520\n","Timer: 0.5341 sec.\n","tensor(2.3600, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2441 || Loss: 4.2918 || Conf Loss: 1.9318 || Regression Loss: 2.3600\n","Timer: 0.6229 sec.\n","tensor(2.4607, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2442 || Loss: 4.8013 || Conf Loss: 2.3406 || Regression Loss: 2.4607\n","Timer: 0.5594 sec.\n","tensor(2.1105, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2443 || Loss: 5.9246 || Conf Loss: 3.8141 || Regression Loss: 2.1105\n","Timer: 0.5784 sec.\n","tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2444 || Loss: 2.9953 || Conf Loss: 2.8859 || Regression Loss: 0.1095\n","Timer: 0.6922 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2445 || Loss: 1.1087 || Conf Loss: 1.1087 || Regression Loss: 0.0000\n","Timer: 0.7228 sec.\n","tensor(1.4921, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2446 || Loss: 5.3754 || Conf Loss: 3.8833 || Regression Loss: 1.4921\n","Timer: 0.6459 sec.\n","tensor(7.0387, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2447 || Loss: 9.7078 || Conf Loss: 2.6691 || Regression Loss: 7.0387\n","Timer: 0.5547 sec.\n","tensor(0.1162, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2448 || Loss: 1.9250 || Conf Loss: 1.8088 || Regression Loss: 0.1162\n","Timer: 0.6347 sec.\n","tensor(3.6517, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2449 || Loss: 5.4428 || Conf Loss: 1.7911 || Regression Loss: 3.6517\n","Timer: 0.7666 sec.\n","tensor(0.4278, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2450 || Loss: 2.2449 || Conf Loss: 1.8171 || Regression Loss: 0.4278\n","Timer: 0.5687 sec.\n","tensor(0.0829, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2451 || Loss: 2.5194 || Conf Loss: 2.4365 || Regression Loss: 0.0829\n","Timer: 0.5832 sec.\n","tensor(3.1545, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2452 || Loss: 7.0826 || Conf Loss: 3.9281 || Regression Loss: 3.1545\n","Timer: 0.5516 sec.\n","tensor(4.3577, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2453 || Loss: 7.4546 || Conf Loss: 3.0969 || Regression Loss: 4.3577\n","Timer: 0.6403 sec.\n","tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2454 || Loss: 2.4474 || Conf Loss: 2.0857 || Regression Loss: 0.3617\n","Timer: 0.7311 sec.\n","tensor(4.2727, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2455 || Loss: 6.1746 || Conf Loss: 1.9018 || Regression Loss: 4.2727\n","Timer: 0.6245 sec.\n","tensor(0.1100, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2456 || Loss: 2.0278 || Conf Loss: 1.9178 || Regression Loss: 0.1100\n","Timer: 0.5899 sec.\n","tensor(0.0722, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2457 || Loss: 1.8978 || Conf Loss: 1.8255 || Regression Loss: 0.0722\n","Timer: 0.6279 sec.\n","tensor(3.5398, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2458 || Loss: 5.4274 || Conf Loss: 1.8876 || Regression Loss: 3.5398\n","Timer: 0.6771 sec.\n","tensor(2.9513, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2459 || Loss: 4.8592 || Conf Loss: 1.9079 || Regression Loss: 2.9513\n","Timer: 0.5648 sec.\n","tensor(2.7101, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2460 || Loss: 5.2482 || Conf Loss: 2.5382 || Regression Loss: 2.7101\n","Timer: 0.6186 sec.\n","tensor(3.6725, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2461 || Loss: 6.7352 || Conf Loss: 3.0628 || Regression Loss: 3.6725\n","Timer: 0.6339 sec.\n","tensor(1.5347, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2462 || Loss: 4.8659 || Conf Loss: 3.3313 || Regression Loss: 1.5347\n","Timer: 0.5372 sec.\n","tensor(4.8434, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2463 || Loss: 6.9844 || Conf Loss: 2.1411 || Regression Loss: 4.8434\n","Timer: 0.5757 sec.\n","tensor(2.3046, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2464 || Loss: 4.1883 || Conf Loss: 1.8838 || Regression Loss: 2.3046\n","Timer: 0.5827 sec.\n","tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2465 || Loss: 3.0512 || Conf Loss: 2.9675 || Regression Loss: 0.0837\n","Timer: 0.6375 sec.\n","tensor(3.0512, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2466 || Loss: 5.0391 || Conf Loss: 1.9879 || Regression Loss: 3.0512\n","Timer: 0.5533 sec.\n","tensor(4.7831, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2467 || Loss: 7.0444 || Conf Loss: 2.2613 || Regression Loss: 4.7831\n","Timer: 0.5662 sec.\n","tensor(4.8969, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2468 || Loss: 6.8274 || Conf Loss: 1.9305 || Regression Loss: 4.8969\n","Timer: 0.7340 sec.\n","tensor(5.0741, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2469 || Loss: 7.1598 || Conf Loss: 2.0857 || Regression Loss: 5.0741\n","Timer: 0.5367 sec.\n","tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2470 || Loss: 2.2157 || Conf Loss: 2.1218 || Regression Loss: 0.0939\n","Timer: 0.6615 sec.\n","tensor(3.6590, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2471 || Loss: 6.4311 || Conf Loss: 2.7720 || Regression Loss: 3.6590\n","Timer: 0.5606 sec.\n","tensor(0.1363, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2472 || Loss: 1.9897 || Conf Loss: 1.8534 || Regression Loss: 0.1363\n","Timer: 0.5409 sec.\n","tensor(0.1426, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2473 || Loss: 1.9597 || Conf Loss: 1.8171 || Regression Loss: 0.1426\n","Timer: 0.5510 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2474 || Loss: 1.1987 || Conf Loss: 1.1987 || Regression Loss: 0.0000\n","Timer: 0.7179 sec.\n","tensor(0.1487, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2475 || Loss: 2.1409 || Conf Loss: 1.9922 || Regression Loss: 0.1487\n","Timer: 0.6171 sec.\n","tensor(1.7809, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2476 || Loss: 3.7694 || Conf Loss: 1.9885 || Regression Loss: 1.7809\n","Timer: 0.5399 sec.\n","tensor(3.8229, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2477 || Loss: 5.8704 || Conf Loss: 2.0476 || Regression Loss: 3.8229\n","Timer: 0.6989 sec.\n","tensor(0.0992, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2478 || Loss: 1.9338 || Conf Loss: 1.8346 || Regression Loss: 0.0992\n","Timer: 0.5526 sec.\n","tensor(4.0108, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2479 || Loss: 6.5076 || Conf Loss: 2.4968 || Regression Loss: 4.0108\n","Timer: 0.6144 sec.\n","tensor(4.9760, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2480 || Loss: 6.7880 || Conf Loss: 1.8120 || Regression Loss: 4.9760\n","Timer: 0.6282 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2481 || Loss: 1.0836 || Conf Loss: 1.0836 || Regression Loss: 0.0000\n","Timer: 0.5953 sec.\n","tensor(3.4824, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2482 || Loss: 5.3739 || Conf Loss: 1.8915 || Regression Loss: 3.4824\n","Timer: 0.5569 sec.\n","tensor(0.5302, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2483 || Loss: 2.9763 || Conf Loss: 2.4460 || Regression Loss: 0.5302\n","Timer: 0.5763 sec.\n","tensor(1.0145, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2484 || Loss: 3.0610 || Conf Loss: 2.0465 || Regression Loss: 1.0145\n","Timer: 0.6217 sec.\n","tensor(0.0759, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2485 || Loss: 1.8543 || Conf Loss: 1.7784 || Regression Loss: 0.0759\n","Timer: 0.5668 sec.\n","tensor(2.7567, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2486 || Loss: 4.4754 || Conf Loss: 1.7187 || Regression Loss: 2.7567\n","Timer: 0.5562 sec.\n","tensor(1.5690, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2487 || Loss: 5.1057 || Conf Loss: 3.5366 || Regression Loss: 1.5690\n","Timer: 0.6190 sec.\n","tensor(3.1566, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2488 || Loss: 5.8593 || Conf Loss: 2.7027 || Regression Loss: 3.1566\n","Timer: 0.6265 sec.\n","tensor(5.2481, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2489 || Loss: 7.0146 || Conf Loss: 1.7665 || Regression Loss: 5.2481\n","Timer: 0.5271 sec.\n","tensor(0.2920, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2490 || Loss: 2.1185 || Conf Loss: 1.8265 || Regression Loss: 0.2920\n","Timer: 0.5899 sec.\n","tensor(0.0775, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2491 || Loss: 1.8361 || Conf Loss: 1.7586 || Regression Loss: 0.0775\n","Timer: 0.5895 sec.\n","tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2492 || Loss: 1.9381 || Conf Loss: 1.7850 || Regression Loss: 0.1530\n","Timer: 0.5321 sec.\n","tensor(5.3327, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2493 || Loss: 7.0946 || Conf Loss: 1.7619 || Regression Loss: 5.3327\n","Timer: 0.5986 sec.\n","tensor(3.0338, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2494 || Loss: 6.3115 || Conf Loss: 3.2777 || Regression Loss: 3.0338\n","Timer: 0.5365 sec.\n","tensor(16.4175, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2495 || Loss: 19.6553 || Conf Loss: 3.2378 || Regression Loss: 16.4175\n","Timer: 0.6114 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2496 || Loss: 1.2784 || Conf Loss: 1.2784 || Regression Loss: 0.0000\n","Timer: 0.5499 sec.\n","tensor(0.1334, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2497 || Loss: 1.9269 || Conf Loss: 1.7934 || Regression Loss: 0.1334\n","Timer: 0.5856 sec.\n","tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2498 || Loss: 2.3965 || Conf Loss: 2.2572 || Regression Loss: 0.1393\n","Timer: 0.7158 sec.\n","tensor(2.2113, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2499 || Loss: 5.7520 || Conf Loss: 3.5407 || Regression Loss: 2.2113\n","Timer: 0.5593 sec.\n","tensor(5.2239, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2500 || Loss: 7.2256 || Conf Loss: 2.0016 || Regression Loss: 5.2239\n","Timer: 0.5691 sec.\n","tensor(4.2677, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2501 || Loss: 6.1605 || Conf Loss: 1.8928 || Regression Loss: 4.2677\n","Timer: 0.5629 sec.\n","tensor(0.8174, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2502 || Loss: 2.6301 || Conf Loss: 1.8128 || Regression Loss: 0.8174\n","Timer: 0.7451 sec.\n","tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2503 || Loss: 3.3699 || Conf Loss: 3.0295 || Regression Loss: 0.3404\n","Timer: 0.5796 sec.\n","tensor(5.3499, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2504 || Loss: 7.4590 || Conf Loss: 2.1092 || Regression Loss: 5.3499\n","Timer: 0.6502 sec.\n","tensor(1.2279, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2505 || Loss: 3.1264 || Conf Loss: 1.8985 || Regression Loss: 1.2279\n","Timer: 0.5453 sec.\n","tensor(2.1520, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2506 || Loss: 7.2993 || Conf Loss: 5.1473 || Regression Loss: 2.1520\n","Timer: 0.6293 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2507 || Loss: 1.2378 || Conf Loss: 1.2378 || Regression Loss: 0.0000\n","Timer: 0.5607 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2508 || Loss: 1.0846 || Conf Loss: 1.0846 || Regression Loss: 0.0000\n","Timer: 0.5159 sec.\n","tensor(2.7529, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2509 || Loss: 4.8283 || Conf Loss: 2.0754 || Regression Loss: 2.7529\n","Timer: 0.5614 sec.\n","tensor(2.4274, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2510 || Loss: 5.8323 || Conf Loss: 3.4049 || Regression Loss: 2.4274\n","Timer: 0.6065 sec.\n","tensor(0.2974, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2511 || Loss: 2.2729 || Conf Loss: 1.9755 || Regression Loss: 0.2974\n","Timer: 0.5758 sec.\n","tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2512 || Loss: 2.2727 || Conf Loss: 2.1262 || Regression Loss: 0.1466\n","Timer: 0.6016 sec.\n","tensor(5.3737, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2513 || Loss: 7.5880 || Conf Loss: 2.2143 || Regression Loss: 5.3737\n","Timer: 0.5238 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2514 || Loss: 1.0807 || Conf Loss: 1.0807 || Regression Loss: 0.0000\n","Timer: 0.5646 sec.\n","tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2515 || Loss: 2.3647 || Conf Loss: 2.2825 || Regression Loss: 0.0822\n","Timer: 0.5707 sec.\n","tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2516 || Loss: 2.2813 || Conf Loss: 1.9519 || Regression Loss: 0.3294\n","Timer: 0.6508 sec.\n","tensor(2.4883, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2517 || Loss: 4.8963 || Conf Loss: 2.4080 || Regression Loss: 2.4883\n","Timer: 0.5402 sec.\n","tensor(3.3149, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2518 || Loss: 5.5069 || Conf Loss: 2.1920 || Regression Loss: 3.3149\n","Timer: 0.5949 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2519 || Loss: 1.1132 || Conf Loss: 1.1132 || Regression Loss: 0.0000\n","Timer: 0.5652 sec.\n","tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2520 || Loss: 2.8583 || Conf Loss: 2.4803 || Regression Loss: 0.3780\n","Timer: 0.6097 sec.\n","tensor(2.1631, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2521 || Loss: 4.1882 || Conf Loss: 2.0251 || Regression Loss: 2.1631\n","Timer: 0.5604 sec.\n","tensor(3.7895, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2522 || Loss: 6.0445 || Conf Loss: 2.2549 || Regression Loss: 3.7895\n","Timer: 0.5672 sec.\n","tensor(2.7026, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2523 || Loss: 4.9188 || Conf Loss: 2.2163 || Regression Loss: 2.7026\n","Timer: 0.5498 sec.\n","tensor(1.5254, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2524 || Loss: 5.2731 || Conf Loss: 3.7478 || Regression Loss: 1.5254\n","Timer: 0.7091 sec.\n","tensor(2.3218, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2525 || Loss: 6.5125 || Conf Loss: 4.1907 || Regression Loss: 2.3218\n","Timer: 0.5452 sec.\n","tensor(1.1046, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2526 || Loss: 4.2053 || Conf Loss: 3.1007 || Regression Loss: 1.1046\n","Timer: 0.5426 sec.\n","tensor(3.3232, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2527 || Loss: 5.3472 || Conf Loss: 2.0241 || Regression Loss: 3.3232\n","Timer: 0.5383 sec.\n","tensor(6.4293, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2528 || Loss: 8.7844 || Conf Loss: 2.3552 || Regression Loss: 6.4293\n","Timer: 0.5373 sec.\n","tensor(1.5999, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2529 || Loss: 4.2394 || Conf Loss: 2.6395 || Regression Loss: 1.5999\n","Timer: 0.6644 sec.\n","tensor(2.8233, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2530 || Loss: 4.9543 || Conf Loss: 2.1310 || Regression Loss: 2.8233\n","Timer: 0.5461 sec.\n","tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2531 || Loss: 2.0754 || Conf Loss: 1.9905 || Regression Loss: 0.0849\n","Timer: 0.6108 sec.\n","tensor(5.4358, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2532 || Loss: 7.3288 || Conf Loss: 1.8931 || Regression Loss: 5.4358\n","Timer: 0.7571 sec.\n","tensor(1.7986, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2533 || Loss: 4.8144 || Conf Loss: 3.0158 || Regression Loss: 1.7986\n","Timer: 0.5665 sec.\n","tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2534 || Loss: 2.0331 || Conf Loss: 1.8860 || Regression Loss: 0.1471\n","Timer: 0.6191 sec.\n","tensor(2.1379, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2535 || Loss: 6.0339 || Conf Loss: 3.8961 || Regression Loss: 2.1379\n","Timer: 0.6099 sec.\n","tensor(5.3255, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2536 || Loss: 7.5124 || Conf Loss: 2.1869 || Regression Loss: 5.3255\n","Timer: 0.5766 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2537 || Loss: 1.2044 || Conf Loss: 1.2044 || Regression Loss: 0.0000\n","Timer: 0.5956 sec.\n","tensor(1.8156, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2538 || Loss: 3.7967 || Conf Loss: 1.9811 || Regression Loss: 1.8156\n","Timer: 0.6648 sec.\n","tensor(2.7215, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2539 || Loss: 4.7409 || Conf Loss: 2.0194 || Regression Loss: 2.7215\n","Timer: 0.5684 sec.\n","tensor(1.8726, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2540 || Loss: 5.3699 || Conf Loss: 3.4973 || Regression Loss: 1.8726\n","Timer: 0.5819 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2541 || Loss: 1.1747 || Conf Loss: 1.1747 || Regression Loss: 0.0000\n","Timer: 0.6763 sec.\n","tensor(5.3456, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2542 || Loss: 7.4026 || Conf Loss: 2.0571 || Regression Loss: 5.3456\n","Timer: 0.5707 sec.\n","tensor(1.7018, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2543 || Loss: 3.7813 || Conf Loss: 2.0796 || Regression Loss: 1.7018\n","Timer: 0.5488 sec.\n","tensor(2.3965, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2544 || Loss: 6.2746 || Conf Loss: 3.8781 || Regression Loss: 2.3965\n","Timer: 0.5407 sec.\n","tensor(4.1616, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2545 || Loss: 6.2556 || Conf Loss: 2.0940 || Regression Loss: 4.1616\n","Timer: 0.5765 sec.\n","tensor(4.0074, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2546 || Loss: 6.2087 || Conf Loss: 2.2013 || Regression Loss: 4.0074\n","Timer: 0.5720 sec.\n","tensor(3.7244, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2547 || Loss: 5.7749 || Conf Loss: 2.0505 || Regression Loss: 3.7244\n","Timer: 0.5584 sec.\n","tensor(0.4948, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2548 || Loss: 2.8444 || Conf Loss: 2.3497 || Regression Loss: 0.4948\n","Timer: 0.5742 sec.\n","tensor(1.9952, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2549 || Loss: 6.2069 || Conf Loss: 4.2117 || Regression Loss: 1.9952\n","Timer: 0.5646 sec.\n","tensor(2.7787, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2550 || Loss: 4.8821 || Conf Loss: 2.1033 || Regression Loss: 2.7787\n","Timer: 0.7085 sec.\n","tensor(3.0465, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2551 || Loss: 5.1961 || Conf Loss: 2.1496 || Regression Loss: 3.0465\n","Timer: 0.5854 sec.\n","tensor(1.4767, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2552 || Loss: 3.5562 || Conf Loss: 2.0795 || Regression Loss: 1.4767\n","Timer: 0.5525 sec.\n","tensor(0.2095, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2553 || Loss: 2.5920 || Conf Loss: 2.3825 || Regression Loss: 0.2095\n","Timer: 0.5731 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2554 || Loss: 1.0846 || Conf Loss: 1.0846 || Regression Loss: 0.0000\n","Timer: 0.6091 sec.\n","tensor(3.6357, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2555 || Loss: 5.6278 || Conf Loss: 1.9921 || Regression Loss: 3.6357\n","Timer: 0.5471 sec.\n","tensor(2.4673, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2556 || Loss: 6.4183 || Conf Loss: 3.9511 || Regression Loss: 2.4673\n","Timer: 0.5327 sec.\n","tensor(3.0814, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2557 || Loss: 5.3619 || Conf Loss: 2.2805 || Regression Loss: 3.0814\n","Timer: 0.4990 sec.\n","tensor(2.2473, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2558 || Loss: 5.9857 || Conf Loss: 3.7384 || Regression Loss: 2.2473\n","Timer: 0.5676 sec.\n","tensor(0.3146, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2559 || Loss: 2.3527 || Conf Loss: 2.0381 || Regression Loss: 0.3146\n","Timer: 0.5202 sec.\n","tensor(3.3060, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2560 || Loss: 6.2864 || Conf Loss: 2.9804 || Regression Loss: 3.3060\n","Timer: 0.5624 sec.\n","tensor(2.1310, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2561 || Loss: 6.0755 || Conf Loss: 3.9446 || Regression Loss: 2.1310\n","Timer: 0.5749 sec.\n","tensor(1.5943, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2562 || Loss: 5.7385 || Conf Loss: 4.1443 || Regression Loss: 1.5943\n","Timer: 0.5390 sec.\n","tensor(1.6756, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2563 || Loss: 5.0651 || Conf Loss: 3.3895 || Regression Loss: 1.6756\n","Timer: 0.5914 sec.\n","tensor(4.1829, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2564 || Loss: 6.1730 || Conf Loss: 1.9902 || Regression Loss: 4.1829\n","Timer: 0.5680 sec.\n","tensor(0.0878, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2565 || Loss: 2.1042 || Conf Loss: 2.0164 || Regression Loss: 0.0878\n","Timer: 0.5447 sec.\n","tensor(5.4436, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2566 || Loss: 7.5218 || Conf Loss: 2.0782 || Regression Loss: 5.4436\n","Timer: 0.5406 sec.\n","tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2567 || Loss: 2.2594 || Conf Loss: 2.1849 || Regression Loss: 0.0745\n","Timer: 0.6114 sec.\n","tensor(0.0592, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2568 || Loss: 2.3562 || Conf Loss: 2.2970 || Regression Loss: 0.0592\n","Timer: 0.6609 sec.\n","tensor(2.0050, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2569 || Loss: 5.5617 || Conf Loss: 3.5567 || Regression Loss: 2.0050\n","Timer: 0.5470 sec.\n","tensor(3.5422, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2570 || Loss: 5.9873 || Conf Loss: 2.4451 || Regression Loss: 3.5422\n","Timer: 0.6912 sec.\n","tensor(1.2848, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2571 || Loss: 3.3426 || Conf Loss: 2.0577 || Regression Loss: 1.2848\n","Timer: 0.5545 sec.\n","tensor(3.7647, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2572 || Loss: 5.8520 || Conf Loss: 2.0873 || Regression Loss: 3.7647\n","Timer: 0.5397 sec.\n","tensor(5.2076, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2573 || Loss: 7.2222 || Conf Loss: 2.0146 || Regression Loss: 5.2076\n","Timer: 0.5682 sec.\n","tensor(2.0428, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2574 || Loss: 4.4847 || Conf Loss: 2.4419 || Regression Loss: 2.0428\n","Timer: 0.6404 sec.\n","tensor(4.0857, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2575 || Loss: 6.9160 || Conf Loss: 2.8303 || Regression Loss: 4.0857\n","Timer: 0.6546 sec.\n","tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2576 || Loss: 2.3797 || Conf Loss: 2.2106 || Regression Loss: 0.1690\n","Timer: 0.5457 sec.\n","tensor(0.4198, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2577 || Loss: 2.2759 || Conf Loss: 1.8560 || Regression Loss: 0.4198\n","Timer: 0.5822 sec.\n","tensor(1.1214, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2578 || Loss: 3.1868 || Conf Loss: 2.0654 || Regression Loss: 1.1214\n","Timer: 0.7071 sec.\n","tensor(1.9706, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2579 || Loss: 5.3782 || Conf Loss: 3.4075 || Regression Loss: 1.9706\n","Timer: 0.5805 sec.\n","tensor(3.0086, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2580 || Loss: 5.0279 || Conf Loss: 2.0193 || Regression Loss: 3.0086\n","Timer: 0.5484 sec.\n","tensor(2.6013, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2581 || Loss: 5.0279 || Conf Loss: 2.4266 || Regression Loss: 2.6013\n","Timer: 0.6246 sec.\n","tensor(4.5566, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2582 || Loss: 6.7042 || Conf Loss: 2.1477 || Regression Loss: 4.5566\n","Timer: 0.5729 sec.\n","tensor(2.9852, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2583 || Loss: 4.8942 || Conf Loss: 1.9089 || Regression Loss: 2.9852\n","Timer: 0.5455 sec.\n","tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2584 || Loss: 2.2696 || Conf Loss: 2.1780 || Regression Loss: 0.0917\n","Timer: 0.6798 sec.\n","tensor(3.1116, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2585 || Loss: 5.8114 || Conf Loss: 2.6997 || Regression Loss: 3.1116\n","Timer: 0.5907 sec.\n","tensor(2.8930, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2586 || Loss: 4.9563 || Conf Loss: 2.0633 || Regression Loss: 2.8930\n","Timer: 0.5961 sec.\n","tensor(4.4481, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2587 || Loss: 6.6668 || Conf Loss: 2.2187 || Regression Loss: 4.4481\n","Timer: 0.5331 sec.\n","tensor(1.1781, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2588 || Loss: 3.1903 || Conf Loss: 2.0122 || Regression Loss: 1.1781\n","Timer: 0.6228 sec.\n","tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2589 || Loss: 2.0522 || Conf Loss: 1.9376 || Regression Loss: 0.1146\n","Timer: 0.5346 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2590 || Loss: 1.2947 || Conf Loss: 1.2947 || Regression Loss: 0.0000\n","Timer: 0.5693 sec.\n","tensor(1.9825, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2591 || Loss: 4.2512 || Conf Loss: 2.2687 || Regression Loss: 1.9825\n","Timer: 0.6044 sec.\n","tensor(2.8923, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2592 || Loss: 6.6620 || Conf Loss: 3.7697 || Regression Loss: 2.8923\n","Timer: 0.6603 sec.\n","tensor(2.5724, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2593 || Loss: 5.9291 || Conf Loss: 3.3567 || Regression Loss: 2.5724\n","Timer: 0.5530 sec.\n","tensor(2.8104, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2594 || Loss: 5.0118 || Conf Loss: 2.2014 || Regression Loss: 2.8104\n","Timer: 0.7152 sec.\n","tensor(3.8821, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2595 || Loss: 5.8421 || Conf Loss: 1.9600 || Regression Loss: 3.8821\n","Timer: 0.5525 sec.\n","tensor(5.3103, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2596 || Loss: 7.3774 || Conf Loss: 2.0671 || Regression Loss: 5.3103\n","Timer: 0.6797 sec.\n","tensor(5.4834, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2597 || Loss: 7.5248 || Conf Loss: 2.0414 || Regression Loss: 5.4834\n","Timer: 0.6016 sec.\n","tensor(2.1409, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2598 || Loss: 4.0265 || Conf Loss: 1.8857 || Regression Loss: 2.1409\n","Timer: 0.5714 sec.\n","tensor(5.3096, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2599 || Loss: 7.2187 || Conf Loss: 1.9090 || Regression Loss: 5.3096\n","Timer: 0.5900 sec.\n","tensor(5.0597, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2600 || Loss: 7.2219 || Conf Loss: 2.1622 || Regression Loss: 5.0597\n","Timer: 0.5639 sec.\n","tensor(0.1252, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2601 || Loss: 2.0783 || Conf Loss: 1.9531 || Regression Loss: 0.1252\n","Timer: 0.5657 sec.\n","tensor(4.0156, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2602 || Loss: 6.3174 || Conf Loss: 2.3018 || Regression Loss: 4.0156\n","Timer: 0.6018 sec.\n","tensor(5.0117, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2603 || Loss: 8.2538 || Conf Loss: 3.2422 || Regression Loss: 5.0117\n","Timer: 0.5657 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2604 || Loss: 1.0323 || Conf Loss: 1.0323 || Regression Loss: 0.0000\n","Timer: 0.6411 sec.\n","tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2605 || Loss: 2.1745 || Conf Loss: 2.0827 || Regression Loss: 0.0918\n","Timer: 0.6314 sec.\n","tensor(1.5300, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2606 || Loss: 4.3709 || Conf Loss: 2.8409 || Regression Loss: 1.5300\n","Timer: 0.7008 sec.\n","tensor(3.1287, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2607 || Loss: 5.4225 || Conf Loss: 2.2939 || Regression Loss: 3.1287\n","Timer: 0.5911 sec.\n","tensor(3.5135, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2608 || Loss: 5.3673 || Conf Loss: 1.8539 || Regression Loss: 3.5135\n","Timer: 0.5833 sec.\n","tensor(2.4406, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2609 || Loss: 4.8297 || Conf Loss: 2.3890 || Regression Loss: 2.4406\n","Timer: 0.6218 sec.\n","tensor(2.9085, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2610 || Loss: 5.8503 || Conf Loss: 2.9418 || Regression Loss: 2.9085\n","Timer: 0.5465 sec.\n","tensor(3.9318, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2611 || Loss: 5.9248 || Conf Loss: 1.9930 || Regression Loss: 3.9318\n","Timer: 0.5582 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2612 || Loss: 1.0548 || Conf Loss: 1.0548 || Regression Loss: 0.0000\n","Timer: 0.5867 sec.\n","tensor(2.2993, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2613 || Loss: 4.1923 || Conf Loss: 1.8930 || Regression Loss: 2.2993\n","Timer: 0.5698 sec.\n","tensor(4.0066, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2614 || Loss: 6.0501 || Conf Loss: 2.0436 || Regression Loss: 4.0066\n","Timer: 0.5778 sec.\n","tensor(4.3290, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2615 || Loss: 6.2424 || Conf Loss: 1.9134 || Regression Loss: 4.3290\n","Timer: 0.5851 sec.\n","tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2616 || Loss: 2.1483 || Conf Loss: 1.8631 || Regression Loss: 0.2852\n","Timer: 0.5926 sec.\n","tensor(0.1132, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2617 || Loss: 2.1264 || Conf Loss: 2.0132 || Regression Loss: 0.1132\n","Timer: 0.5614 sec.\n","tensor(4.4438, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2618 || Loss: 6.3195 || Conf Loss: 1.8758 || Regression Loss: 4.4438\n","Timer: 0.5938 sec.\n","tensor(0.9970, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2619 || Loss: 3.6711 || Conf Loss: 2.6742 || Regression Loss: 0.9970\n","Timer: 0.6659 sec.\n","tensor(1.0986, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2620 || Loss: 3.0196 || Conf Loss: 1.9210 || Regression Loss: 1.0986\n","Timer: 0.6958 sec.\n","tensor(3.3689, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2621 || Loss: 6.7150 || Conf Loss: 3.3461 || Regression Loss: 3.3689\n","Timer: 0.6225 sec.\n","tensor(2.4386, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2622 || Loss: 4.3006 || Conf Loss: 1.8620 || Regression Loss: 2.4386\n","Timer: 0.7476 sec.\n","tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2623 || Loss: 2.1876 || Conf Loss: 1.9331 || Regression Loss: 0.2545\n","Timer: 0.6231 sec.\n","tensor(5.8207, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2624 || Loss: 8.1418 || Conf Loss: 2.3211 || Regression Loss: 5.8207\n","Timer: 0.5892 sec.\n","tensor(2.0951, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2625 || Loss: 4.6127 || Conf Loss: 2.5176 || Regression Loss: 2.0951\n","Timer: 0.6235 sec.\n","tensor(1.3602, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2626 || Loss: 3.4153 || Conf Loss: 2.0551 || Regression Loss: 1.3602\n","Timer: 0.5937 sec.\n","tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2627 || Loss: 2.1142 || Conf Loss: 1.8679 || Regression Loss: 0.2463\n","Timer: 0.6137 sec.\n","tensor(3.3672, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2628 || Loss: 5.8180 || Conf Loss: 2.4508 || Regression Loss: 3.3672\n","Timer: 0.5825 sec.\n","tensor(4.3284, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2629 || Loss: 6.2823 || Conf Loss: 1.9539 || Regression Loss: 4.3284\n","Timer: 0.5789 sec.\n","tensor(0.8873, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2630 || Loss: 3.0466 || Conf Loss: 2.1593 || Regression Loss: 0.8873\n","Timer: 0.5679 sec.\n","tensor(0.0940, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2631 || Loss: 2.0029 || Conf Loss: 1.9089 || Regression Loss: 0.0940\n","Timer: 0.5366 sec.\n","tensor(2.2363, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2632 || Loss: 6.9201 || Conf Loss: 4.6838 || Regression Loss: 2.2363\n","Timer: 0.6037 sec.\n","tensor(1.4677, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2633 || Loss: 4.8784 || Conf Loss: 3.4107 || Regression Loss: 1.4677\n","Timer: 0.6112 sec.\n","tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2634 || Loss: 1.9562 || Conf Loss: 1.8903 || Regression Loss: 0.0659\n","Timer: 0.5628 sec.\n","tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2635 || Loss: 2.3377 || Conf Loss: 2.0983 || Regression Loss: 0.2394\n","Timer: 0.6280 sec.\n","tensor(1.8808, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2636 || Loss: 4.1011 || Conf Loss: 2.2203 || Regression Loss: 1.8808\n","Timer: 0.5788 sec.\n","tensor(3.5372, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2637 || Loss: 5.4800 || Conf Loss: 1.9428 || Regression Loss: 3.5372\n","Timer: 0.5530 sec.\n","tensor(6.6256, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2638 || Loss: 9.8747 || Conf Loss: 3.2491 || Regression Loss: 6.6256\n","Timer: 0.5268 sec.\n","tensor(4.6010, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2639 || Loss: 8.3051 || Conf Loss: 3.7041 || Regression Loss: 4.6010\n","Timer: 0.5617 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2640 || Loss: 1.2925 || Conf Loss: 1.2925 || Regression Loss: 0.0000\n","Timer: 0.6418 sec.\n","tensor(1.4712, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2641 || Loss: 4.7814 || Conf Loss: 3.3102 || Regression Loss: 1.4712\n","Timer: 0.6110 sec.\n","tensor(0.5677, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2642 || Loss: 3.8947 || Conf Loss: 3.3270 || Regression Loss: 0.5677\n","Timer: 0.5732 sec.\n","tensor(1.0763, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2643 || Loss: 3.0906 || Conf Loss: 2.0143 || Regression Loss: 1.0763\n","Timer: 0.6423 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2644 || Loss: 1.2485 || Conf Loss: 1.2485 || Regression Loss: 0.0000\n","Timer: 0.6827 sec.\n","tensor(0.6729, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2645 || Loss: 3.5389 || Conf Loss: 2.8660 || Regression Loss: 0.6729\n","Timer: 0.5368 sec.\n","tensor(0.7658, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2646 || Loss: 2.8841 || Conf Loss: 2.1183 || Regression Loss: 0.7658\n","Timer: 0.6321 sec.\n","tensor(2.6473, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2647 || Loss: 4.9149 || Conf Loss: 2.2677 || Regression Loss: 2.6473\n","Timer: 0.5677 sec.\n","tensor(5.6188, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2648 || Loss: 8.6464 || Conf Loss: 3.0276 || Regression Loss: 5.6188\n","Timer: 0.6624 sec.\n","tensor(2.7010, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2649 || Loss: 4.7788 || Conf Loss: 2.0778 || Regression Loss: 2.7010\n","Timer: 0.6333 sec.\n","tensor(5.2644, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2650 || Loss: 7.5462 || Conf Loss: 2.2818 || Regression Loss: 5.2644\n","Timer: 0.5538 sec.\n","tensor(1.3661, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2651 || Loss: 3.4781 || Conf Loss: 2.1120 || Regression Loss: 1.3661\n","Timer: 0.6052 sec.\n","tensor(5.4122, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2652 || Loss: 7.5355 || Conf Loss: 2.1233 || Regression Loss: 5.4122\n","Timer: 0.5514 sec.\n","tensor(3.4317, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2653 || Loss: 5.3995 || Conf Loss: 1.9678 || Regression Loss: 3.4317\n","Timer: 0.7115 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2654 || Loss: 1.1298 || Conf Loss: 1.1298 || Regression Loss: 0.0000\n","Timer: 0.5894 sec.\n","tensor(3.8521, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2655 || Loss: 5.9275 || Conf Loss: 2.0754 || Regression Loss: 3.8521\n","Timer: 0.7054 sec.\n","tensor(4.0646, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2656 || Loss: 6.1182 || Conf Loss: 2.0535 || Regression Loss: 4.0646\n","Timer: 0.6633 sec.\n","tensor(2.9697, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2657 || Loss: 4.9434 || Conf Loss: 1.9736 || Regression Loss: 2.9697\n","Timer: 0.6135 sec.\n","tensor(0.1061, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2658 || Loss: 2.1492 || Conf Loss: 2.0431 || Regression Loss: 0.1061\n","Timer: 0.5409 sec.\n","tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2659 || Loss: 2.1546 || Conf Loss: 1.9948 || Regression Loss: 0.1598\n","Timer: 0.7564 sec.\n","tensor(4.0481, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2660 || Loss: 6.7124 || Conf Loss: 2.6642 || Regression Loss: 4.0481\n","Timer: 0.5610 sec.\n","tensor(1.7032, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2661 || Loss: 3.6448 || Conf Loss: 1.9416 || Regression Loss: 1.7032\n","Timer: 0.6598 sec.\n","tensor(2.9632, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2662 || Loss: 5.0266 || Conf Loss: 2.0634 || Regression Loss: 2.9632\n","Timer: 0.6226 sec.\n","tensor(0.2363, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2663 || Loss: 2.3828 || Conf Loss: 2.1465 || Regression Loss: 0.2363\n","Timer: 0.6031 sec.\n","tensor(1.0585, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2664 || Loss: 3.7741 || Conf Loss: 2.7155 || Regression Loss: 1.0585\n","Timer: 0.5846 sec.\n","tensor(4.2169, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2665 || Loss: 7.3659 || Conf Loss: 3.1489 || Regression Loss: 4.2169\n","Timer: 0.6194 sec.\n","tensor(4.2213, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2666 || Loss: 7.2724 || Conf Loss: 3.0512 || Regression Loss: 4.2213\n","Timer: 0.6316 sec.\n","tensor(1.3783, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2667 || Loss: 3.3313 || Conf Loss: 1.9530 || Regression Loss: 1.3783\n","Timer: 0.5587 sec.\n","tensor(1.7846, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2668 || Loss: 3.7566 || Conf Loss: 1.9719 || Regression Loss: 1.7846\n","Timer: 0.7188 sec.\n","tensor(2.1578, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2669 || Loss: 4.5208 || Conf Loss: 2.3631 || Regression Loss: 2.1578\n","Timer: 0.6378 sec.\n","tensor(0.5138, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2670 || Loss: 2.5763 || Conf Loss: 2.0625 || Regression Loss: 0.5138\n","Timer: 0.5741 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2671 || Loss: 1.1908 || Conf Loss: 1.1908 || Regression Loss: 0.0000\n","Timer: 0.6199 sec.\n","tensor(2.1574, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2672 || Loss: 6.2019 || Conf Loss: 4.0444 || Regression Loss: 2.1574\n","Timer: 0.5823 sec.\n","tensor(5.4770, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2673 || Loss: 8.2269 || Conf Loss: 2.7499 || Regression Loss: 5.4770\n","Timer: 0.5612 sec.\n","tensor(1.2308, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2674 || Loss: 4.1257 || Conf Loss: 2.8948 || Regression Loss: 1.2308\n","Timer: 0.6664 sec.\n","tensor(2.3710, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2675 || Loss: 4.3316 || Conf Loss: 1.9606 || Regression Loss: 2.3710\n","Timer: 0.5889 sec.\n","tensor(0.1147, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2676 || Loss: 2.0792 || Conf Loss: 1.9646 || Regression Loss: 0.1147\n","Timer: 0.6655 sec.\n","tensor(2.1327, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2677 || Loss: 4.2272 || Conf Loss: 2.0944 || Regression Loss: 2.1327\n","Timer: 0.5599 sec.\n","tensor(3.8531, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2678 || Loss: 5.7962 || Conf Loss: 1.9431 || Regression Loss: 3.8531\n","Timer: 0.6324 sec.\n","tensor(3.2125, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2679 || Loss: 6.2603 || Conf Loss: 3.0478 || Regression Loss: 3.2125\n","Timer: 0.5603 sec.\n","tensor(5.3732, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2680 || Loss: 7.3548 || Conf Loss: 1.9816 || Regression Loss: 5.3732\n","Timer: 0.5434 sec.\n","tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2681 || Loss: 2.2449 || Conf Loss: 2.1478 || Regression Loss: 0.0970\n","Timer: 0.6099 sec.\n","tensor(3.4798, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2682 || Loss: 5.4363 || Conf Loss: 1.9565 || Regression Loss: 3.4798\n","Timer: 0.5723 sec.\n","tensor(0.5489, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2683 || Loss: 2.9108 || Conf Loss: 2.3619 || Regression Loss: 0.5489\n","Timer: 0.5347 sec.\n","tensor(2.1828, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2684 || Loss: 4.9922 || Conf Loss: 2.8094 || Regression Loss: 2.1828\n","Timer: 0.7496 sec.\n","tensor(4.0937, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2685 || Loss: 6.0800 || Conf Loss: 1.9862 || Regression Loss: 4.0937\n","Timer: 0.6240 sec.\n","tensor(1.6959, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2686 || Loss: 3.7506 || Conf Loss: 2.0546 || Regression Loss: 1.6959\n","Timer: 0.6707 sec.\n","tensor(0.0934, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2687 || Loss: 2.0530 || Conf Loss: 1.9595 || Regression Loss: 0.0934\n","Timer: 0.5576 sec.\n","tensor(2.6000, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2688 || Loss: 4.5156 || Conf Loss: 1.9156 || Regression Loss: 2.6000\n","Timer: 0.7603 sec.\n","tensor(2.1408, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2689 || Loss: 6.1908 || Conf Loss: 4.0499 || Regression Loss: 2.1408\n","Timer: 0.5982 sec.\n","tensor(3.6181, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2690 || Loss: 5.9925 || Conf Loss: 2.3744 || Regression Loss: 3.6181\n","Timer: 0.5749 sec.\n","tensor(3.9513, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2691 || Loss: 6.1567 || Conf Loss: 2.2054 || Regression Loss: 3.9513\n","Timer: 0.5817 sec.\n","tensor(3.1184, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2692 || Loss: 5.0423 || Conf Loss: 1.9239 || Regression Loss: 3.1184\n","Timer: 0.5513 sec.\n","tensor(3.1316, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2693 || Loss: 4.9994 || Conf Loss: 1.8678 || Regression Loss: 3.1316\n","Timer: 0.6846 sec.\n","tensor(5.2376, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2694 || Loss: 8.5972 || Conf Loss: 3.3596 || Regression Loss: 5.2376\n","Timer: 0.6371 sec.\n","tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2695 || Loss: 3.3404 || Conf Loss: 2.8546 || Regression Loss: 0.4858\n","Timer: 0.5691 sec.\n","tensor(5.2794, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2696 || Loss: 7.2934 || Conf Loss: 2.0139 || Regression Loss: 5.2794\n","Timer: 0.5479 sec.\n","tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2697 || Loss: 2.0893 || Conf Loss: 2.0367 || Regression Loss: 0.0527\n","Timer: 0.5582 sec.\n","tensor(5.3896, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2698 || Loss: 7.9135 || Conf Loss: 2.5239 || Regression Loss: 5.3896\n","Timer: 0.6274 sec.\n","tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2699 || Loss: 1.9753 || Conf Loss: 1.8694 || Regression Loss: 0.1059\n","Timer: 0.6041 sec.\n","tensor(0.4194, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2700 || Loss: 2.5096 || Conf Loss: 2.0901 || Regression Loss: 0.4194\n","Timer: 0.5929 sec.\n","tensor(2.2612, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2701 || Loss: 6.7645 || Conf Loss: 4.5033 || Regression Loss: 2.2612\n","Timer: 0.5578 sec.\n","tensor(5.3258, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2702 || Loss: 7.2607 || Conf Loss: 1.9348 || Regression Loss: 5.3258\n","Timer: 0.6721 sec.\n","tensor(5.1066, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2703 || Loss: 7.2832 || Conf Loss: 2.1766 || Regression Loss: 5.1066\n","Timer: 0.6922 sec.\n","tensor(3.4053, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2704 || Loss: 6.9692 || Conf Loss: 3.5639 || Regression Loss: 3.4053\n","Timer: 0.6546 sec.\n","tensor(4.5251, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2705 || Loss: 6.4078 || Conf Loss: 1.8827 || Regression Loss: 4.5251\n","Timer: 0.5797 sec.\n","tensor(0.1959, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2706 || Loss: 2.1332 || Conf Loss: 1.9373 || Regression Loss: 0.1959\n","Timer: 0.5862 sec.\n","tensor(2.7913, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2707 || Loss: 4.8133 || Conf Loss: 2.0220 || Regression Loss: 2.7913\n","Timer: 0.5965 sec.\n","tensor(4.4903, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2708 || Loss: 6.4239 || Conf Loss: 1.9336 || Regression Loss: 4.4903\n","Timer: 0.7178 sec.\n","tensor(3.6860, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2709 || Loss: 5.9799 || Conf Loss: 2.2939 || Regression Loss: 3.6860\n","Timer: 0.6227 sec.\n","tensor(0.1367, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2710 || Loss: 2.1475 || Conf Loss: 2.0108 || Regression Loss: 0.1367\n","Timer: 0.5598 sec.\n","tensor(0.5657, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2711 || Loss: 2.4511 || Conf Loss: 1.8854 || Regression Loss: 0.5657\n","Timer: 0.5976 sec.\n","tensor(0.4832, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2712 || Loss: 2.5142 || Conf Loss: 2.0311 || Regression Loss: 0.4832\n","Timer: 0.5268 sec.\n","tensor(1.8150, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2713 || Loss: 5.8467 || Conf Loss: 4.0317 || Regression Loss: 1.8150\n","Timer: 0.5441 sec.\n","tensor(4.5000, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2714 || Loss: 6.6859 || Conf Loss: 2.1859 || Regression Loss: 4.5000\n","Timer: 0.5830 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2715 || Loss: 1.1687 || Conf Loss: 1.1687 || Regression Loss: 0.0000\n","Timer: 0.5454 sec.\n","tensor(5.3531, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2716 || Loss: 7.2980 || Conf Loss: 1.9449 || Regression Loss: 5.3531\n","Timer: 0.5903 sec.\n","tensor(1.2167, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2717 || Loss: 4.0942 || Conf Loss: 2.8775 || Regression Loss: 1.2167\n","Timer: 0.5546 sec.\n","tensor(5.3234, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2718 || Loss: 7.2206 || Conf Loss: 1.8972 || Regression Loss: 5.3234\n","Timer: 0.5796 sec.\n","tensor(3.0949, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2719 || Loss: 5.3351 || Conf Loss: 2.2402 || Regression Loss: 3.0949\n","Timer: 0.6295 sec.\n","tensor(0.2128, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2720 || Loss: 2.1413 || Conf Loss: 1.9285 || Regression Loss: 0.2128\n","Timer: 0.5555 sec.\n","tensor(1.8860, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2721 || Loss: 4.6195 || Conf Loss: 2.7336 || Regression Loss: 1.8860\n","Timer: 0.6128 sec.\n","tensor(0.1506, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2722 || Loss: 2.0756 || Conf Loss: 1.9249 || Regression Loss: 0.1506\n","Timer: 0.6703 sec.\n","tensor(1.3887, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2723 || Loss: 5.0712 || Conf Loss: 3.6825 || Regression Loss: 1.3887\n","Timer: 0.5664 sec.\n","tensor(3.4788, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2724 || Loss: 5.5540 || Conf Loss: 2.0752 || Regression Loss: 3.4788\n","Timer: 0.6509 sec.\n","tensor(5.1655, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2725 || Loss: 7.4392 || Conf Loss: 2.2738 || Regression Loss: 5.1655\n","Timer: 0.5473 sec.\n","tensor(4.6538, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2726 || Loss: 6.5828 || Conf Loss: 1.9290 || Regression Loss: 4.6538\n","Timer: 0.5484 sec.\n","tensor(1.7148, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2727 || Loss: 3.7576 || Conf Loss: 2.0428 || Regression Loss: 1.7148\n","Timer: 0.5476 sec.\n","tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2728 || Loss: 2.1997 || Conf Loss: 1.9147 || Regression Loss: 0.2850\n","Timer: 0.5435 sec.\n","tensor(5.8506, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2729 || Loss: 7.9313 || Conf Loss: 2.0807 || Regression Loss: 5.8506\n","Timer: 0.5979 sec.\n","tensor(2.0799, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2730 || Loss: 4.6110 || Conf Loss: 2.5311 || Regression Loss: 2.0799\n","Timer: 0.7500 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2731 || Loss: 1.1852 || Conf Loss: 1.1852 || Regression Loss: 0.0000\n","Timer: 0.5700 sec.\n","tensor(0.1000, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2732 || Loss: 1.9762 || Conf Loss: 1.8763 || Regression Loss: 0.1000\n","Timer: 0.6327 sec.\n","tensor(1.9384, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2733 || Loss: 3.9012 || Conf Loss: 1.9628 || Regression Loss: 1.9384\n","Timer: 0.5950 sec.\n","tensor(2.8937, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2734 || Loss: 6.5866 || Conf Loss: 3.6929 || Regression Loss: 2.8937\n","Timer: 0.6031 sec.\n","tensor(2.6290, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2735 || Loss: 4.7583 || Conf Loss: 2.1293 || Regression Loss: 2.6290\n","Timer: 0.5326 sec.\n","tensor(0.5012, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2736 || Loss: 2.3440 || Conf Loss: 1.8428 || Regression Loss: 0.5012\n","Timer: 0.7187 sec.\n","tensor(0.3478, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2737 || Loss: 2.3996 || Conf Loss: 2.0518 || Regression Loss: 0.3478\n","Timer: 0.5651 sec.\n","tensor(1.2406, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2738 || Loss: 4.2200 || Conf Loss: 2.9794 || Regression Loss: 1.2406\n","Timer: 0.6151 sec.\n","tensor(2.3257, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2739 || Loss: 6.2009 || Conf Loss: 3.8753 || Regression Loss: 2.3257\n","Timer: 0.6096 sec.\n","tensor(0.1329, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2740 || Loss: 2.2529 || Conf Loss: 2.1200 || Regression Loss: 0.1329\n","Timer: 0.6793 sec.\n","tensor(1.9974, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2741 || Loss: 3.9137 || Conf Loss: 1.9163 || Regression Loss: 1.9974\n","Timer: 0.5655 sec.\n","tensor(1.8523, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2742 || Loss: 5.4266 || Conf Loss: 3.5744 || Regression Loss: 1.8523\n","Timer: 0.5728 sec.\n","tensor(3.1783, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2743 || Loss: 8.5645 || Conf Loss: 5.3862 || Regression Loss: 3.1783\n","Timer: 0.6068 sec.\n","tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2744 || Loss: 2.2927 || Conf Loss: 2.1813 || Regression Loss: 0.1114\n","Timer: 0.5702 sec.\n","tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2745 || Loss: 2.2245 || Conf Loss: 2.1095 || Regression Loss: 0.1150\n","Timer: 0.5721 sec.\n","tensor(3.0848, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2746 || Loss: 5.6410 || Conf Loss: 2.5563 || Regression Loss: 3.0848\n","Timer: 0.5630 sec.\n","tensor(1.5586, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2747 || Loss: 3.8285 || Conf Loss: 2.2699 || Regression Loss: 1.5586\n","Timer: 0.6126 sec.\n","tensor(0.1031, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2748 || Loss: 2.1558 || Conf Loss: 2.0527 || Regression Loss: 0.1031\n","Timer: 0.7054 sec.\n","tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2749 || Loss: 2.2554 || Conf Loss: 2.1175 || Regression Loss: 0.1378\n","Timer: 0.5959 sec.\n","tensor(5.2234, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2750 || Loss: 7.3392 || Conf Loss: 2.1159 || Regression Loss: 5.2234\n","Timer: 0.7138 sec.\n","tensor(3.0140, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2751 || Loss: 5.0232 || Conf Loss: 2.0092 || Regression Loss: 3.0140\n","Timer: 0.6230 sec.\n","tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2752 || Loss: 2.1405 || Conf Loss: 2.0350 || Regression Loss: 0.1054\n","Timer: 0.5617 sec.\n","tensor(1.0354, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2753 || Loss: 3.0037 || Conf Loss: 1.9684 || Regression Loss: 1.0354\n","Timer: 0.5328 sec.\n","tensor(1.8934, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2754 || Loss: 5.5588 || Conf Loss: 3.6654 || Regression Loss: 1.8934\n","Timer: 0.7018 sec.\n","tensor(2.6700, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2755 || Loss: 4.7811 || Conf Loss: 2.1111 || Regression Loss: 2.6700\n","Timer: 0.5689 sec.\n","tensor(2.8836, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2756 || Loss: 5.0780 || Conf Loss: 2.1944 || Regression Loss: 2.8836\n","Timer: 0.5758 sec.\n","tensor(1.2690, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2757 || Loss: 3.3187 || Conf Loss: 2.0497 || Regression Loss: 1.2690\n","Timer: 0.5422 sec.\n","tensor(3.6484, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2758 || Loss: 5.6321 || Conf Loss: 1.9837 || Regression Loss: 3.6484\n","Timer: 0.6912 sec.\n","tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2759 || Loss: 2.1532 || Conf Loss: 1.9464 || Regression Loss: 0.2068\n","Timer: 0.5986 sec.\n","tensor(4.9028, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2760 || Loss: 6.9387 || Conf Loss: 2.0359 || Regression Loss: 4.9028\n","Timer: 0.5902 sec.\n","tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2761 || Loss: 2.6628 || Conf Loss: 2.5016 || Regression Loss: 0.1611\n","Timer: 0.5558 sec.\n","tensor(3.1370, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2762 || Loss: 5.0558 || Conf Loss: 1.9188 || Regression Loss: 3.1370\n","Timer: 0.6822 sec.\n","tensor(5.6696, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2763 || Loss: 7.5780 || Conf Loss: 1.9084 || Regression Loss: 5.6696\n","Timer: 0.5431 sec.\n","tensor(0.7075, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2764 || Loss: 3.4687 || Conf Loss: 2.7612 || Regression Loss: 0.7075\n","Timer: 0.5902 sec.\n","tensor(4.9270, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2765 || Loss: 6.9098 || Conf Loss: 1.9829 || Regression Loss: 4.9270\n","Timer: 0.6000 sec.\n","tensor(0.1532, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2766 || Loss: 2.0378 || Conf Loss: 1.8846 || Regression Loss: 0.1532\n","Timer: 0.5705 sec.\n","tensor(1.1359, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2767 || Loss: 3.4097 || Conf Loss: 2.2738 || Regression Loss: 1.1359\n","Timer: 0.6702 sec.\n","tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2768 || Loss: 2.1486 || Conf Loss: 2.0073 || Regression Loss: 0.1413\n","Timer: 0.5245 sec.\n","tensor(1.2394, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2769 || Loss: 3.1833 || Conf Loss: 1.9439 || Regression Loss: 1.2394\n","Timer: 0.5804 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2770 || Loss: 1.1647 || Conf Loss: 1.1647 || Regression Loss: 0.0000\n","Timer: 0.5526 sec.\n","tensor(3.5297, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2771 || Loss: 5.4188 || Conf Loss: 1.8891 || Regression Loss: 3.5297\n","Timer: 0.5767 sec.\n","tensor(5.3473, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2772 || Loss: 7.3850 || Conf Loss: 2.0377 || Regression Loss: 5.3473\n","Timer: 0.5676 sec.\n","tensor(2.5076, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2773 || Loss: 4.4145 || Conf Loss: 1.9069 || Regression Loss: 2.5076\n","Timer: 0.6819 sec.\n","tensor(1.3469, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2774 || Loss: 3.2911 || Conf Loss: 1.9443 || Regression Loss: 1.3469\n","Timer: 0.5635 sec.\n","tensor(0.1378, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2775 || Loss: 2.1222 || Conf Loss: 1.9844 || Regression Loss: 0.1378\n","Timer: 0.5952 sec.\n","tensor(2.0426, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2776 || Loss: 5.6172 || Conf Loss: 3.5746 || Regression Loss: 2.0426\n","Timer: 0.6219 sec.\n","tensor(3.3863, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2777 || Loss: 5.7871 || Conf Loss: 2.4008 || Regression Loss: 3.3863\n","Timer: 0.5299 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2778 || Loss: 1.1442 || Conf Loss: 1.1442 || Regression Loss: 0.0000\n","Timer: 0.5698 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2779 || Loss: 1.1536 || Conf Loss: 1.1536 || Regression Loss: 0.0000\n","Timer: 0.5953 sec.\n","tensor(3.6779, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2780 || Loss: 6.1191 || Conf Loss: 2.4412 || Regression Loss: 3.6779\n","Timer: 0.6558 sec.\n","tensor(1.5055, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2781 || Loss: 4.4307 || Conf Loss: 2.9251 || Regression Loss: 1.5055\n","Timer: 0.6626 sec.\n","tensor(1.1973, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2782 || Loss: 3.0691 || Conf Loss: 1.8718 || Regression Loss: 1.1973\n","Timer: 0.5574 sec.\n","tensor(3.7364, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2783 || Loss: 5.5496 || Conf Loss: 1.8131 || Regression Loss: 3.7364\n","Timer: 0.6543 sec.\n","tensor(2.3904, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2784 || Loss: 5.9583 || Conf Loss: 3.5678 || Regression Loss: 2.3904\n","Timer: 0.6585 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2785 || Loss: 1.0994 || Conf Loss: 1.0994 || Regression Loss: 0.0000\n","Timer: 0.6231 sec.\n","tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2786 || Loss: 2.0013 || Conf Loss: 1.9195 || Regression Loss: 0.0817\n","Timer: 0.5813 sec.\n","tensor(2.2385, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2787 || Loss: 5.9823 || Conf Loss: 3.7438 || Regression Loss: 2.2385\n","Timer: 0.6175 sec.\n","tensor(4.1258, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2788 || Loss: 6.0708 || Conf Loss: 1.9451 || Regression Loss: 4.1258\n","Timer: 0.5799 sec.\n","tensor(3.8086, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2789 || Loss: 5.6920 || Conf Loss: 1.8834 || Regression Loss: 3.8086\n","Timer: 0.6261 sec.\n","tensor(2.3874, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2790 || Loss: 4.3055 || Conf Loss: 1.9181 || Regression Loss: 2.3874\n","Timer: 0.7143 sec.\n","tensor(0.1776, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2791 || Loss: 2.1512 || Conf Loss: 1.9736 || Regression Loss: 0.1776\n","Timer: 0.5916 sec.\n","tensor(0.0853, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2792 || Loss: 2.0503 || Conf Loss: 1.9650 || Regression Loss: 0.0853\n","Timer: 0.5445 sec.\n","tensor(1.8835, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2793 || Loss: 3.7939 || Conf Loss: 1.9104 || Regression Loss: 1.8835\n","Timer: 0.6053 sec.\n","tensor(5.0146, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2794 || Loss: 6.9857 || Conf Loss: 1.9710 || Regression Loss: 5.0146\n","Timer: 0.6363 sec.\n","tensor(2.7117, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2795 || Loss: 5.1610 || Conf Loss: 2.4493 || Regression Loss: 2.7117\n","Timer: 0.5694 sec.\n","tensor(3.5468, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2796 || Loss: 5.8884 || Conf Loss: 2.3415 || Regression Loss: 3.5468\n","Timer: 0.5359 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2797 || Loss: 1.0794 || Conf Loss: 1.0794 || Regression Loss: 0.0000\n","Timer: 0.5253 sec.\n","tensor(2.0275, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2798 || Loss: 4.4471 || Conf Loss: 2.4196 || Regression Loss: 2.0275\n","Timer: 0.5729 sec.\n","tensor(3.7617, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2799 || Loss: 5.5722 || Conf Loss: 1.8105 || Regression Loss: 3.7617\n","Timer: 0.6243 sec.\n","tensor(3.8096, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2800 || Loss: 6.8254 || Conf Loss: 3.0158 || Regression Loss: 3.8096\n","Timer: 0.5506 sec.\n","tensor(3.8664, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2801 || Loss: 5.8311 || Conf Loss: 1.9646 || Regression Loss: 3.8664\n","Timer: 0.6133 sec.\n","tensor(2.3766, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2802 || Loss: 4.1828 || Conf Loss: 1.8062 || Regression Loss: 2.3766\n","Timer: 0.5619 sec.\n","tensor(0.0515, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2803 || Loss: 1.9090 || Conf Loss: 1.8575 || Regression Loss: 0.0515\n","Timer: 0.6698 sec.\n","tensor(0.1164, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2804 || Loss: 1.9645 || Conf Loss: 1.8481 || Regression Loss: 0.1164\n","Timer: 0.5438 sec.\n","tensor(2.8883, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2805 || Loss: 4.6787 || Conf Loss: 1.7903 || Regression Loss: 2.8883\n","Timer: 0.5771 sec.\n","tensor(0.2333, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2806 || Loss: 2.0981 || Conf Loss: 1.8648 || Regression Loss: 0.2333\n","Timer: 0.5580 sec.\n","tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2807 || Loss: 2.3777 || Conf Loss: 2.0911 || Regression Loss: 0.2866\n","Timer: 0.6818 sec.\n","tensor(4.9926, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2808 || Loss: 6.9630 || Conf Loss: 1.9704 || Regression Loss: 4.9926\n","Timer: 0.5685 sec.\n","tensor(1.2608, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2809 || Loss: 3.9048 || Conf Loss: 2.6440 || Regression Loss: 1.2608\n","Timer: 0.6316 sec.\n","tensor(5.5891, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2810 || Loss: 7.3290 || Conf Loss: 1.7399 || Regression Loss: 5.5891\n","Timer: 0.5874 sec.\n","tensor(5.0030, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2811 || Loss: 6.7905 || Conf Loss: 1.7875 || Regression Loss: 5.0030\n","Timer: 0.6357 sec.\n","tensor(0.1084, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2812 || Loss: 1.7780 || Conf Loss: 1.6695 || Regression Loss: 0.1084\n","Timer: 0.5640 sec.\n","tensor(1.6700, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2813 || Loss: 5.6686 || Conf Loss: 3.9986 || Regression Loss: 1.6700\n","Timer: 0.5815 sec.\n","tensor(1.0663, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2814 || Loss: 4.5614 || Conf Loss: 3.4952 || Regression Loss: 1.0663\n","Timer: 0.6158 sec.\n","tensor(4.7963, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2815 || Loss: 6.9077 || Conf Loss: 2.1114 || Regression Loss: 4.7963\n","Timer: 0.5597 sec.\n","tensor(4.6885, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2816 || Loss: 6.7582 || Conf Loss: 2.0697 || Regression Loss: 4.6885\n","Timer: 0.5368 sec.\n","tensor(0.1028, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2817 || Loss: 2.1206 || Conf Loss: 2.0177 || Regression Loss: 0.1028\n","Timer: 0.5485 sec.\n","tensor(5.8881, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2818 || Loss: 7.9682 || Conf Loss: 2.0801 || Regression Loss: 5.8881\n","Timer: 0.5905 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2819 || Loss: 0.9778 || Conf Loss: 0.9778 || Regression Loss: 0.0000\n","Timer: 0.6282 sec.\n","tensor(5.5132, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2820 || Loss: 7.5061 || Conf Loss: 1.9929 || Regression Loss: 5.5132\n","Timer: 0.5517 sec.\n","tensor(3.1366, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2821 || Loss: 5.7952 || Conf Loss: 2.6586 || Regression Loss: 3.1366\n","Timer: 0.5373 sec.\n","tensor(2.1865, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2822 || Loss: 5.9850 || Conf Loss: 3.7985 || Regression Loss: 2.1865\n","Timer: 0.5775 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2823 || Loss: 1.0413 || Conf Loss: 1.0413 || Regression Loss: 0.0000\n","Timer: 0.5648 sec.\n","tensor(3.2800, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2824 || Loss: 5.7184 || Conf Loss: 2.4383 || Regression Loss: 3.2800\n","Timer: 0.5956 sec.\n","tensor(5.3610, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2825 || Loss: 7.3017 || Conf Loss: 1.9408 || Regression Loss: 5.3610\n","Timer: 0.5529 sec.\n","tensor(5.3495, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2826 || Loss: 7.2389 || Conf Loss: 1.8895 || Regression Loss: 5.3495\n","Timer: 0.6937 sec.\n","tensor(3.4558, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2827 || Loss: 5.6296 || Conf Loss: 2.1738 || Regression Loss: 3.4558\n","Timer: 0.6715 sec.\n","tensor(3.0072, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2828 || Loss: 7.6524 || Conf Loss: 4.6452 || Regression Loss: 3.0072\n","Timer: 0.6142 sec.\n","tensor(2.7377, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2829 || Loss: 4.9282 || Conf Loss: 2.1905 || Regression Loss: 2.7377\n","Timer: 0.5251 sec.\n","tensor(0.0998, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2830 || Loss: 2.0966 || Conf Loss: 1.9968 || Regression Loss: 0.0998\n","Timer: 0.5728 sec.\n","tensor(3.4321, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2831 || Loss: 5.3285 || Conf Loss: 1.8964 || Regression Loss: 3.4321\n","Timer: 0.5599 sec.\n","tensor(4.1470, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2832 || Loss: 6.0039 || Conf Loss: 1.8569 || Regression Loss: 4.1470\n","Timer: 0.5604 sec.\n","tensor(1.7128, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2833 || Loss: 3.6590 || Conf Loss: 1.9462 || Regression Loss: 1.7128\n","Timer: 0.5992 sec.\n","tensor(2.8564, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2834 || Loss: 4.6669 || Conf Loss: 1.8105 || Regression Loss: 2.8564\n","Timer: 0.5548 sec.\n","tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2835 || Loss: 2.1546 || Conf Loss: 2.0697 || Regression Loss: 0.0849\n","Timer: 0.5484 sec.\n","tensor(0.0755, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2836 || Loss: 2.0305 || Conf Loss: 1.9549 || Regression Loss: 0.0755\n","Timer: 0.6720 sec.\n","tensor(0.7984, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2837 || Loss: 3.4394 || Conf Loss: 2.6410 || Regression Loss: 0.7984\n","Timer: 0.5998 sec.\n","tensor(3.8763, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2838 || Loss: 5.7340 || Conf Loss: 1.8577 || Regression Loss: 3.8763\n","Timer: 0.5907 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2839 || Loss: 1.2625 || Conf Loss: 1.2625 || Regression Loss: 0.0000\n","Timer: 0.5441 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2840 || Loss: 1.0309 || Conf Loss: 1.0309 || Regression Loss: 0.0000\n","Timer: 0.6003 sec.\n","tensor(0.1089, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2841 || Loss: 1.9130 || Conf Loss: 1.8041 || Regression Loss: 0.1089\n","Timer: 0.5686 sec.\n","tensor(1.8829, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2842 || Loss: 4.9681 || Conf Loss: 3.0852 || Regression Loss: 1.8829\n","Timer: 0.5461 sec.\n","tensor(1.7699, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2843 || Loss: 5.1872 || Conf Loss: 3.4173 || Regression Loss: 1.7699\n","Timer: 0.5751 sec.\n","tensor(0.4738, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2844 || Loss: 2.6757 || Conf Loss: 2.2019 || Regression Loss: 0.4738\n","Timer: 0.7454 sec.\n","tensor(3.5566, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2845 || Loss: 6.8998 || Conf Loss: 3.3433 || Regression Loss: 3.5566\n","Timer: 0.5705 sec.\n","tensor(2.6871, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2846 || Loss: 5.2230 || Conf Loss: 2.5359 || Regression Loss: 2.6871\n","Timer: 0.7142 sec.\n","tensor(5.2240, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2847 || Loss: 7.3090 || Conf Loss: 2.0851 || Regression Loss: 5.2240\n","Timer: 0.5611 sec.\n","tensor(0.1098, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2848 || Loss: 2.0015 || Conf Loss: 1.8916 || Regression Loss: 0.1098\n","Timer: 0.6559 sec.\n","tensor(2.0456, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2849 || Loss: 4.1019 || Conf Loss: 2.0563 || Regression Loss: 2.0456\n","Timer: 0.5729 sec.\n","tensor(2.0963, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2850 || Loss: 5.2561 || Conf Loss: 3.1598 || Regression Loss: 2.0963\n","Timer: 0.5984 sec.\n","tensor(2.8657, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2851 || Loss: 4.8557 || Conf Loss: 1.9900 || Regression Loss: 2.8657\n","Timer: 0.5828 sec.\n","tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2852 || Loss: 1.8836 || Conf Loss: 1.8186 || Regression Loss: 0.0651\n","Timer: 0.6003 sec.\n","tensor(1.2226, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2853 || Loss: 3.0932 || Conf Loss: 1.8707 || Regression Loss: 1.2226\n","Timer: 0.5666 sec.\n","tensor(2.8027, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2854 || Loss: 4.5953 || Conf Loss: 1.7925 || Regression Loss: 2.8027\n","Timer: 0.6134 sec.\n","tensor(5.1581, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2855 || Loss: 7.0250 || Conf Loss: 1.8669 || Regression Loss: 5.1581\n","Timer: 0.6430 sec.\n","tensor(5.0744, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2856 || Loss: 6.8456 || Conf Loss: 1.7712 || Regression Loss: 5.0744\n","Timer: 0.5824 sec.\n","tensor(5.4127, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2857 || Loss: 7.5780 || Conf Loss: 2.1653 || Regression Loss: 5.4127\n","Timer: 0.6019 sec.\n","tensor(1.4311, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2858 || Loss: 3.3045 || Conf Loss: 1.8733 || Regression Loss: 1.4311\n","Timer: 0.5604 sec.\n","tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2859 || Loss: 1.8732 || Conf Loss: 1.7208 || Regression Loss: 0.1524\n","Timer: 0.5439 sec.\n","tensor(2.5872, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2860 || Loss: 4.5205 || Conf Loss: 1.9334 || Regression Loss: 2.5872\n","Timer: 0.6472 sec.\n","tensor(0.1445, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2861 || Loss: 1.9329 || Conf Loss: 1.7884 || Regression Loss: 0.1445\n","Timer: 0.5740 sec.\n","tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2862 || Loss: 1.8304 || Conf Loss: 1.7592 || Regression Loss: 0.0712\n","Timer: 0.5715 sec.\n","tensor(2.2903, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2863 || Loss: 5.9757 || Conf Loss: 3.6854 || Regression Loss: 2.2903\n","Timer: 0.5580 sec.\n","tensor(1.3281, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2864 || Loss: 3.8844 || Conf Loss: 2.5563 || Regression Loss: 1.3281\n","Timer: 0.5818 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2865 || Loss: 1.2833 || Conf Loss: 1.2833 || Regression Loss: 0.0000\n","Timer: 0.6468 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2866 || Loss: 1.2220 || Conf Loss: 1.2220 || Regression Loss: 0.0000\n","Timer: 0.5831 sec.\n","tensor(0.0517, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2867 || Loss: 1.9145 || Conf Loss: 1.8628 || Regression Loss: 0.0517\n","Timer: 0.6055 sec.\n","tensor(3.3765, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2868 || Loss: 6.2617 || Conf Loss: 2.8853 || Regression Loss: 3.3765\n","Timer: 0.5261 sec.\n","tensor(1.3138, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2869 || Loss: 4.7717 || Conf Loss: 3.4578 || Regression Loss: 1.3138\n","Timer: 0.5804 sec.\n","tensor(3.8788, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2870 || Loss: 5.7952 || Conf Loss: 1.9164 || Regression Loss: 3.8788\n","Timer: 0.6491 sec.\n","tensor(5.6080, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2871 || Loss: 7.8030 || Conf Loss: 2.1951 || Regression Loss: 5.6080\n","Timer: 0.6153 sec.\n","tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2872 || Loss: 2.0326 || Conf Loss: 1.9676 || Regression Loss: 0.0650\n","Timer: 0.6242 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2873 || Loss: 1.2164 || Conf Loss: 1.2164 || Regression Loss: 0.0000\n","Timer: 0.5617 sec.\n","tensor(0.0457, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2874 || Loss: 1.9259 || Conf Loss: 1.8803 || Regression Loss: 0.0457\n","Timer: 0.5528 sec.\n","tensor(3.8015, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2875 || Loss: 5.8654 || Conf Loss: 2.0639 || Regression Loss: 3.8015\n","Timer: 0.6262 sec.\n","tensor(2.1818, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2876 || Loss: 4.1374 || Conf Loss: 1.9556 || Regression Loss: 2.1818\n","Timer: 0.5325 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2877 || Loss: 0.9778 || Conf Loss: 0.9778 || Regression Loss: 0.0000\n","Timer: 0.6075 sec.\n","tensor(4.9310, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2878 || Loss: 6.8357 || Conf Loss: 1.9046 || Regression Loss: 4.9310\n","Timer: 0.6747 sec.\n","tensor(0.1854, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2879 || Loss: 2.0467 || Conf Loss: 1.8613 || Regression Loss: 0.1854\n","Timer: 0.5771 sec.\n","tensor(1.1038, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2880 || Loss: 3.3042 || Conf Loss: 2.2004 || Regression Loss: 1.1038\n","Timer: 0.6712 sec.\n","tensor(2.8235, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2881 || Loss: 6.6828 || Conf Loss: 3.8594 || Regression Loss: 2.8235\n","Timer: 0.5856 sec.\n","tensor(0.8686, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2882 || Loss: 2.7724 || Conf Loss: 1.9038 || Regression Loss: 0.8686\n","Timer: 0.5508 sec.\n","tensor(2.5240, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2883 || Loss: 4.3429 || Conf Loss: 1.8190 || Regression Loss: 2.5240\n","Timer: 0.5917 sec.\n","tensor(2.4923, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2884 || Loss: 5.3221 || Conf Loss: 2.8298 || Regression Loss: 2.4923\n","Timer: 0.6346 sec.\n","tensor(1.7238, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2885 || Loss: 3.8859 || Conf Loss: 2.1621 || Regression Loss: 1.7238\n","Timer: 0.5594 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2886 || Loss: 1.0933 || Conf Loss: 1.0933 || Regression Loss: 0.0000\n","Timer: 0.7097 sec.\n","tensor(1.1527, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2887 || Loss: 5.2907 || Conf Loss: 4.1381 || Regression Loss: 1.1527\n","Timer: 0.6030 sec.\n","tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2888 || Loss: 2.0052 || Conf Loss: 1.8923 || Regression Loss: 0.1129\n","Timer: 0.5353 sec.\n","tensor(0.1111, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2889 || Loss: 2.0083 || Conf Loss: 1.8972 || Regression Loss: 0.1111\n","Timer: 0.5535 sec.\n","tensor(3.7230, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2890 || Loss: 6.2368 || Conf Loss: 2.5138 || Regression Loss: 3.7230\n","Timer: 0.5496 sec.\n","tensor(0.0803, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2891 || Loss: 1.9629 || Conf Loss: 1.8826 || Regression Loss: 0.0803\n","Timer: 0.6713 sec.\n","tensor(4.5766, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2892 || Loss: 6.8808 || Conf Loss: 2.3041 || Regression Loss: 4.5766\n","Timer: 0.5144 sec.\n","tensor(4.1274, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2893 || Loss: 5.9154 || Conf Loss: 1.7880 || Regression Loss: 4.1274\n","Timer: 0.5740 sec.\n","tensor(3.9656, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2894 || Loss: 5.7653 || Conf Loss: 1.7996 || Regression Loss: 3.9656\n","Timer: 0.5827 sec.\n","tensor(0.0436, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2895 || Loss: 1.7433 || Conf Loss: 1.6997 || Regression Loss: 0.0436\n","Timer: 0.5953 sec.\n","tensor(4.0908, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2896 || Loss: 5.8686 || Conf Loss: 1.7778 || Regression Loss: 4.0908\n","Timer: 0.5453 sec.\n","tensor(0.4777, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2897 || Loss: 2.2601 || Conf Loss: 1.7824 || Regression Loss: 0.4777\n","Timer: 0.5594 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2898 || Loss: 0.9994 || Conf Loss: 0.9994 || Regression Loss: 0.0000\n","Timer: 0.5864 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2899 || Loss: 0.9601 || Conf Loss: 0.9601 || Regression Loss: 0.0000\n","Timer: 0.5449 sec.\n","tensor(3.4173, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2900 || Loss: 5.4634 || Conf Loss: 2.0461 || Regression Loss: 3.4173\n","Timer: 0.6250 sec.\n","tensor(0.1134, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2901 || Loss: 1.9704 || Conf Loss: 1.8569 || Regression Loss: 0.1134\n","Timer: 0.6151 sec.\n","tensor(1.3144, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2902 || Loss: 3.2154 || Conf Loss: 1.9010 || Regression Loss: 1.3144\n","Timer: 0.5534 sec.\n","tensor(4.0658, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2903 || Loss: 5.9315 || Conf Loss: 1.8657 || Regression Loss: 4.0658\n","Timer: 0.5602 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2904 || Loss: 1.1987 || Conf Loss: 1.1987 || Regression Loss: 0.0000\n","Timer: 0.6556 sec.\n","tensor(0.0534, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2905 || Loss: 1.9068 || Conf Loss: 1.8533 || Regression Loss: 0.0534\n","Timer: 0.5347 sec.\n","tensor(2.4994, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2906 || Loss: 4.7526 || Conf Loss: 2.2533 || Regression Loss: 2.4994\n","Timer: 0.7032 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2907 || Loss: 1.2256 || Conf Loss: 1.2256 || Regression Loss: 0.0000\n","Timer: 0.5967 sec.\n","tensor(2.6099, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2908 || Loss: 5.8635 || Conf Loss: 3.2536 || Regression Loss: 2.6099\n","Timer: 0.5916 sec.\n","tensor(5.0511, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2909 || Loss: 6.9392 || Conf Loss: 1.8881 || Regression Loss: 5.0511\n","Timer: 0.5540 sec.\n","tensor(0.0864, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2910 || Loss: 1.7984 || Conf Loss: 1.7120 || Regression Loss: 0.0864\n","Timer: 0.5292 sec.\n","tensor(1.8481, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2911 || Loss: 3.6249 || Conf Loss: 1.7768 || Regression Loss: 1.8481\n","Timer: 0.5321 sec.\n","tensor(1.7229, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2912 || Loss: 3.9396 || Conf Loss: 2.2167 || Regression Loss: 1.7229\n","Timer: 0.5925 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2913 || Loss: 1.0586 || Conf Loss: 1.0586 || Regression Loss: 0.0000\n","Timer: 0.5556 sec.\n","tensor(3.9975, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2914 || Loss: 5.6913 || Conf Loss: 1.6938 || Regression Loss: 3.9975\n","Timer: 0.5561 sec.\n","tensor(3.4612, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2915 || Loss: 5.2510 || Conf Loss: 1.7898 || Regression Loss: 3.4612\n","Timer: 0.6033 sec.\n","tensor(2.1769, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2916 || Loss: 6.0089 || Conf Loss: 3.8319 || Regression Loss: 2.1769\n","Timer: 0.5986 sec.\n","tensor(1.0302, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2917 || Loss: 4.3024 || Conf Loss: 3.2722 || Regression Loss: 1.0302\n","Timer: 0.6925 sec.\n","tensor(2.3329, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2918 || Loss: 4.3421 || Conf Loss: 2.0092 || Regression Loss: 2.3329\n","Timer: 0.6161 sec.\n","tensor(2.9578, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2919 || Loss: 4.7375 || Conf Loss: 1.7797 || Regression Loss: 2.9578\n","Timer: 0.6185 sec.\n","tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2920 || Loss: 1.9865 || Conf Loss: 1.9228 || Regression Loss: 0.0637\n","Timer: 0.5515 sec.\n","tensor(1.2319, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2921 || Loss: 3.2085 || Conf Loss: 1.9766 || Regression Loss: 1.2319\n","Timer: 0.5795 sec.\n","tensor(0.0941, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2922 || Loss: 1.8575 || Conf Loss: 1.7635 || Regression Loss: 0.0941\n","Timer: 0.5595 sec.\n","tensor(2.0384, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2923 || Loss: 4.2342 || Conf Loss: 2.1958 || Regression Loss: 2.0384\n","Timer: 0.6495 sec.\n","tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2924 || Loss: 2.0490 || Conf Loss: 1.8594 || Regression Loss: 0.1896\n","Timer: 0.6107 sec.\n","tensor(1.4098, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2925 || Loss: 4.5029 || Conf Loss: 3.0930 || Regression Loss: 1.4098\n","Timer: 0.5678 sec.\n","tensor(3.0612, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2926 || Loss: 4.8091 || Conf Loss: 1.7479 || Regression Loss: 3.0612\n","Timer: 0.5726 sec.\n","tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2927 || Loss: 1.8353 || Conf Loss: 1.7632 || Regression Loss: 0.0721\n","Timer: 0.6041 sec.\n","tensor(3.5526, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2928 || Loss: 5.9260 || Conf Loss: 2.3734 || Regression Loss: 3.5526\n","Timer: 0.5628 sec.\n","tensor(3.7176, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2929 || Loss: 5.7365 || Conf Loss: 2.0188 || Regression Loss: 3.7176\n","Timer: 0.5867 sec.\n","tensor(1.6201, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2930 || Loss: 3.4144 || Conf Loss: 1.7943 || Regression Loss: 1.6201\n","Timer: 0.5673 sec.\n","tensor(0.3929, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2931 || Loss: 2.4179 || Conf Loss: 2.0250 || Regression Loss: 0.3929\n","Timer: 0.6097 sec.\n","tensor(2.7455, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2932 || Loss: 4.8027 || Conf Loss: 2.0572 || Regression Loss: 2.7455\n","Timer: 0.6521 sec.\n","tensor(4.8609, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2933 || Loss: 6.6422 || Conf Loss: 1.7813 || Regression Loss: 4.8609\n","Timer: 0.5960 sec.\n","tensor(0.9664, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2934 || Loss: 2.7110 || Conf Loss: 1.7446 || Regression Loss: 0.9664\n","Timer: 0.5389 sec.\n","tensor(1.2005, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2935 || Loss: 5.8622 || Conf Loss: 4.6617 || Regression Loss: 1.2005\n","Timer: 0.5782 sec.\n","tensor(3.2845, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2936 || Loss: 7.9152 || Conf Loss: 4.6308 || Regression Loss: 3.2845\n","Timer: 0.6445 sec.\n","tensor(2.9423, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2937 || Loss: 6.5638 || Conf Loss: 3.6216 || Regression Loss: 2.9423\n","Timer: 0.5469 sec.\n","tensor(2.7168, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2938 || Loss: 4.6001 || Conf Loss: 1.8833 || Regression Loss: 2.7168\n","Timer: 0.5725 sec.\n","tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2939 || Loss: 2.3811 || Conf Loss: 2.2745 || Regression Loss: 0.1066\n","Timer: 0.6077 sec.\n","tensor(3.8940, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2940 || Loss: 5.7197 || Conf Loss: 1.8257 || Regression Loss: 3.8940\n","Timer: 0.6511 sec.\n","tensor(2.0209, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2941 || Loss: 5.8046 || Conf Loss: 3.7837 || Regression Loss: 2.0209\n","Timer: 0.5997 sec.\n","tensor(5.4988, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2942 || Loss: 7.3355 || Conf Loss: 1.8367 || Regression Loss: 5.4988\n","Timer: 0.5665 sec.\n","tensor(2.8900, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2943 || Loss: 5.5441 || Conf Loss: 2.6541 || Regression Loss: 2.8900\n","Timer: 0.5622 sec.\n","tensor(5.4550, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2944 || Loss: 8.1683 || Conf Loss: 2.7133 || Regression Loss: 5.4550\n","Timer: 0.5396 sec.\n","tensor(4.4342, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2945 || Loss: 6.5068 || Conf Loss: 2.0726 || Regression Loss: 4.4342\n","Timer: 0.5207 sec.\n","tensor(5.5946, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2946 || Loss: 7.4878 || Conf Loss: 1.8933 || Regression Loss: 5.5946\n","Timer: 0.5609 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2947 || Loss: 0.9316 || Conf Loss: 0.9316 || Regression Loss: 0.0000\n","Timer: 0.5826 sec.\n","tensor(5.5913, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2948 || Loss: 7.5423 || Conf Loss: 1.9511 || Regression Loss: 5.5913\n","Timer: 0.5371 sec.\n","tensor(5.3704, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2949 || Loss: 7.3627 || Conf Loss: 1.9924 || Regression Loss: 5.3704\n","Timer: 0.5774 sec.\n","tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2950 || Loss: 1.9769 || Conf Loss: 1.8655 || Regression Loss: 0.1114\n","Timer: 0.6106 sec.\n","tensor(3.4378, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2951 || Loss: 5.2397 || Conf Loss: 1.8018 || Regression Loss: 3.4378\n","Timer: 0.5859 sec.\n","tensor(3.8709, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2952 || Loss: 5.9522 || Conf Loss: 2.0814 || Regression Loss: 3.8709\n","Timer: 0.5799 sec.\n","tensor(2.0291, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2953 || Loss: 4.0718 || Conf Loss: 2.0427 || Regression Loss: 2.0291\n","Timer: 0.5755 sec.\n","tensor(2.0871, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2954 || Loss: 3.9273 || Conf Loss: 1.8402 || Regression Loss: 2.0871\n","Timer: 0.7234 sec.\n","tensor(2.6498, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2955 || Loss: 4.4538 || Conf Loss: 1.8040 || Regression Loss: 2.6498\n","Timer: 0.5547 sec.\n","tensor(5.9876, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2956 || Loss: 7.7472 || Conf Loss: 1.7596 || Regression Loss: 5.9876\n","Timer: 0.5489 sec.\n","tensor(0.4142, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2957 || Loss: 2.2484 || Conf Loss: 1.8342 || Regression Loss: 0.4142\n","Timer: 0.5635 sec.\n","tensor(0.1260, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2958 || Loss: 2.0991 || Conf Loss: 1.9731 || Regression Loss: 0.1260\n","Timer: 0.7358 sec.\n","tensor(0.0536, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2959 || Loss: 1.8753 || Conf Loss: 1.8217 || Regression Loss: 0.0536\n","Timer: 0.5209 sec.\n","tensor(5.0462, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2960 || Loss: 6.8437 || Conf Loss: 1.7975 || Regression Loss: 5.0462\n","Timer: 0.6857 sec.\n","tensor(4.9326, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2961 || Loss: 6.6291 || Conf Loss: 1.6965 || Regression Loss: 4.9326\n","Timer: 0.6043 sec.\n","tensor(0.2050, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2962 || Loss: 2.1035 || Conf Loss: 1.8984 || Regression Loss: 0.2050\n","Timer: 0.5894 sec.\n","tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2963 || Loss: 1.8898 || Conf Loss: 1.6880 || Regression Loss: 0.2018\n","Timer: 0.5589 sec.\n","tensor(3.0927, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2964 || Loss: 6.2350 || Conf Loss: 3.1424 || Regression Loss: 3.0927\n","Timer: 0.5733 sec.\n","tensor(0.9149, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2965 || Loss: 4.8036 || Conf Loss: 3.8887 || Regression Loss: 0.9149\n","Timer: 0.6276 sec.\n","tensor(4.0091, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2966 || Loss: 5.8528 || Conf Loss: 1.8437 || Regression Loss: 4.0091\n","Timer: 0.5517 sec.\n","tensor(5.9780, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2967 || Loss: 8.0928 || Conf Loss: 2.1148 || Regression Loss: 5.9780\n","Timer: 0.5868 sec.\n","tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2968 || Loss: 2.1007 || Conf Loss: 1.7944 || Regression Loss: 0.3063\n","Timer: 0.5793 sec.\n","tensor(5.8510, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2969 || Loss: 7.6276 || Conf Loss: 1.7766 || Regression Loss: 5.8510\n","Timer: 0.6100 sec.\n","tensor(2.3319, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2970 || Loss: 6.6840 || Conf Loss: 4.3521 || Regression Loss: 2.3319\n","Timer: 0.7162 sec.\n","tensor(5.3189, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2971 || Loss: 7.9073 || Conf Loss: 2.5884 || Regression Loss: 5.3189\n","Timer: 0.5362 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2972 || Loss: 1.1414 || Conf Loss: 1.1414 || Regression Loss: 0.0000\n","Timer: 0.5719 sec.\n","tensor(3.8055, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2973 || Loss: 5.7782 || Conf Loss: 1.9727 || Regression Loss: 3.8055\n","Timer: 0.5755 sec.\n","tensor(5.0613, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2974 || Loss: 6.8930 || Conf Loss: 1.8317 || Regression Loss: 5.0613\n","Timer: 0.5615 sec.\n","tensor(5.3995, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2975 || Loss: 7.3179 || Conf Loss: 1.9184 || Regression Loss: 5.3995\n","Timer: 0.6276 sec.\n","tensor(1.9416, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2976 || Loss: 3.7803 || Conf Loss: 1.8387 || Regression Loss: 1.9416\n","Timer: 0.6701 sec.\n","tensor(1.3081, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2977 || Loss: 5.1398 || Conf Loss: 3.8317 || Regression Loss: 1.3081\n","Timer: 0.5783 sec.\n","tensor(5.2986, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2978 || Loss: 7.0711 || Conf Loss: 1.7725 || Regression Loss: 5.2986\n","Timer: 0.6685 sec.\n","tensor(3.7892, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2979 || Loss: 5.5603 || Conf Loss: 1.7711 || Regression Loss: 3.7892\n","Timer: 0.5835 sec.\n","tensor(4.2546, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2980 || Loss: 6.4821 || Conf Loss: 2.2276 || Regression Loss: 4.2546\n","Timer: 0.6649 sec.\n","tensor(1.1088, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2981 || Loss: 4.2261 || Conf Loss: 3.1173 || Regression Loss: 1.1088\n","Timer: 0.6111 sec.\n","tensor(2.3456, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2982 || Loss: 5.9327 || Conf Loss: 3.5871 || Regression Loss: 2.3456\n","Timer: 0.5856 sec.\n","tensor(3.6498, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2983 || Loss: 5.5324 || Conf Loss: 1.8826 || Regression Loss: 3.6498\n","Timer: 0.6029 sec.\n","tensor(0.1311, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2984 || Loss: 2.3030 || Conf Loss: 2.1719 || Regression Loss: 0.1311\n","Timer: 0.6310 sec.\n","tensor(2.5046, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2985 || Loss: 4.4765 || Conf Loss: 1.9719 || Regression Loss: 2.5046\n","Timer: 0.5550 sec.\n","tensor(3.2497, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2986 || Loss: 5.0311 || Conf Loss: 1.7814 || Regression Loss: 3.2497\n","Timer: 0.5797 sec.\n","tensor(2.4491, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2987 || Loss: 4.7130 || Conf Loss: 2.2639 || Regression Loss: 2.4491\n","Timer: 0.5476 sec.\n","tensor(0.1650, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2988 || Loss: 1.9491 || Conf Loss: 1.7841 || Regression Loss: 0.1650\n","Timer: 0.5855 sec.\n","tensor(3.0608, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2989 || Loss: 4.9361 || Conf Loss: 1.8753 || Regression Loss: 3.0608\n","Timer: 0.5651 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2990 || Loss: 1.0880 || Conf Loss: 1.0880 || Regression Loss: 0.0000\n","Timer: 0.6006 sec.\n","tensor(9.8505, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2991 || Loss: 13.4795 || Conf Loss: 3.6290 || Regression Loss: 9.8505\n","Timer: 0.5829 sec.\n","tensor(2.4991, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2992 || Loss: 4.2290 || Conf Loss: 1.7299 || Regression Loss: 2.4991\n","Timer: 0.5792 sec.\n","tensor(3.5246, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2993 || Loss: 5.7163 || Conf Loss: 2.1917 || Regression Loss: 3.5246\n","Timer: 0.5710 sec.\n","tensor(3.3604, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2994 || Loss: 5.0678 || Conf Loss: 1.7074 || Regression Loss: 3.3604\n","Timer: 0.5813 sec.\n","tensor(2.5395, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2995 || Loss: 6.3159 || Conf Loss: 3.7764 || Regression Loss: 2.5395\n","Timer: 0.6101 sec.\n","tensor(1.6243, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2996 || Loss: 3.6589 || Conf Loss: 2.0347 || Regression Loss: 1.6243\n","Timer: 0.5483 sec.\n","tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2997 || Loss: 2.0306 || Conf Loss: 1.8244 || Regression Loss: 0.2062\n","Timer: 0.6885 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2998 || Loss: 1.0269 || Conf Loss: 1.0269 || Regression Loss: 0.0000\n","Timer: 0.6729 sec.\n","tensor(3.5788, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 2999 || Loss: 5.3904 || Conf Loss: 1.8116 || Regression Loss: 3.5788\n","Timer: 0.5606 sec.\n","tensor(0.2153, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3000 || Loss: 2.0096 || Conf Loss: 1.7943 || Regression Loss: 0.2153\n","Timer: 0.5421 sec.\n","tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3001 || Loss: 2.0335 || Conf Loss: 1.8015 || Regression Loss: 0.2320\n","Timer: 0.6214 sec.\n","tensor(2.6939, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3002 || Loss: 4.4009 || Conf Loss: 1.7070 || Regression Loss: 2.6939\n","Timer: 0.5479 sec.\n","tensor(5.3447, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3003 || Loss: 7.1003 || Conf Loss: 1.7557 || Regression Loss: 5.3447\n","Timer: 0.5776 sec.\n","tensor(5.6563, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3004 || Loss: 7.3265 || Conf Loss: 1.6702 || Regression Loss: 5.6563\n","Timer: 0.6377 sec.\n","tensor(3.7908, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3005 || Loss: 5.7701 || Conf Loss: 1.9793 || Regression Loss: 3.7908\n","Timer: 0.5479 sec.\n","tensor(0.1678, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3006 || Loss: 1.9161 || Conf Loss: 1.7483 || Regression Loss: 0.1678\n","Timer: 0.5585 sec.\n","tensor(4.3444, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3007 || Loss: 6.0462 || Conf Loss: 1.7018 || Regression Loss: 4.3444\n","Timer: 0.6066 sec.\n","tensor(1.1902, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3008 || Loss: 3.6289 || Conf Loss: 2.4387 || Regression Loss: 1.1902\n","Timer: 0.5831 sec.\n","tensor(0.7797, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3009 || Loss: 3.0123 || Conf Loss: 2.2325 || Regression Loss: 0.7797\n","Timer: 0.5997 sec.\n","tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3010 || Loss: 2.2887 || Conf Loss: 2.0590 || Regression Loss: 0.2297\n","Timer: 0.5600 sec.\n","tensor(2.1394, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3011 || Loss: 3.9584 || Conf Loss: 1.8190 || Regression Loss: 2.1394\n","Timer: 0.5631 sec.\n","tensor(2.7825, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3012 || Loss: 5.3604 || Conf Loss: 2.5778 || Regression Loss: 2.7825\n","Timer: 0.5531 sec.\n","tensor(3.8287, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3013 || Loss: 7.3408 || Conf Loss: 3.5121 || Regression Loss: 3.8287\n","Timer: 0.5867 sec.\n","tensor(1.1697, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3014 || Loss: 2.8614 || Conf Loss: 1.6917 || Regression Loss: 1.1697\n","Timer: 0.5518 sec.\n","tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3015 || Loss: 2.3423 || Conf Loss: 2.1979 || Regression Loss: 0.1444\n","Timer: 0.5746 sec.\n","tensor(3.0258, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3016 || Loss: 5.0204 || Conf Loss: 1.9946 || Regression Loss: 3.0258\n","Timer: 0.5497 sec.\n","tensor(1.7570, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3017 || Loss: 5.6101 || Conf Loss: 3.8531 || Regression Loss: 1.7570\n","Timer: 0.5668 sec.\n","tensor(1.4486, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3018 || Loss: 3.2750 || Conf Loss: 1.8263 || Regression Loss: 1.4486\n","Timer: 0.6307 sec.\n","tensor(1.3036, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3019 || Loss: 3.8726 || Conf Loss: 2.5690 || Regression Loss: 1.3036\n","Timer: 0.6486 sec.\n","tensor(1.3560, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3020 || Loss: 3.1535 || Conf Loss: 1.7974 || Regression Loss: 1.3560\n","Timer: 0.5805 sec.\n","tensor(3.3279, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3021 || Loss: 5.1191 || Conf Loss: 1.7912 || Regression Loss: 3.3279\n","Timer: 0.5561 sec.\n","tensor(3.1002, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3022 || Loss: 5.8894 || Conf Loss: 2.7892 || Regression Loss: 3.1002\n","Timer: 0.5586 sec.\n","tensor(1.9969, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3023 || Loss: 4.1663 || Conf Loss: 2.1694 || Regression Loss: 1.9969\n","Timer: 0.5613 sec.\n","tensor(1.8976, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3024 || Loss: 4.6402 || Conf Loss: 2.7426 || Regression Loss: 1.8976\n","Timer: 0.5214 sec.\n","tensor(2.1048, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3025 || Loss: 4.0646 || Conf Loss: 1.9598 || Regression Loss: 2.1048\n","Timer: 0.5505 sec.\n","tensor(4.0339, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3026 || Loss: 5.8592 || Conf Loss: 1.8253 || Regression Loss: 4.0339\n","Timer: 0.6460 sec.\n","tensor(1.4670, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3027 || Loss: 4.7585 || Conf Loss: 3.2915 || Regression Loss: 1.4670\n","Timer: 0.6065 sec.\n","tensor(5.0976, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3028 || Loss: 6.9777 || Conf Loss: 1.8801 || Regression Loss: 5.0976\n","Timer: 0.6401 sec.\n","tensor(3.8985, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3029 || Loss: 6.2818 || Conf Loss: 2.3833 || Regression Loss: 3.8985\n","Timer: 0.6034 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3030 || Loss: 0.9295 || Conf Loss: 0.9295 || Regression Loss: 0.0000\n","Timer: 0.6961 sec.\n","tensor(1.5088, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3031 || Loss: 3.7133 || Conf Loss: 2.2045 || Regression Loss: 1.5088\n","Timer: 0.5961 sec.\n","tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3032 || Loss: 2.2670 || Conf Loss: 2.0385 || Regression Loss: 0.2285\n","Timer: 0.6296 sec.\n","tensor(3.8976, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3033 || Loss: 5.6874 || Conf Loss: 1.7899 || Regression Loss: 3.8976\n","Timer: 0.5606 sec.\n","tensor(0.1572, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3034 || Loss: 2.0258 || Conf Loss: 1.8686 || Regression Loss: 0.1572\n","Timer: 0.5347 sec.\n","tensor(0.1455, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3035 || Loss: 1.9581 || Conf Loss: 1.8126 || Regression Loss: 0.1455\n","Timer: 0.7224 sec.\n","tensor(1.5733, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3036 || Loss: 3.4591 || Conf Loss: 1.8857 || Regression Loss: 1.5733\n","Timer: 0.6030 sec.\n","tensor(5.1316, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3037 || Loss: 6.8346 || Conf Loss: 1.7029 || Regression Loss: 5.1316\n","Timer: 0.6107 sec.\n","tensor(4.8401, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3038 || Loss: 6.6360 || Conf Loss: 1.7959 || Regression Loss: 4.8401\n","Timer: 0.6066 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3039 || Loss: 0.9604 || Conf Loss: 0.9604 || Regression Loss: 0.0000\n","Timer: 0.5542 sec.\n","tensor(3.0206, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3040 || Loss: 5.8327 || Conf Loss: 2.8121 || Regression Loss: 3.0206\n","Timer: 0.6113 sec.\n","tensor(0.5933, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3041 || Loss: 3.2616 || Conf Loss: 2.6683 || Regression Loss: 0.5933\n","Timer: 0.5811 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3042 || Loss: 0.9336 || Conf Loss: 0.9336 || Regression Loss: 0.0000\n","Timer: 0.6337 sec.\n","tensor(1.9854, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3043 || Loss: 3.7851 || Conf Loss: 1.7997 || Regression Loss: 1.9854\n","Timer: 0.5474 sec.\n","tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3044 || Loss: 2.1921 || Conf Loss: 1.9403 || Regression Loss: 0.2518\n","Timer: 0.5524 sec.\n","tensor(0.1198, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3045 || Loss: 2.0334 || Conf Loss: 1.9136 || Regression Loss: 0.1198\n","Timer: 0.5608 sec.\n","tensor(5.7277, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3046 || Loss: 11.4292 || Conf Loss: 5.7015 || Regression Loss: 5.7277\n","Timer: 0.5324 sec.\n","tensor(3.9639, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3047 || Loss: 7.2231 || Conf Loss: 3.2592 || Regression Loss: 3.9639\n","Timer: 0.5980 sec.\n","tensor(2.4020, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3048 || Loss: 4.4810 || Conf Loss: 2.0791 || Regression Loss: 2.4020\n","Timer: 0.5454 sec.\n","tensor(5.4840, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3049 || Loss: 7.3003 || Conf Loss: 1.8163 || Regression Loss: 5.4840\n","Timer: 0.5471 sec.\n","tensor(1.8752, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3050 || Loss: 3.7588 || Conf Loss: 1.8836 || Regression Loss: 1.8752\n","Timer: 0.5741 sec.\n","tensor(0.2814, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3051 || Loss: 3.2613 || Conf Loss: 2.9799 || Regression Loss: 0.2814\n","Timer: 0.5602 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3052 || Loss: 1.0456 || Conf Loss: 1.0456 || Regression Loss: 0.0000\n","Timer: 0.5644 sec.\n","tensor(5.4396, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3053 || Loss: 7.4242 || Conf Loss: 1.9846 || Regression Loss: 5.4396\n","Timer: 0.5795 sec.\n","tensor(1.1747, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3054 || Loss: 3.3633 || Conf Loss: 2.1886 || Regression Loss: 1.1747\n","Timer: 0.7105 sec.\n","tensor(2.5798, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3055 || Loss: 4.6657 || Conf Loss: 2.0859 || Regression Loss: 2.5798\n","Timer: 0.5807 sec.\n","tensor(2.4161, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3056 || Loss: 4.3087 || Conf Loss: 1.8926 || Regression Loss: 2.4161\n","Timer: 0.5639 sec.\n","tensor(2.2698, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3057 || Loss: 6.0617 || Conf Loss: 3.7919 || Regression Loss: 2.2698\n","Timer: 0.5622 sec.\n","tensor(2.1258, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3058 || Loss: 5.6596 || Conf Loss: 3.5338 || Regression Loss: 2.1258\n","Timer: 0.5816 sec.\n","tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3059 || Loss: 1.8850 || Conf Loss: 1.7862 || Regression Loss: 0.0988\n","Timer: 0.5534 sec.\n","tensor(1.4660, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3060 || Loss: 4.8153 || Conf Loss: 3.3493 || Regression Loss: 1.4660\n","Timer: 0.6782 sec.\n","tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3061 || Loss: 1.8852 || Conf Loss: 1.8122 || Regression Loss: 0.0729\n","Timer: 0.6729 sec.\n","tensor(5.6548, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3062 || Loss: 7.4705 || Conf Loss: 1.8157 || Regression Loss: 5.6548\n","Timer: 0.5797 sec.\n","tensor(5.1683, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3063 || Loss: 6.9982 || Conf Loss: 1.8299 || Regression Loss: 5.1683\n","Timer: 0.6301 sec.\n","tensor(2.0222, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3064 || Loss: 5.8303 || Conf Loss: 3.8081 || Regression Loss: 2.0222\n","Timer: 0.5412 sec.\n","tensor(4.4673, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3065 || Loss: 6.3286 || Conf Loss: 1.8612 || Regression Loss: 4.4673\n","Timer: 0.6191 sec.\n","tensor(2.1921, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3066 || Loss: 4.9496 || Conf Loss: 2.7576 || Regression Loss: 2.1921\n","Timer: 0.6232 sec.\n","tensor(0.2158, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3067 || Loss: 2.2119 || Conf Loss: 1.9961 || Regression Loss: 0.2158\n","Timer: 0.6896 sec.\n","tensor(5.7529, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3068 || Loss: 7.4449 || Conf Loss: 1.6920 || Regression Loss: 5.7529\n","Timer: 0.5373 sec.\n","tensor(5.3305, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3069 || Loss: 7.2054 || Conf Loss: 1.8749 || Regression Loss: 5.3305\n","Timer: 0.5850 sec.\n","tensor(4.6212, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3070 || Loss: 6.8486 || Conf Loss: 2.2275 || Regression Loss: 4.6212\n","Timer: 0.7115 sec.\n","tensor(2.7193, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3071 || Loss: 4.7054 || Conf Loss: 1.9861 || Regression Loss: 2.7193\n","Timer: 0.5396 sec.\n","tensor(4.9727, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3072 || Loss: 7.0002 || Conf Loss: 2.0275 || Regression Loss: 4.9727\n","Timer: 0.5273 sec.\n","tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3073 || Loss: 1.9876 || Conf Loss: 1.8406 || Regression Loss: 0.1470\n","Timer: 0.5591 sec.\n","tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3074 || Loss: 2.0176 || Conf Loss: 1.8702 || Regression Loss: 0.1474\n","Timer: 0.6368 sec.\n","tensor(5.0861, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3075 || Loss: 6.9301 || Conf Loss: 1.8440 || Regression Loss: 5.0861\n","Timer: 0.5855 sec.\n","tensor(3.5750, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3076 || Loss: 5.3680 || Conf Loss: 1.7930 || Regression Loss: 3.5750\n","Timer: 0.5582 sec.\n","tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3077 || Loss: 2.0189 || Conf Loss: 1.8875 || Regression Loss: 0.1314\n","Timer: 0.5762 sec.\n","tensor(5.4401, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3078 || Loss: 7.2166 || Conf Loss: 1.7764 || Regression Loss: 5.4401\n","Timer: 0.7404 sec.\n","tensor(2.5298, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3079 || Loss: 4.4139 || Conf Loss: 1.8841 || Regression Loss: 2.5298\n","Timer: 0.5809 sec.\n","tensor(5.4581, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3080 || Loss: 7.2381 || Conf Loss: 1.7800 || Regression Loss: 5.4581\n","Timer: 0.5652 sec.\n","tensor(2.3158, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3081 || Loss: 4.4959 || Conf Loss: 2.1801 || Regression Loss: 2.3158\n","Timer: 0.5614 sec.\n","tensor(5.3600, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3082 || Loss: 7.1267 || Conf Loss: 1.7666 || Regression Loss: 5.3600\n","Timer: 0.5807 sec.\n","tensor(6.6483, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3083 || Loss: 9.5167 || Conf Loss: 2.8683 || Regression Loss: 6.6483\n","Timer: 0.6279 sec.\n","tensor(3.7994, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3084 || Loss: 5.6153 || Conf Loss: 1.8159 || Regression Loss: 3.7994\n","Timer: 0.6343 sec.\n","tensor(3.4637, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3085 || Loss: 5.2271 || Conf Loss: 1.7634 || Regression Loss: 3.4637\n","Timer: 0.6011 sec.\n","tensor(0.5285, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3086 || Loss: 3.4416 || Conf Loss: 2.9132 || Regression Loss: 0.5285\n","Timer: 0.5510 sec.\n","tensor(0.1530, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3087 || Loss: 2.1771 || Conf Loss: 2.0241 || Regression Loss: 0.1530\n","Timer: 0.5786 sec.\n","tensor(3.7184, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3088 || Loss: 5.5736 || Conf Loss: 1.8553 || Regression Loss: 3.7184\n","Timer: 0.6661 sec.\n","tensor(5.2594, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3089 || Loss: 7.1951 || Conf Loss: 1.9357 || Regression Loss: 5.2594\n","Timer: 0.5781 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3090 || Loss: 1.1879 || Conf Loss: 1.1879 || Regression Loss: 0.0000\n","Timer: 0.5491 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3091 || Loss: 0.8935 || Conf Loss: 0.8935 || Regression Loss: 0.0000\n","Timer: 0.5461 sec.\n","tensor(4.7630, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3092 || Loss: 6.5269 || Conf Loss: 1.7639 || Regression Loss: 4.7630\n","Timer: 0.5517 sec.\n","tensor(6.1448, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3093 || Loss: 7.8631 || Conf Loss: 1.7183 || Regression Loss: 6.1448\n","Timer: 0.5575 sec.\n","tensor(1.0170, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3094 || Loss: 3.4991 || Conf Loss: 2.4822 || Regression Loss: 1.0170\n","Timer: 0.5662 sec.\n","tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3095 || Loss: 2.2170 || Conf Loss: 2.1129 || Regression Loss: 0.1041\n","Timer: 0.6195 sec.\n","tensor(5.7335, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3096 || Loss: 7.6657 || Conf Loss: 1.9322 || Regression Loss: 5.7335\n","Timer: 0.6836 sec.\n","tensor(5.4134, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3097 || Loss: 7.1737 || Conf Loss: 1.7603 || Regression Loss: 5.4134\n","Timer: 0.5504 sec.\n","tensor(1.7743, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3098 || Loss: 4.7095 || Conf Loss: 2.9352 || Regression Loss: 1.7743\n","Timer: 0.5575 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3099 || Loss: 0.9133 || Conf Loss: 0.9133 || Regression Loss: 0.0000\n","Timer: 0.6401 sec.\n","tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3100 || Loss: 1.7203 || Conf Loss: 1.6624 || Regression Loss: 0.0579\n","Timer: 0.5327 sec.\n","tensor(3.3824, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3101 || Loss: 5.1751 || Conf Loss: 1.7928 || Regression Loss: 3.3824\n","Timer: 0.5966 sec.\n","tensor(5.6317, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3102 || Loss: 7.3431 || Conf Loss: 1.7114 || Regression Loss: 5.6317\n","Timer: 0.6017 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3103 || Loss: 1.0468 || Conf Loss: 1.0468 || Regression Loss: 0.0000\n","Timer: 0.5491 sec.\n","tensor(2.2654, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3104 || Loss: 5.4194 || Conf Loss: 3.1540 || Regression Loss: 2.2654\n","Timer: 0.6433 sec.\n","tensor(1.2302, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3105 || Loss: 4.9439 || Conf Loss: 3.7137 || Regression Loss: 1.2302\n","Timer: 0.5686 sec.\n","tensor(2.4472, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3106 || Loss: 4.8396 || Conf Loss: 2.3923 || Regression Loss: 2.4472\n","Timer: 0.5456 sec.\n","tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3107 || Loss: 1.8626 || Conf Loss: 1.7755 || Regression Loss: 0.0871\n","Timer: 0.5672 sec.\n","tensor(1.8614, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3108 || Loss: 3.7778 || Conf Loss: 1.9165 || Regression Loss: 1.8614\n","Timer: 0.5719 sec.\n","tensor(5.4573, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3109 || Loss: 7.1478 || Conf Loss: 1.6905 || Regression Loss: 5.4573\n","Timer: 0.5561 sec.\n","tensor(0.3683, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3110 || Loss: 2.1599 || Conf Loss: 1.7916 || Regression Loss: 0.3683\n","Timer: 0.6272 sec.\n","tensor(0.0924, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3111 || Loss: 1.8303 || Conf Loss: 1.7379 || Regression Loss: 0.0924\n","Timer: 0.5584 sec.\n","tensor(5.6756, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3112 || Loss: 7.4702 || Conf Loss: 1.7946 || Regression Loss: 5.6756\n","Timer: 0.6887 sec.\n","tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3113 || Loss: 1.8081 || Conf Loss: 1.7648 || Regression Loss: 0.0433\n","Timer: 0.5982 sec.\n","tensor(2.6438, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3114 || Loss: 4.8641 || Conf Loss: 2.2203 || Regression Loss: 2.6438\n","Timer: 0.6509 sec.\n","tensor(1.6086, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3115 || Loss: 5.2407 || Conf Loss: 3.6321 || Regression Loss: 1.6086\n","Timer: 0.5808 sec.\n","tensor(1.3823, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3116 || Loss: 3.8080 || Conf Loss: 2.4257 || Regression Loss: 1.3823\n","Timer: 0.5622 sec.\n","tensor(0.0757, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3117 || Loss: 1.8419 || Conf Loss: 1.7662 || Regression Loss: 0.0757\n","Timer: 0.5335 sec.\n","tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3118 || Loss: 1.8708 || Conf Loss: 1.7885 || Regression Loss: 0.0823\n","Timer: 0.5574 sec.\n","tensor(1.7818, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3119 || Loss: 3.7095 || Conf Loss: 1.9277 || Regression Loss: 1.7818\n","Timer: 0.5763 sec.\n","tensor(0.8128, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3120 || Loss: 4.1114 || Conf Loss: 3.2986 || Regression Loss: 0.8128\n","Timer: 0.5544 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3121 || Loss: 1.2945 || Conf Loss: 1.2945 || Regression Loss: 0.0000\n","Timer: 0.6669 sec.\n","tensor(3.8399, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3122 || Loss: 5.5995 || Conf Loss: 1.7596 || Regression Loss: 3.8399\n","Timer: 0.5394 sec.\n","tensor(0.1760, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3123 || Loss: 1.9542 || Conf Loss: 1.7782 || Regression Loss: 0.1760\n","Timer: 0.5598 sec.\n","tensor(0.2126, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3124 || Loss: 2.4542 || Conf Loss: 2.2416 || Regression Loss: 0.2126\n","Timer: 0.5660 sec.\n","tensor(2.1774, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3125 || Loss: 4.4350 || Conf Loss: 2.2577 || Regression Loss: 2.1774\n","Timer: 0.5224 sec.\n","tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3126 || Loss: 1.9276 || Conf Loss: 1.7544 || Regression Loss: 0.1732\n","Timer: 0.6899 sec.\n","tensor(3.1221, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3127 || Loss: 4.8342 || Conf Loss: 1.7121 || Regression Loss: 3.1221\n","Timer: 0.5519 sec.\n","tensor(2.4027, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3128 || Loss: 5.6525 || Conf Loss: 3.2498 || Regression Loss: 2.4027\n","Timer: 0.6396 sec.\n","tensor(1.6151, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3129 || Loss: 4.6193 || Conf Loss: 3.0042 || Regression Loss: 1.6151\n","Timer: 0.5629 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3130 || Loss: 1.2545 || Conf Loss: 1.2545 || Regression Loss: 0.0000\n","Timer: 0.6975 sec.\n","tensor(4.4624, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3131 || Loss: 6.7781 || Conf Loss: 2.3157 || Regression Loss: 4.4624\n","Timer: 0.6488 sec.\n","tensor(4.4775, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3132 || Loss: 6.5510 || Conf Loss: 2.0735 || Regression Loss: 4.4775\n","Timer: 0.6002 sec.\n","tensor(1.6169, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3133 || Loss: 3.5083 || Conf Loss: 1.8914 || Regression Loss: 1.6169\n","Timer: 0.5477 sec.\n","tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3134 || Loss: 2.0340 || Conf Loss: 1.7762 || Regression Loss: 0.2578\n","Timer: 0.5524 sec.\n","tensor(0.3440, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3135 || Loss: 2.2342 || Conf Loss: 1.8902 || Regression Loss: 0.3440\n","Timer: 0.6281 sec.\n","tensor(5.1536, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3136 || Loss: 7.0893 || Conf Loss: 1.9356 || Regression Loss: 5.1536\n","Timer: 0.5617 sec.\n","tensor(2.5752, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3137 || Loss: 4.3945 || Conf Loss: 1.8193 || Regression Loss: 2.5752\n","Timer: 0.6340 sec.\n","tensor(4.0675, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3138 || Loss: 6.1881 || Conf Loss: 2.1205 || Regression Loss: 4.0675\n","Timer: 0.6383 sec.\n","tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3139 || Loss: 1.8142 || Conf Loss: 1.7554 || Regression Loss: 0.0588\n","Timer: 0.5925 sec.\n","tensor(5.2887, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3140 || Loss: 8.3597 || Conf Loss: 3.0711 || Regression Loss: 5.2887\n","Timer: 0.5600 sec.\n","tensor(3.3805, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3141 || Loss: 5.9944 || Conf Loss: 2.6139 || Regression Loss: 3.3805\n","Timer: 0.5749 sec.\n","tensor(0.0486, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3142 || Loss: 1.7435 || Conf Loss: 1.6950 || Regression Loss: 0.0486\n","Timer: 0.5537 sec.\n","tensor(5.1438, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3143 || Loss: 7.0463 || Conf Loss: 1.9025 || Regression Loss: 5.1438\n","Timer: 0.5839 sec.\n","tensor(1.6439, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3144 || Loss: 3.3761 || Conf Loss: 1.7322 || Regression Loss: 1.6439\n","Timer: 0.5880 sec.\n","tensor(1.5432, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3145 || Loss: 3.3766 || Conf Loss: 1.8334 || Regression Loss: 1.5432\n","Timer: 0.5624 sec.\n","tensor(4.9284, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3146 || Loss: 6.6982 || Conf Loss: 1.7698 || Regression Loss: 4.9284\n","Timer: 0.5438 sec.\n","tensor(4.2155, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3147 || Loss: 7.7427 || Conf Loss: 3.5272 || Regression Loss: 4.2155\n","Timer: 0.5659 sec.\n","tensor(5.5829, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3148 || Loss: 7.4561 || Conf Loss: 1.8732 || Regression Loss: 5.5829\n","Timer: 0.5522 sec.\n","tensor(4.7053, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3149 || Loss: 6.4340 || Conf Loss: 1.7287 || Regression Loss: 4.7053\n","Timer: 0.5629 sec.\n","tensor(3.4501, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3150 || Loss: 5.1985 || Conf Loss: 1.7484 || Regression Loss: 3.4501\n","Timer: 0.6300 sec.\n","tensor(4.5459, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3151 || Loss: 10.4401 || Conf Loss: 5.8943 || Regression Loss: 4.5459\n","Timer: 0.5784 sec.\n","tensor(5.4947, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3152 || Loss: 7.7753 || Conf Loss: 2.2806 || Regression Loss: 5.4947\n","Timer: 0.5740 sec.\n","tensor(4.9231, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3153 || Loss: 6.9253 || Conf Loss: 2.0022 || Regression Loss: 4.9231\n","Timer: 0.5861 sec.\n","tensor(5.6205, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3154 || Loss: 7.3815 || Conf Loss: 1.7610 || Regression Loss: 5.6205\n","Timer: 0.5663 sec.\n","tensor(3.0563, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3155 || Loss: 5.0051 || Conf Loss: 1.9488 || Regression Loss: 3.0563\n","Timer: 0.5688 sec.\n","tensor(5.4773, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3156 || Loss: 7.3120 || Conf Loss: 1.8347 || Regression Loss: 5.4773\n","Timer: 0.5945 sec.\n","tensor(4.4186, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3157 || Loss: 6.3993 || Conf Loss: 1.9807 || Regression Loss: 4.4186\n","Timer: 0.5558 sec.\n","tensor(4.4073, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3158 || Loss: 6.2535 || Conf Loss: 1.8463 || Regression Loss: 4.4073\n","Timer: 0.5881 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3159 || Loss: 0.9437 || Conf Loss: 0.9437 || Regression Loss: 0.0000\n","Timer: 0.6146 sec.\n","tensor(2.4776, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3160 || Loss: 4.2192 || Conf Loss: 1.7415 || Regression Loss: 2.4776\n","Timer: 0.7097 sec.\n","tensor(1.7049, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3161 || Loss: 3.4727 || Conf Loss: 1.7679 || Regression Loss: 1.7049\n","Timer: 0.6450 sec.\n","tensor(2.8620, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3162 || Loss: 5.5635 || Conf Loss: 2.7015 || Regression Loss: 2.8620\n","Timer: 0.5830 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3163 || Loss: 1.1341 || Conf Loss: 1.1341 || Regression Loss: 0.0000\n","Timer: 0.5362 sec.\n","tensor(2.7782, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3164 || Loss: 5.9940 || Conf Loss: 3.2158 || Regression Loss: 2.7782\n","Timer: 0.6376 sec.\n","tensor(0.1414, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3165 || Loss: 2.0001 || Conf Loss: 1.8587 || Regression Loss: 0.1414\n","Timer: 0.6681 sec.\n","tensor(2.4987, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3166 || Loss: 5.4940 || Conf Loss: 2.9953 || Regression Loss: 2.4987\n","Timer: 0.5547 sec.\n","tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3167 || Loss: 1.8762 || Conf Loss: 1.7506 || Regression Loss: 0.1257\n","Timer: 0.7029 sec.\n","tensor(1.8625, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3168 || Loss: 3.5824 || Conf Loss: 1.7199 || Regression Loss: 1.8625\n","Timer: 0.5503 sec.\n","tensor(4.0194, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3169 || Loss: 5.7618 || Conf Loss: 1.7424 || Regression Loss: 4.0194\n","Timer: 0.5585 sec.\n","tensor(3.7541, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3170 || Loss: 6.8350 || Conf Loss: 3.0809 || Regression Loss: 3.7541\n","Timer: 0.5579 sec.\n","tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3171 || Loss: 2.4107 || Conf Loss: 2.1756 || Regression Loss: 0.2351\n","Timer: 0.6090 sec.\n","tensor(2.8888, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3172 || Loss: 5.6014 || Conf Loss: 2.7126 || Regression Loss: 2.8888\n","Timer: 0.5480 sec.\n","tensor(1.1029, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3173 || Loss: 3.4828 || Conf Loss: 2.3798 || Regression Loss: 1.1029\n","Timer: 0.5776 sec.\n","tensor(1.4008, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3174 || Loss: 3.7822 || Conf Loss: 2.3814 || Regression Loss: 1.4008\n","Timer: 0.5862 sec.\n","tensor(1.7675, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3175 || Loss: 5.1558 || Conf Loss: 3.3883 || Regression Loss: 1.7675\n","Timer: 0.5763 sec.\n","tensor(3.0839, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3176 || Loss: 6.0416 || Conf Loss: 2.9577 || Regression Loss: 3.0839\n","Timer: 0.5468 sec.\n","tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3177 || Loss: 2.1848 || Conf Loss: 2.0622 || Regression Loss: 0.1225\n","Timer: 0.7075 sec.\n","tensor(2.9703, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3178 || Loss: 4.7660 || Conf Loss: 1.7958 || Regression Loss: 2.9703\n","Timer: 0.7319 sec.\n","tensor(3.9147, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3179 || Loss: 5.9169 || Conf Loss: 2.0021 || Regression Loss: 3.9147\n","Timer: 0.6228 sec.\n","tensor(5.3003, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3180 || Loss: 7.0518 || Conf Loss: 1.7515 || Regression Loss: 5.3003\n","Timer: 0.5768 sec.\n","tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3181 || Loss: 1.9426 || Conf Loss: 1.7762 || Regression Loss: 0.1663\n","Timer: 0.6746 sec.\n","tensor(3.9667, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3182 || Loss: 6.4499 || Conf Loss: 2.4832 || Regression Loss: 3.9667\n","Timer: 0.5611 sec.\n","tensor(2.3099, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3183 || Loss: 4.1840 || Conf Loss: 1.8741 || Regression Loss: 2.3099\n","Timer: 0.5616 sec.\n","tensor(2.2442, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3184 || Loss: 5.5557 || Conf Loss: 3.3115 || Regression Loss: 2.2442\n","Timer: 0.6674 sec.\n","tensor(2.1423, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3185 || Loss: 3.9365 || Conf Loss: 1.7942 || Regression Loss: 2.1423\n","Timer: 0.6103 sec.\n","tensor(5.9429, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3186 || Loss: 8.2888 || Conf Loss: 2.3459 || Regression Loss: 5.9429\n","Timer: 0.5380 sec.\n","tensor(3.0546, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3187 || Loss: 5.3246 || Conf Loss: 2.2700 || Regression Loss: 3.0546\n","Timer: 0.5967 sec.\n","tensor(4.9366, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3188 || Loss: 6.7600 || Conf Loss: 1.8234 || Regression Loss: 4.9366\n","Timer: 0.5914 sec.\n","tensor(0.1095, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3189 || Loss: 1.9315 || Conf Loss: 1.8220 || Regression Loss: 0.1095\n","Timer: 0.5909 sec.\n","tensor(5.5557, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3190 || Loss: 7.3428 || Conf Loss: 1.7871 || Regression Loss: 5.5557\n","Timer: 0.6510 sec.\n","tensor(0.4046, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3191 || Loss: 2.5616 || Conf Loss: 2.1570 || Regression Loss: 0.4046\n","Timer: 0.5791 sec.\n","tensor(0.7902, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3192 || Loss: 3.5369 || Conf Loss: 2.7467 || Regression Loss: 0.7902\n","Timer: 0.5410 sec.\n","tensor(2.3652, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3193 || Loss: 4.2031 || Conf Loss: 1.8379 || Regression Loss: 2.3652\n","Timer: 0.6166 sec.\n","tensor(0.1381, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3194 || Loss: 1.9477 || Conf Loss: 1.8096 || Regression Loss: 0.1381\n","Timer: 0.6609 sec.\n","tensor(4.8949, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3195 || Loss: 6.8345 || Conf Loss: 1.9396 || Regression Loss: 4.8949\n","Timer: 0.5587 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3196 || Loss: 0.9962 || Conf Loss: 0.9962 || Regression Loss: 0.0000\n","Timer: 0.6309 sec.\n","tensor(5.1993, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3197 || Loss: 6.9351 || Conf Loss: 1.7358 || Regression Loss: 5.1993\n","Timer: 0.5589 sec.\n","tensor(5.1108, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3198 || Loss: 6.8412 || Conf Loss: 1.7304 || Regression Loss: 5.1108\n","Timer: 0.5676 sec.\n","tensor(5.8215, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3199 || Loss: 7.5078 || Conf Loss: 1.6863 || Regression Loss: 5.8215\n","Timer: 0.5461 sec.\n","tensor(5.2595, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3200 || Loss: 7.0124 || Conf Loss: 1.7528 || Regression Loss: 5.2595\n","Timer: 0.6191 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3201 || Loss: 0.9058 || Conf Loss: 0.9058 || Regression Loss: 0.0000\n","Timer: 0.5752 sec.\n","tensor(3.6032, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3202 || Loss: 6.0267 || Conf Loss: 2.4235 || Regression Loss: 3.6032\n","Timer: 0.5475 sec.\n","tensor(5.1149, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3203 || Loss: 6.7846 || Conf Loss: 1.6697 || Regression Loss: 5.1149\n","Timer: 0.5923 sec.\n","tensor(0.0827, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3204 || Loss: 1.8750 || Conf Loss: 1.7923 || Regression Loss: 0.0827\n","Timer: 0.6854 sec.\n","tensor(3.7612, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3205 || Loss: 5.4717 || Conf Loss: 1.7105 || Regression Loss: 3.7612\n","Timer: 0.5964 sec.\n","tensor(5.1938, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3206 || Loss: 7.7763 || Conf Loss: 2.5826 || Regression Loss: 5.1938\n","Timer: 0.5683 sec.\n","tensor(1.5034, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3207 || Loss: 3.3826 || Conf Loss: 1.8792 || Regression Loss: 1.5034\n","Timer: 0.6091 sec.\n","tensor(0.0818, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3208 || Loss: 1.8500 || Conf Loss: 1.7682 || Regression Loss: 0.0818\n","Timer: 0.6870 sec.\n","tensor(2.7495, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3209 || Loss: 7.0281 || Conf Loss: 4.2786 || Regression Loss: 2.7495\n","Timer: 0.5596 sec.\n","tensor(1.5611, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3210 || Loss: 5.1065 || Conf Loss: 3.5453 || Regression Loss: 1.5611\n","Timer: 0.5902 sec.\n","tensor(5.2961, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3211 || Loss: 7.1361 || Conf Loss: 1.8399 || Regression Loss: 5.2961\n","Timer: 0.6043 sec.\n","tensor(0.0794, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3212 || Loss: 1.8441 || Conf Loss: 1.7647 || Regression Loss: 0.0794\n","Timer: 0.6493 sec.\n","tensor(4.1857, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3213 || Loss: 6.1547 || Conf Loss: 1.9691 || Regression Loss: 4.1857\n","Timer: 0.6071 sec.\n","tensor(2.8258, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3214 || Loss: 4.5711 || Conf Loss: 1.7453 || Regression Loss: 2.8258\n","Timer: 0.5845 sec.\n","tensor(0.7583, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3215 || Loss: 8.3860 || Conf Loss: 7.6277 || Regression Loss: 0.7583\n","Timer: 0.5681 sec.\n","tensor(3.4436, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3216 || Loss: 5.7211 || Conf Loss: 2.2775 || Regression Loss: 3.4436\n","Timer: 0.5787 sec.\n","tensor(2.7088, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3217 || Loss: 5.0153 || Conf Loss: 2.3065 || Regression Loss: 2.7088\n","Timer: 0.5715 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3218 || Loss: 0.9229 || Conf Loss: 0.9229 || Regression Loss: 0.0000\n","Timer: 0.5202 sec.\n","tensor(3.4541, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3219 || Loss: 5.5266 || Conf Loss: 2.0725 || Regression Loss: 3.4541\n","Timer: 0.5539 sec.\n","tensor(2.0400, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3220 || Loss: 4.0019 || Conf Loss: 1.9619 || Regression Loss: 2.0400\n","Timer: 0.6483 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3221 || Loss: 1.0864 || Conf Loss: 1.0864 || Regression Loss: 0.0000\n","Timer: 0.5988 sec.\n","tensor(2.1057, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3222 || Loss: 6.2757 || Conf Loss: 4.1700 || Regression Loss: 2.1057\n","Timer: 0.6194 sec.\n","tensor(2.7501, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3223 || Loss: 6.2155 || Conf Loss: 3.4654 || Regression Loss: 2.7501\n","Timer: 0.5570 sec.\n","tensor(0.1886, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3224 || Loss: 2.3202 || Conf Loss: 2.1316 || Regression Loss: 0.1886\n","Timer: 0.6464 sec.\n","tensor(5.0876, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3225 || Loss: 7.3437 || Conf Loss: 2.2561 || Regression Loss: 5.0876\n","Timer: 0.6683 sec.\n","tensor(3.2822, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3226 || Loss: 5.1569 || Conf Loss: 1.8747 || Regression Loss: 3.2822\n","Timer: 0.5871 sec.\n","tensor(0.1221, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3227 || Loss: 2.0752 || Conf Loss: 1.9531 || Regression Loss: 0.1221\n","Timer: 0.5700 sec.\n","tensor(6.2640, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3228 || Loss: 10.3056 || Conf Loss: 4.0416 || Regression Loss: 6.2640\n","Timer: 0.5930 sec.\n","tensor(5.0344, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3229 || Loss: 6.8789 || Conf Loss: 1.8445 || Regression Loss: 5.0344\n","Timer: 0.5446 sec.\n","tensor(3.1816, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3230 || Loss: 5.4854 || Conf Loss: 2.3038 || Regression Loss: 3.1816\n","Timer: 0.5894 sec.\n","tensor(1.5352, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3231 || Loss: 5.1404 || Conf Loss: 3.6052 || Regression Loss: 1.5352\n","Timer: 0.5607 sec.\n","tensor(3.9710, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3232 || Loss: 5.7923 || Conf Loss: 1.8212 || Regression Loss: 3.9710\n","Timer: 0.5556 sec.\n","tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3233 || Loss: 2.1741 || Conf Loss: 1.9562 || Regression Loss: 0.2180\n","Timer: 0.5332 sec.\n","tensor(6.3676, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3234 || Loss: 8.2087 || Conf Loss: 1.8411 || Regression Loss: 6.3676\n","Timer: 0.6887 sec.\n","tensor(0.1875, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3235 || Loss: 1.9812 || Conf Loss: 1.7937 || Regression Loss: 0.1875\n","Timer: 0.6019 sec.\n","tensor(1.7796, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3236 || Loss: 5.0118 || Conf Loss: 3.2321 || Regression Loss: 1.7796\n","Timer: 0.5910 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3237 || Loss: 1.0406 || Conf Loss: 1.0406 || Regression Loss: 0.0000\n","Timer: 0.5857 sec.\n","tensor(0.1473, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3238 || Loss: 1.9403 || Conf Loss: 1.7930 || Regression Loss: 0.1473\n","Timer: 0.6008 sec.\n","tensor(1.9818, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3239 || Loss: 3.9845 || Conf Loss: 2.0026 || Regression Loss: 1.9818\n","Timer: 0.6556 sec.\n","tensor(0.4597, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3240 || Loss: 2.2550 || Conf Loss: 1.7952 || Regression Loss: 0.4597\n","Timer: 0.6371 sec.\n","tensor(5.0755, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3241 || Loss: 6.8569 || Conf Loss: 1.7814 || Regression Loss: 5.0755\n","Timer: 0.5794 sec.\n","tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3242 || Loss: 1.9094 || Conf Loss: 1.7507 || Regression Loss: 0.1587\n","Timer: 0.6196 sec.\n","tensor(4.9455, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3243 || Loss: 6.6640 || Conf Loss: 1.7184 || Regression Loss: 4.9455\n","Timer: 0.5697 sec.\n","tensor(1.8126, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3244 || Loss: 3.5774 || Conf Loss: 1.7648 || Regression Loss: 1.8126\n","Timer: 0.6935 sec.\n","tensor(5.4624, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3245 || Loss: 7.2413 || Conf Loss: 1.7789 || Regression Loss: 5.4624\n","Timer: 0.5842 sec.\n","tensor(4.5490, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3246 || Loss: 6.2502 || Conf Loss: 1.7013 || Regression Loss: 4.5490\n","Timer: 0.5781 sec.\n","tensor(2.0340, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3247 || Loss: 5.5532 || Conf Loss: 3.5192 || Regression Loss: 2.0340\n","Timer: 0.5695 sec.\n","tensor(5.4256, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3248 || Loss: 7.2001 || Conf Loss: 1.7745 || Regression Loss: 5.4256\n","Timer: 0.6478 sec.\n","tensor(1.5816, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3249 || Loss: 3.4327 || Conf Loss: 1.8511 || Regression Loss: 1.5816\n","Timer: 0.5527 sec.\n","tensor(0.4679, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3250 || Loss: 2.3509 || Conf Loss: 1.8830 || Regression Loss: 0.4679\n","Timer: 0.6292 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3251 || Loss: 1.3376 || Conf Loss: 1.3376 || Regression Loss: 0.0000\n","Timer: 0.5684 sec.\n","tensor(5.5514, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3252 || Loss: 8.0289 || Conf Loss: 2.4775 || Regression Loss: 5.5514\n","Timer: 0.5810 sec.\n","tensor(3.5560, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3253 || Loss: 5.5992 || Conf Loss: 2.0432 || Regression Loss: 3.5560\n","Timer: 0.5737 sec.\n","tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3254 || Loss: 2.0884 || Conf Loss: 1.8667 || Regression Loss: 0.2217\n","Timer: 0.5533 sec.\n","tensor(2.3291, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3255 || Loss: 4.3842 || Conf Loss: 2.0551 || Regression Loss: 2.3291\n","Timer: 0.6078 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3256 || Loss: 1.1249 || Conf Loss: 1.1249 || Regression Loss: 0.0000\n","Timer: 0.5799 sec.\n","tensor(2.3656, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3257 || Loss: 4.1322 || Conf Loss: 1.7666 || Regression Loss: 2.3656\n","Timer: 0.5896 sec.\n","tensor(3.2148, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3258 || Loss: 4.9132 || Conf Loss: 1.6984 || Regression Loss: 3.2148\n","Timer: 0.6415 sec.\n","tensor(5.2879, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3259 || Loss: 7.4515 || Conf Loss: 2.1636 || Regression Loss: 5.2879\n","Timer: 0.5743 sec.\n","tensor(4.9659, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3260 || Loss: 6.7927 || Conf Loss: 1.8268 || Regression Loss: 4.9659\n","Timer: 0.7461 sec.\n","tensor(3.9641, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3261 || Loss: 6.0349 || Conf Loss: 2.0708 || Regression Loss: 3.9641\n","Timer: 0.6876 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3262 || Loss: 0.9068 || Conf Loss: 0.9068 || Regression Loss: 0.0000\n","Timer: 0.5644 sec.\n","tensor(3.3300, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3263 || Loss: 5.1331 || Conf Loss: 1.8030 || Regression Loss: 3.3300\n","Timer: 0.5753 sec.\n","tensor(4.6152, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3264 || Loss: 6.9299 || Conf Loss: 2.3147 || Regression Loss: 4.6152\n","Timer: 0.6716 sec.\n","tensor(10.3409, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3265 || Loss: 15.2882 || Conf Loss: 4.9473 || Regression Loss: 10.3409\n","Timer: 0.5665 sec.\n","tensor(2.3297, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3266 || Loss: 5.0286 || Conf Loss: 2.6990 || Regression Loss: 2.3297\n","Timer: 0.6442 sec.\n","tensor(1.5019, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3267 || Loss: 4.0393 || Conf Loss: 2.5373 || Regression Loss: 1.5019\n","Timer: 0.6045 sec.\n","tensor(2.3951, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3268 || Loss: 5.6291 || Conf Loss: 3.2340 || Regression Loss: 2.3951\n","Timer: 0.5766 sec.\n","tensor(1.0823, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3269 || Loss: 3.6856 || Conf Loss: 2.6033 || Regression Loss: 1.0823\n","Timer: 0.5946 sec.\n","tensor(3.6121, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3270 || Loss: 5.4303 || Conf Loss: 1.8182 || Regression Loss: 3.6121\n","Timer: 0.6681 sec.\n","tensor(0.1798, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3271 || Loss: 2.0798 || Conf Loss: 1.9000 || Regression Loss: 0.1798\n","Timer: 0.5667 sec.\n","tensor(2.4211, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3272 || Loss: 4.2291 || Conf Loss: 1.8080 || Regression Loss: 2.4211\n","Timer: 0.5597 sec.\n","tensor(0.0899, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3273 || Loss: 2.0447 || Conf Loss: 1.9548 || Regression Loss: 0.0899\n","Timer: 0.6881 sec.\n","tensor(2.6649, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3274 || Loss: 4.4449 || Conf Loss: 1.7800 || Regression Loss: 2.6649\n","Timer: 0.5494 sec.\n","tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3275 || Loss: 1.9153 || Conf Loss: 1.7047 || Regression Loss: 0.2106\n","Timer: 0.5605 sec.\n","tensor(0.7700, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3276 || Loss: 2.8469 || Conf Loss: 2.0769 || Regression Loss: 0.7700\n","Timer: 0.5504 sec.\n","tensor(1.5712, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3277 || Loss: 3.3123 || Conf Loss: 1.7411 || Regression Loss: 1.5712\n","Timer: 0.5677 sec.\n","tensor(1.3668, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3278 || Loss: 3.6766 || Conf Loss: 2.3098 || Regression Loss: 1.3668\n","Timer: 0.5842 sec.\n","tensor(5.4756, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3279 || Loss: 7.1964 || Conf Loss: 1.7208 || Regression Loss: 5.4756\n","Timer: 0.5657 sec.\n","tensor(1.8620, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3280 || Loss: 5.8251 || Conf Loss: 3.9631 || Regression Loss: 1.8620\n","Timer: 0.6637 sec.\n","tensor(2.9505, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3281 || Loss: 4.9579 || Conf Loss: 2.0074 || Regression Loss: 2.9505\n","Timer: 0.6091 sec.\n","tensor(2.6020, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3282 || Loss: 4.7178 || Conf Loss: 2.1158 || Regression Loss: 2.6020\n","Timer: 0.5900 sec.\n","tensor(4.2783, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3283 || Loss: 6.0212 || Conf Loss: 1.7430 || Regression Loss: 4.2783\n","Timer: 0.5584 sec.\n","tensor(3.4357, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3284 || Loss: 5.1435 || Conf Loss: 1.7078 || Regression Loss: 3.4357\n","Timer: 0.7343 sec.\n","tensor(5.4548, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3285 || Loss: 7.2250 || Conf Loss: 1.7702 || Regression Loss: 5.4548\n","Timer: 0.5372 sec.\n","tensor(5.2526, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3286 || Loss: 6.9798 || Conf Loss: 1.7272 || Regression Loss: 5.2526\n","Timer: 0.5589 sec.\n","tensor(1.3425, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3287 || Loss: 3.2050 || Conf Loss: 1.8625 || Regression Loss: 1.3425\n","Timer: 0.5335 sec.\n","tensor(0.5323, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3288 || Loss: 2.5975 || Conf Loss: 2.0652 || Regression Loss: 0.5323\n","Timer: 0.5693 sec.\n","tensor(1.3286, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3289 || Loss: 3.0213 || Conf Loss: 1.6928 || Regression Loss: 1.3286\n","Timer: 0.5571 sec.\n","tensor(5.4323, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3290 || Loss: 7.0999 || Conf Loss: 1.6676 || Regression Loss: 5.4323\n","Timer: 0.5530 sec.\n","tensor(2.0017, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3291 || Loss: 5.7275 || Conf Loss: 3.7258 || Regression Loss: 2.0017\n","Timer: 0.5752 sec.\n","tensor(1.5954, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3292 || Loss: 4.6643 || Conf Loss: 3.0690 || Regression Loss: 1.5954\n","Timer: 0.5502 sec.\n","tensor(1.3257, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3293 || Loss: 4.0753 || Conf Loss: 2.7496 || Regression Loss: 1.3257\n","Timer: 0.6745 sec.\n","tensor(5.2377, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3294 || Loss: 7.2078 || Conf Loss: 1.9702 || Regression Loss: 5.2377\n","Timer: 0.5938 sec.\n","tensor(1.9063, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3295 || Loss: 3.7631 || Conf Loss: 1.8568 || Regression Loss: 1.9063\n","Timer: 0.5511 sec.\n","tensor(2.8741, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3296 || Loss: 4.7879 || Conf Loss: 1.9138 || Regression Loss: 2.8741\n","Timer: 0.5535 sec.\n","tensor(0.1004, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3297 || Loss: 1.9041 || Conf Loss: 1.8037 || Regression Loss: 0.1004\n","Timer: 0.5597 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3298 || Loss: 1.1078 || Conf Loss: 1.1078 || Regression Loss: 0.0000\n","Timer: 0.6404 sec.\n","tensor(3.2842, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3299 || Loss: 5.5387 || Conf Loss: 2.2545 || Regression Loss: 3.2842\n","Timer: 0.6127 sec.\n","tensor(12.3669, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3300 || Loss: 15.9353 || Conf Loss: 3.5685 || Regression Loss: 12.3669\n","Timer: 0.5499 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3301 || Loss: 0.9746 || Conf Loss: 0.9746 || Regression Loss: 0.0000\n","Timer: 0.5397 sec.\n","tensor(0.2471, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3302 || Loss: 2.1058 || Conf Loss: 1.8587 || Regression Loss: 0.2471\n","Timer: 0.5966 sec.\n","tensor(3.5515, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3303 || Loss: 5.3150 || Conf Loss: 1.7635 || Regression Loss: 3.5515\n","Timer: 0.5736 sec.\n","tensor(4.9110, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3304 || Loss: 8.9095 || Conf Loss: 3.9985 || Regression Loss: 4.9110\n","Timer: 0.5423 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3305 || Loss: 1.1059 || Conf Loss: 1.1059 || Regression Loss: 0.0000\n","Timer: 0.6203 sec.\n","tensor(0.7140, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3306 || Loss: 2.5311 || Conf Loss: 1.8170 || Regression Loss: 0.7140\n","Timer: 0.7075 sec.\n","tensor(5.8347, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3307 || Loss: 7.6714 || Conf Loss: 1.8366 || Regression Loss: 5.8347\n","Timer: 0.6329 sec.\n","tensor(5.0586, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3308 || Loss: 6.7813 || Conf Loss: 1.7227 || Regression Loss: 5.0586\n","Timer: 0.5826 sec.\n","tensor(2.1697, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3309 || Loss: 5.6066 || Conf Loss: 3.4369 || Regression Loss: 2.1697\n","Timer: 0.5737 sec.\n","tensor(1.8305, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3310 || Loss: 5.2533 || Conf Loss: 3.4228 || Regression Loss: 1.8305\n","Timer: 0.6907 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3311 || Loss: 1.0461 || Conf Loss: 1.0461 || Regression Loss: 0.0000\n","Timer: 0.5702 sec.\n","tensor(4.6974, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3312 || Loss: 7.5408 || Conf Loss: 2.8433 || Regression Loss: 4.6974\n","Timer: 0.7089 sec.\n","tensor(4.1757, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3313 || Loss: 8.8443 || Conf Loss: 4.6686 || Regression Loss: 4.1757\n","Timer: 0.5614 sec.\n","tensor(5.2747, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3314 || Loss: 7.7659 || Conf Loss: 2.4912 || Regression Loss: 5.2747\n","Timer: 0.5958 sec.\n","tensor(0.7725, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3315 || Loss: 3.3448 || Conf Loss: 2.5723 || Regression Loss: 0.7725\n","Timer: 0.5664 sec.\n","tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3316 || Loss: 2.2446 || Conf Loss: 1.8954 || Regression Loss: 0.3492\n","Timer: 0.7144 sec.\n","tensor(3.7308, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3317 || Loss: 5.9776 || Conf Loss: 2.2468 || Regression Loss: 3.7308\n","Timer: 0.6040 sec.\n","tensor(1.9619, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3318 || Loss: 5.7550 || Conf Loss: 3.7931 || Regression Loss: 1.9619\n","Timer: 0.6296 sec.\n","tensor(5.6388, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3319 || Loss: 7.4506 || Conf Loss: 1.8118 || Regression Loss: 5.6388\n","Timer: 0.5800 sec.\n","tensor(3.4711, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3320 || Loss: 5.3111 || Conf Loss: 1.8399 || Regression Loss: 3.4711\n","Timer: 0.6516 sec.\n","tensor(0.0849, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3321 || Loss: 2.0668 || Conf Loss: 1.9819 || Regression Loss: 0.0849\n","Timer: 0.6166 sec.\n","tensor(2.0192, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3322 || Loss: 4.1005 || Conf Loss: 2.0814 || Regression Loss: 2.0192\n","Timer: 0.5931 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3323 || Loss: 1.0002 || Conf Loss: 1.0002 || Regression Loss: 0.0000\n","Timer: 0.5653 sec.\n","tensor(2.3923, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3324 || Loss: 5.0069 || Conf Loss: 2.6146 || Regression Loss: 2.3923\n","Timer: 0.6644 sec.\n","tensor(4.9915, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3325 || Loss: 6.9888 || Conf Loss: 1.9972 || Regression Loss: 4.9915\n","Timer: 0.6477 sec.\n","tensor(0.0662, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3326 || Loss: 1.8562 || Conf Loss: 1.7900 || Regression Loss: 0.0662\n","Timer: 0.7077 sec.\n","tensor(4.7957, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3327 || Loss: 6.7192 || Conf Loss: 1.9235 || Regression Loss: 4.7957\n","Timer: 0.6988 sec.\n","tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3328 || Loss: 1.8490 || Conf Loss: 1.7699 || Regression Loss: 0.0790\n","Timer: 0.7029 sec.\n","tensor(3.9017, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3329 || Loss: 6.1196 || Conf Loss: 2.2179 || Regression Loss: 3.9017\n","Timer: 0.5951 sec.\n","tensor(3.4457, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3330 || Loss: 5.2249 || Conf Loss: 1.7792 || Regression Loss: 3.4457\n","Timer: 0.5760 sec.\n","tensor(3.7052, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3331 || Loss: 6.2496 || Conf Loss: 2.5445 || Regression Loss: 3.7052\n","Timer: 0.5216 sec.\n","tensor(4.3469, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3332 || Loss: 6.2626 || Conf Loss: 1.9158 || Regression Loss: 4.3469\n","Timer: 0.6861 sec.\n","tensor(2.6874, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3333 || Loss: 4.5955 || Conf Loss: 1.9081 || Regression Loss: 2.6874\n","Timer: 0.6245 sec.\n","tensor(0.1238, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3334 || Loss: 1.8426 || Conf Loss: 1.7188 || Regression Loss: 0.1238\n","Timer: 0.6083 sec.\n","tensor(5.0802, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3335 || Loss: 6.8591 || Conf Loss: 1.7789 || Regression Loss: 5.0802\n","Timer: 0.5739 sec.\n","tensor(5.2810, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3336 || Loss: 7.1026 || Conf Loss: 1.8217 || Regression Loss: 5.2810\n","Timer: 0.5847 sec.\n","tensor(5.5668, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3337 || Loss: 7.3548 || Conf Loss: 1.7879 || Regression Loss: 5.5668\n","Timer: 0.6043 sec.\n","tensor(4.9418, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3338 || Loss: 6.6671 || Conf Loss: 1.7253 || Regression Loss: 4.9418\n","Timer: 0.6135 sec.\n","tensor(5.2717, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3339 || Loss: 7.0027 || Conf Loss: 1.7310 || Regression Loss: 5.2717\n","Timer: 0.5753 sec.\n","tensor(5.1601, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3340 || Loss: 11.7735 || Conf Loss: 6.6133 || Regression Loss: 5.1601\n","Timer: 0.5491 sec.\n","tensor(1.9579, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3341 || Loss: 6.8414 || Conf Loss: 4.8835 || Regression Loss: 1.9579\n","Timer: 0.5544 sec.\n","tensor(2.4574, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3342 || Loss: 4.3667 || Conf Loss: 1.9093 || Regression Loss: 2.4574\n","Timer: 0.6810 sec.\n","tensor(1.3677, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3343 || Loss: 4.9897 || Conf Loss: 3.6220 || Regression Loss: 1.3677\n","Timer: 0.6081 sec.\n","tensor(1.4695, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3344 || Loss: 3.7124 || Conf Loss: 2.2429 || Regression Loss: 1.4695\n","Timer: 0.5825 sec.\n","tensor(2.7462, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3345 || Loss: 4.7779 || Conf Loss: 2.0316 || Regression Loss: 2.7462\n","Timer: 0.5579 sec.\n","tensor(1.9124, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3346 || Loss: 3.7484 || Conf Loss: 1.8360 || Regression Loss: 1.9124\n","Timer: 0.6519 sec.\n","tensor(5.4442, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3347 || Loss: 7.2311 || Conf Loss: 1.7870 || Regression Loss: 5.4442\n","Timer: 0.6357 sec.\n","tensor(5.2986, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3348 || Loss: 7.3203 || Conf Loss: 2.0217 || Regression Loss: 5.2986\n","Timer: 0.6695 sec.\n","tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3349 || Loss: 2.3459 || Conf Loss: 2.0838 || Regression Loss: 0.2621\n","Timer: 0.5844 sec.\n","tensor(1.0704, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3350 || Loss: 4.2261 || Conf Loss: 3.1557 || Regression Loss: 1.0704\n","Timer: 0.5761 sec.\n","tensor(1.9124, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3351 || Loss: 3.7900 || Conf Loss: 1.8776 || Regression Loss: 1.9124\n","Timer: 0.6927 sec.\n","tensor(2.3990, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3352 || Loss: 6.5904 || Conf Loss: 4.1914 || Regression Loss: 2.3990\n","Timer: 0.5948 sec.\n","tensor(1.1593, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3353 || Loss: 3.1883 || Conf Loss: 2.0290 || Regression Loss: 1.1593\n","Timer: 0.6081 sec.\n","tensor(4.4490, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3354 || Loss: 6.8179 || Conf Loss: 2.3689 || Regression Loss: 4.4490\n","Timer: 0.6740 sec.\n","tensor(2.5854, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3355 || Loss: 4.4170 || Conf Loss: 1.8316 || Regression Loss: 2.5854\n","Timer: 0.6125 sec.\n","tensor(0.0577, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3356 || Loss: 2.0005 || Conf Loss: 1.9428 || Regression Loss: 0.0577\n","Timer: 0.6404 sec.\n","tensor(5.0411, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3357 || Loss: 6.8974 || Conf Loss: 1.8562 || Regression Loss: 5.0411\n","Timer: 0.5923 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3358 || Loss: 1.0065 || Conf Loss: 1.0065 || Regression Loss: 0.0000\n","Timer: 0.5537 sec.\n","tensor(1.2136, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3359 || Loss: 4.2209 || Conf Loss: 3.0072 || Regression Loss: 1.2136\n","Timer: 0.5828 sec.\n","tensor(2.3648, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3360 || Loss: 4.2737 || Conf Loss: 1.9089 || Regression Loss: 2.3648\n","Timer: 0.5712 sec.\n","tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3361 || Loss: 0.9841 || Conf Loss: 0.9841 || Regression Loss: 0.0000\n","Timer: 0.5448 sec.\n","tensor(4.2820, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3362 || Loss: 6.3754 || Conf Loss: 2.0934 || Regression Loss: 4.2820\n","Timer: 0.6620 sec.\n","tensor(3.8963, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3363 || Loss: 5.7079 || Conf Loss: 1.8116 || Regression Loss: 3.8963\n","Timer: 0.6221 sec.\n","tensor(3.2344, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3364 || Loss: 5.0859 || Conf Loss: 1.8515 || Regression Loss: 3.2344\n","Timer: 0.5618 sec.\n","tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)\n","iter 3365 || Loss: 1.9196 || Conf Loss: 1.8578 || Regression Loss: 0.0618\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hoIqCBShVWfq"},"source":[""],"execution_count":null,"outputs":[]}]}